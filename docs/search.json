[
  {
    "objectID": "geographic_trends.html",
    "href": "geographic_trends.html",
    "title": "Geographic Trends",
    "section": "",
    "text": "Code\nfrom pyspark.sql import SparkSession, functions as F\nimport seaborn as sns, matplotlib.pyplot as plt\nsns.set(style=\"whitegrid\")\n\nspark = SparkSession.builder.appName(\"EDA\").getOrCreate()\ndf = spark.read.parquet(\"data/clean_job_postings.parquet\")\n\n\nOverview Geographic EDA using Lightcast cleaned Spark DataFrame df. Focus on states, remote share, salaries, and hubs.\nTop 10 States by Job postings\n\n\nCode\nstate_counts = (df.groupBy(\"STATE_NAME\")\n                  .agg(F.count(\"*\").alias(\"postings\"))\n                  .orderBy(F.col(\"postings\").desc())\n                  .limit(10))\npdf = state_counts.toPandas()\n\nplt.figure(figsize=(8,4))\nsns.barplot(data=pdf, x=\"postings\", y=\"STATE_NAME\", color=\"#4C78A8\")\nplt.title(\"Top 10 States by Job Postings\")\nplt.xlabel(\"Postings\")\nplt.ylabel(\"State\")\nplt.tight_layout()\nplt.show()\n\n\n\n\n\n\n\n\n\nRemote vs Onsite Share by Industry\n\n\nCode\nremote_ind = (df.groupBy(\"NAICS2_NAME\",\"REMOTE_TYPE\")\n                .agg(F.count(\"*\").alias(\"postings\")))\npivot = (remote_ind.groupBy(\"NAICS2_NAME\")\n           .pivot(\"REMOTE_TYPE\", [\"Remote\",\"Hybrid\",\"Onsite\"])\n           .sum(\"postings\")\n           .fillna(0))\npivot = pivot.withColumn(\"total\", F.col(\"Remote\")+F.col(\"Hybrid\")+F.col(\"Onsite\")) \\\n             .withColumn(\"Remote_share\", F.col(\"Remote\")/F.col(\"total\")) \\\n             .orderBy(F.col(\"Remote_share\").desc()) \\\n             .limit(12)\npdf = pivot.select(\"NAICS2_NAME\",\"Remote_share\").toPandas()\n\nplt.figure(figsize=(8,5))\nsns.barplot(data=pdf, x=\"Remote_share\", y=\"NAICS2_NAME\", color=\"#E45756\")\nfrom matplotlib.ticker import FuncFormatter\nplt.gca().xaxis.set_major_formatter(FuncFormatter(lambda x,_: f\"{x:.0%}\"))\nplt.title(\"Industries with Highest Remote Share\")\nplt.xlabel(\"Remote share\")\nplt.ylabel(\"Industry\")\nplt.tight_layout()\nplt.show()\n\n\n\n\n\n\n\n\n\nAverage Salary by State\n\n\nCode\nstate_salary = (df.select(\"STATE_NAME\",\"SALARY\")\n                  .where(F.col(\"SALARY\").isNotNull())\n                  .groupBy(\"STATE_NAME\")\n                  .agg(F.count(\"*\").alias(\"n_postings\"),\n                       F.avg(\"SALARY\").alias(\"avg_salary\"),\n                       F.expr(\"percentile_approx(SALARY,0.5)\").alias(\"median_salary\"))\n                  .orderBy(F.col(\"avg_salary\").desc())\n                  .limit(20))\npdf = state_salary.toPandas()\n\nplt.figure(figsize=(9,5))\nsns.barplot(data=pdf, x=\"avg_salary\", y=\"STATE_NAME\", color=\"#72B7B2\")\nplt.title(\"Average Salary by State\")\nplt.xlabel(\"Average salary\")\nplt.ylabel(\"State\")\nplt.tight_layout()\nplt.show()\n\n\n\n\n\n\n\n\n\nTech Hubs vs Emerging Locations\n\n\nCode\nhub = (df.withColumn(\"hub_label\",\n          F.when(F.col(\"STATE_NAME\").isin(\"California\",\"Texas\",\"Massachusetts\",\"Washington\",\"New York\"),\n                 F.lit(\"Tech Hub\")).otherwise(F.lit(\"Emerging\")))\n         .groupBy(\"hub_label\").agg(F.count(\"*\").alias(\"postings\"))\n         .orderBy(F.col(\"postings\").desc()))\npdf = hub.toPandas()\n\nplt.figure(figsize=(5,4))\nsns.barplot(data=pdf, x=\"hub_label\", y=\"postings\", palette=\"Set2\")\nplt.title(\"Tech Hubs vs Emerging Locations\")\nplt.xlabel(\"\")\nplt.ylabel(\"Postings\")\nplt.tight_layout()\nplt.show()\n\n\n\n\n\n\n\n\n\nTop states by postings\n\n\nCode\ntop_states = df.groupBy(\"STATE_NAME\").count().orderBy(\"count\", ascending=False).limit(15).toPandas()\ntop_states.plot(kind=\"barh\", x=\"STATE_NAME\", y=\"count\", figsize=(8,6), legend=False, title=\"Top states by postings\")\nimport matplotlib.pyplot as plt\nplt.gca().invert_yaxis()\nplt.tight_layout()\nplt.show()\n\n\n\n\n\n\n\n\n\nTop states by remote share\n\n\nCode\nstate_remote_pdf = df.groupBy(\"STATE_NAME\",\"REMOTE_TYPE\").count().toPandas()\npivot = state_remote_pdf.pivot_table(index=\"STATE_NAME\", columns=\"REMOTE_TYPE\", values=\"count\", aggfunc=\"sum\", fill_value=0)\npivot[\"total\"] = pivot.sum(axis=1)\nfor c in [\"Remote\",\"Hybrid\",\"Onsite\"]:\n    if c not in pivot.columns:\n        pivot[c] = 0\npivot[\"remote_share\"] = pivot[\"Remote\"] / pivot[\"total\"]\ntop_remote = pivot.sort_values(\"remote_share\", ascending=False).head(15)\n\ntop_remote[\"remote_share\"].plot(kind=\"barh\", figsize=(8,6), xlim=(0,1), title=\"Top states by remote share\")\nplt.gca().invert_yaxis()\nplt.tight_layout()"
  },
  {
    "objectID": "eda.html",
    "href": "eda.html",
    "title": "EDA",
    "section": "",
    "text": "Code\nfrom pyspark.sql import SparkSession\nspark = SparkSession.builder.appName(\"JobPostingsEDA\").getOrCreate()\ndf = spark.read.option(\"header\",\"true\").option(\"inferSchema\",\"true\") \\\n    .option(\"multiLine\",\"true\").option(\"escape\",\"\\\"\") \\\n    .csv(\"data/raw/lightcast_job_postings.csv\")\ndf.cache()\ndf.count()\n\n\n72498\n\n\n\n\nCode\nfrom pyspark.sql.functions import when, col, trim\nfrom pyspark.sql.types import IntegerType, FloatType\n\ncols_blank = [\"CITY_NAME\",\"STATE_NAME\",\"REMOTE_TYPE\",\"MIN_EDULEVELS\",\n              \"SALARY\",\"SALARY_FROM\",\"SALARY_TO\",\n              \"MIN_YEARS_EXPERIENCE\",\"MAX_YEARS_EXPERIENCE\"]\nfor c in cols_blank:\n    if c in df.columns:\n        df = df.withColumn(c, when(trim(col(c)) == \"\", None).otherwise(col(c)))\n\ndf = df.withColumn(\"REMOTE_TYPE\", col(\"REMOTE_TYPE\").cast(IntegerType())) \\\n       .withColumn(\"MIN_EDULEVELS\", col(\"MIN_EDULEVELS\").cast(IntegerType())) \\\n       .withColumn(\"SALARY\", col(\"SALARY\").cast(FloatType())) \\\n       .withColumn(\"SALARY_FROM\", col(\"SALARY_FROM\").cast(FloatType())) \\\n       .withColumn(\"SALARY_TO\", col(\"SALARY_TO\").cast(FloatType())) \\\n       .withColumn(\"MIN_YEARS_EXPERIENCE\", col(\"MIN_YEARS_EXPERIENCE\").cast(FloatType())) \\\n       .withColumn(\"MAX_YEARS_EXPERIENCE\", col(\"MAX_YEARS_EXPERIENCE\").cast(FloatType()))\n\ndf = df.withColumn(\n    \"REMOTE_TYPE\",\n    when(col(\"REMOTE_TYPE\") == 1, \"Remote\")\n    .when(col(\"REMOTE_TYPE\") == 2, \"Onsite\")\n    .when(col(\"REMOTE_TYPE\") == 3, \"Hybrid\")\n    .otherwise(\"Onsite\")\n)\n\ndf = df.withColumn(\n    \"MIN_EDULEVELS\",\n    when(col(\"MIN_EDULEVELS\").isin(0,1,99), \"Associate or lower\")\n    .when(col(\"MIN_EDULEVELS\") == 2, \"Bachelor\")\n    .when(col(\"MIN_EDULEVELS\") == 3, \"Master's\")\n    .when(col(\"MIN_EDULEVELS\") == 4, \"PhD\")\n    .otherwise(\"Associate or lower\")\n)\n\ndf = df.withColumn(\"CITY_NAME\", when(col(\"CITY_NAME\").isNull(), \"No City\").otherwise(col(\"CITY_NAME\")))\ndf = df.withColumn(\"STATE_NAME\", when(col(\"STATE_NAME\").isNull(), \"No State\").otherwise(col(\"STATE_NAME\")))\n\ndf = df.withColumn(\n    \"SALARY\",\n    when(col(\"SALARY\").isNull() & col(\"SALARY_FROM\").isNotNull() & col(\"SALARY_TO\").isNotNull(),\n         (col(\"SALARY_FROM\") + col(\"SALARY_TO\"))/2.0\n    ).otherwise(col(\"SALARY\"))\n)\ndf.count()\n\n\n72498\n\n\n\n\nCode\ndf.write.mode(\"overwrite\").parquet(\"data/clean_job_postings.parquet\")\n\n\n\n\nCode\n# Remote share by state\nstate_remote = df.groupBy(\"STATE_NAME\",\"REMOTE_TYPE\").count().orderBy(\"count\", ascending=False)\nstate_remote.show(20, truncate=False)\n\n# Top cities by postings\ndf.groupBy(\"CITY_NAME\",\"STATE_NAME\").count().orderBy(\"count\", ascending=False).show(20, truncate=False)\n\n# Salary by state\ndf.groupBy(\"STATE_NAME\").avg(\"SALARY\").orderBy(\"avg(SALARY)\", ascending=False).show(20, truncate=False)\n\n\n+--------------+-----------+-----+\n|STATE_NAME    |REMOTE_TYPE|count|\n+--------------+-----------+-----+\n|Texas         |Onsite     |6763 |\n|California    |Onsite     |5766 |\n|Florida       |Onsite     |3060 |\n|Virginia      |Onsite     |2942 |\n|Illinois      |Onsite     |2896 |\n|New York      |Onsite     |2787 |\n|North Carolina|Onsite     |2240 |\n|Ohio          |Onsite     |2198 |\n|Georgia       |Onsite     |2169 |\n|New Jersey    |Onsite     |2148 |\n|Pennsylvania  |Onsite     |1828 |\n|Massachusetts |Onsite     |1651 |\n|Michigan      |Onsite     |1522 |\n|Arizona       |Onsite     |1349 |\n|Washington    |Onsite     |1260 |\n|Colorado      |Onsite     |1141 |\n|Texas         |Remote     |1091 |\n|Minnesota     |Onsite     |1075 |\n|California    |Remote     |1056 |\n|Maryland      |Onsite     |1018 |\n+--------------+-----------+-----+\nonly showing top 20 rows\n\n\n+-----------------+---------------------------------------+-----+\n|CITY_NAME        |STATE_NAME                             |count|\n+-----------------+---------------------------------------+-----+\n|New York, NY     |New York                               |2175 |\n|Chicago, IL      |Illinois                               |1803 |\n|Atlanta, GA      |Georgia                                |1706 |\n|Austin, TX       |Texas                                  |1463 |\n|Houston, TX      |Texas                                  |1423 |\n|Dallas, TX       |Texas                                  |1326 |\n|Charlotte, NC    |North Carolina                         |1226 |\n|Washington, DC   |Washington, D.C. (District of Columbia)|1210 |\n|Boston, MA       |Massachusetts                          |1012 |\n|Richmond, VA     |Virginia                               |884  |\n|San Francisco, CA|California                             |876  |\n|Phoenix, AZ      |Arizona                                |759  |\n|Los Angeles, CA  |California                             |737  |\n|Seattle, WA      |Washington                             |650  |\n|Columbus, OH     |Ohio                                   |647  |\n|Denver, CO       |Colorado                               |630  |\n|Tampa, FL        |Florida                                |617  |\n|Minneapolis, MN  |Minnesota                              |606  |\n|Philadelphia, PA |Pennsylvania                           |595  |\n|Raleigh, NC      |North Carolina                         |568  |\n+-----------------+---------------------------------------+-----+\nonly showing top 20 rows\n\n\n+---------------------------------------+------------------+\n|STATE_NAME                             |avg(SALARY)       |\n+---------------------------------------+------------------+\n|Connecticut                            |124966.07226107226|\n|New Jersey                             |123011.95022371365|\n|Arkansas                               |122204.1050955414 |\n|Virginia                               |121915.68095572734|\n|Vermont                                |121862.91588785047|\n|California                             |121078.16375806837|\n|Montana                                |120711.40350877192|\n|Illinois                               |120562.1273692191 |\n|Washington                             |119963.5337972167 |\n|Washington, D.C. (District of Columbia)|118926.40808080808|\n|Massachusetts                          |117145.98220858896|\n|Michigan                               |116451.63358778626|\n|North Carolina                         |116420.56212424849|\n|Maryland                               |116161.16097560976|\n|Iowa                                   |115321.96656534955|\n|Oklahoma                               |114818.31034482758|\n|Minnesota                              |114782.0500736377 |\n|Texas                                  |114607.66336818521|\n|New York                               |114173.67230695901|\n|Georgia                                |114030.27155655096|\n+---------------------------------------+------------------+\nonly showing top 20 rows\n\n\n\n\nCode\nfrom pyspark.sql.functions import col, count, sum as _sum, when, to_date, year, month, desc\n\n# Parse posting date if available\ndate_col = \"POSTED_DATE\"\nif date_col in df.columns:\n    df = df.withColumn(date_col, to_date(col(date_col)))\n    df = df.withColumn(\"YEAR\", year(col(date_col))).withColumn(\"MONTH\", month(col(date_col)))\n\n# Flag AI vs non AI using title and description keywords\nai_patterns = [\"ai\",\"artificial intelligence\",\"machine learning\",\"ml\",\"deep learning\",\"nlp\",\"computer vision\",\"llm\",\"genai\",\"gen ai\",\"data scientist\",\"ml engineer\"]\ndef mk_like(c):\n    expr = None\n    for p in ai_patterns:\n        cond = col(c).rlike(f\"(?i)\\\\b{p}\\\\b\")\n        expr = cond if expr is None else (expr | cond)\n    return expr\n\nai_flag = None\nif \"TITLE\" in df.columns:\n    ai_flag = mk_like(\"TITLE\")\nif \"JOB_DESCRIPTION\" in df.columns:\n    ai_desc = mk_like(\"JOB_DESCRIPTION\")\n    ai_flag = ai_desc if ai_flag is None else (ai_flag | ai_desc)\n\nif ai_flag is not None:\n    df = df.withColumn(\"IS_AI_ROLE\", when(ai_flag, 1).otherwise(0))\nelse:\n    df = df.withColumn(\"IS_AI_ROLE\", when(col(\"TITLE\").isNotNull(), 0).otherwise(0))\n\n\n\n\nCode\nfrom pyspark.sql.functions import desc\n\n\n\nRemote share by state\nstate_remote = df.groupBy(“STATE_NAME”,“REMOTE_TYPE”).count().orderBy(“count”, ascending=False) state_remote.show(30, truncate=False)\n\n\nTop states by postings\nstate_totals = df.groupBy(“STATE_NAME”).count().orderBy(“count”, ascending=False) state_totals.show(30, truncate=False)\n\n\nAI vs non AI counts by state\nfrom pyspark.sql.functions import count, sum as _sum, avg ai_state = df.groupBy(“STATE_NAME”).agg( _sum(“IS_AI_ROLE”).alias(“ai_posts”), (count(“*“) - _sum(“IS_AI_ROLE”)).alias(“non_ai_posts”) ).orderBy(“ai_posts”, ascending=False) ai_state.show(30, truncate=False)\n\n\nMonthly trend of remote vs onsite overall\nif “YEAR” in df.columns and “MONTH” in df.columns: monthly_remote = df.groupBy(“YEAR”,“MONTH”,“REMOTE_TYPE”).count().orderBy(“YEAR”,“MONTH”,“REMOTE_TYPE”) monthly_remote.show(60, truncate=False)\n\n\nSalary by state for AI vs non AI\nif “SALARY” in df.columns: sal_by_state_ai = df.groupBy(“STATE_NAME”,“IS_AI_ROLE”).agg(avg(“SALARY”).alias(“avg_salary”)).orderBy(“avg_salary”, ascending=False) sal_by_state_ai.show(30, truncate=False) ```"
  },
  {
    "objectID": "tech_hub_analysis.html",
    "href": "tech_hub_analysis.html",
    "title": "Tech Hub Analysis",
    "section": "",
    "text": "This section evaluates whether legacy tech hubs (Bay Area, Seattle, Boston, NYC, Austin) still dominate AI hiring or whether a set of emerging hubs is gaining share. We compare posting volume, AI share, remote/hybrid availability, and median salary (when available).\n\n\n\n\n\n\nNote\n\n\n\nData source: data/raw/lightcast_job_postings.csv (Lightcast, 2024; Jan–Sep if that’s what you downloaded).\nInstructions: Make sure the CSV is at data/raw/lightcast_job_postings.csv."
  },
  {
    "objectID": "tech_hub_analysis.html#purpose",
    "href": "tech_hub_analysis.html#purpose",
    "title": "Tech Hub Analysis",
    "section": "",
    "text": "This section evaluates whether legacy tech hubs (Bay Area, Seattle, Boston, NYC, Austin) still dominate AI hiring or whether a set of emerging hubs is gaining share. We compare posting volume, AI share, remote/hybrid availability, and median salary (when available).\n\n\n\n\n\n\nNote\n\n\n\nData source: data/raw/lightcast_job_postings.csv (Lightcast, 2024; Jan–Sep if that’s what you downloaded).\nInstructions: Make sure the CSV is at data/raw/lightcast_job_postings.csv."
  },
  {
    "objectID": "tech_hub_analysis.html#setup",
    "href": "tech_hub_analysis.html#setup",
    "title": "Tech Hub Analysis",
    "section": "0.2 Setup",
    "text": "0.2 Setup\nlibrary(tidyverse) library(lubridate) theme_set(theme_minimal(base_size = 14))\npath &lt;- “data/raw/lightcast_job_postings.csv” raw &lt;- read_csv(path, show_col_types = FALSE) df &lt;- raw %&gt;% rename_with(toupper) %&gt;% mutate( CITY_NAME = coalesce(CITY_NAME, CITY, NA), STATE_NAME = coalesce(STATE_NAME, STATE, NA), TITLE = coalesce(JOB_TITLE, TITLE, NA), SKILLS_TXT = coalesce(SKILLS, SKILL_TEXT, NA), POSTED = coalesce(POSTED_DATE, DATE_POSTED, as.character(NA)), POSTED = suppressWarnings(ymd(POSTED)), REMOTE_TYPE = case_when( REMOTE_TYPE %in% c(“Remote”,“REMOTE”,“remote”,“1”) ~ “Remote”, REMOTE_TYPE %in% c(“Hybrid”,“HYBRID”,“hybrid”,“3”) ~ “Hybrid”, TRUE ~ “On-site” ), SALARY = suppressWarnings(readr::parse_number(coalesce(SALARY, SALARY_TO, SALARY_FROM))) )"
  },
  {
    "objectID": "skill_gap_analysis.html",
    "href": "skill_gap_analysis.html",
    "title": "Skill Gap Analysis",
    "section": "",
    "text": "Objective: Compare the skills required in IT job postings against the actual skills of your group members to identify knowledge gaps and areas for improvement."
  },
  {
    "objectID": "skill_gap_analysis.html#create-a-team-based-skill-dataframe",
    "href": "skill_gap_analysis.html#create-a-team-based-skill-dataframe",
    "title": "Skill Gap Analysis",
    "section": "1 Create a team-based skill dataframe",
    "text": "1 Create a team-based skill dataframe\nEach team member should list their current skills relevant to their selected IT career path. Use a numerical scale (1-5) to indicate proficiency levels:\nNote: Each team member has been given a fictional score to better demonstrate the variations in proficiency level.\n\n1 = Beginner\n2 = Basic knowledge\n3 = Intermediate\n4 = Advanced\n5 = Expert\n\n\n\nCode\nimport pandas as pd\nimport json\nimport numpy as np\nfrom collections import Counter\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\nskills_data = {\n    \"Name\": [\"Thomas\", \"Fayobomi\", \"Dominique\", \"Aryan\"],\n    \"Python\": [1, 2, 4, 5],\n    \"SQL\": [2, 3, 3, 4],\n    \"Machine Learning\": [1, 2, 4, 4],\n    \"Cloud Computing\": [1, 2, 3, 5]\n}\n\ndf_skills = pd.DataFrame(skills_data)\ndf_skills.set_index(\"Name\", inplace=True)\ndf_skills\n\n\n\n\n\n\n\n\n\nPython\nSQL\nMachine Learning\nCloud Computing\n\n\nName\n\n\n\n\n\n\n\n\nThomas\n1\n2\n1\n1\n\n\nFayobomi\n2\n3\n2\n2\n\n\nDominique\n4\n3\n4\n3\n\n\nAryan\n5\n4\n4\n5\n\n\n\n\n\n\n\nYou can use heatmaps or any other visualizations to visualize team strengths and gaps.\n\n1.1 \nVisualizing Skill Gaps with Seaborn\n\n\nCode\nimport seaborn as sns\nimport matplotlib.pyplot as plt\n\nplt.figure(figsize=(8, 6))\nsns.heatmap(df_skills, annot=True, cmap=\"coolwarm\", linewidths=0.5)\nplt.title(\"Team Skill Levels Heatmap\")\nplt.show()\n\n\n\n\n\n\n\n\n\n\n\n1.2 Compare team skills to industry requirements\nExtract most in-demand skills from IT job postings. Identify gaps between team skill levels and job expectations."
  },
  {
    "objectID": "skill_gap_analysis.html#extracting-top-skills-from-job-descriptions",
    "href": "skill_gap_analysis.html#extracting-top-skills-from-job-descriptions",
    "title": "Skill Gap Analysis",
    "section": "2 Extracting Top Skills from Job Descriptions",
    "text": "2 Extracting Top Skills from Job Descriptions\n\n\nCode\nfrom collections import Counter\n\n#Assuming job_descriptions is a list of text from job postings\ntop_skills = [\"Python\", \"SQL\", \"Machine Learning\", \"Cloud Computing\"]\njob_skill_counts = Counter(top_skills)\n\n# Compare with team skill levels\nfor skill in top_skills:\n    if skill not in df_skills.columns:\n        df_skills[skill] = 0  # Assume no knowledge in missing skills\n\ndf_skills\n\n\n\n\n\n\n\n\n\nPython\nSQL\nMachine Learning\nCloud Computing\n\n\nName\n\n\n\n\n\n\n\n\nThomas\n1\n2\n1\n1\n\n\nFayobomi\n2\n3\n2\n2\n\n\nDominique\n4\n3\n4\n3\n\n\nAryan\n5\n4\n4\n5"
  },
  {
    "objectID": "skill_gap_analysis.html#improvement-plan",
    "href": "skill_gap_analysis.html#improvement-plan",
    "title": "Skill Gap Analysis",
    "section": "3 Improvement Plan",
    "text": "3 Improvement Plan\nWhich skills should each member prioritize learning? What courses or resources can help? How can the team collaborate to bridge skill gaps?\n\n\nCode\nfrom pyspark.sql import SparkSession, functions as F\nimport seaborn as sns, matplotlib.pyplot as plt\nsns.set(style=\"whitegrid\")\n\nspark = SparkSession.builder.appName(\"EDA\").getOrCreate()\ndf = spark.read.parquet(\"data/clean_job_postings.parquet\")\n\n\nWARNING: Using incubator modules: jdk.incubator.vector\nUsing Spark's default log4j profile: org/apache/spark/log4j2-defaults.properties\nSetting default log level to \"WARN\".\nTo adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n25/10/16 22:58:30 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n[Stage 0:&gt;                                                          (0 + 1) / 1]                                                                                \n\n\n\n\nCode\nprint(df.columns)\nprint(df.head(5))\n\n\n['ID', 'LAST_UPDATED_DATE', 'LAST_UPDATED_TIMESTAMP', 'DUPLICATES', 'POSTED', 'EXPIRED', 'DURATION', 'SOURCE_TYPES', 'SOURCES', 'URL', 'ACTIVE_URLS', 'ACTIVE_SOURCES_INFO', 'TITLE_RAW', 'BODY', 'MODELED_EXPIRED', 'MODELED_DURATION', 'COMPANY', 'COMPANY_NAME', 'COMPANY_RAW', 'COMPANY_IS_STAFFING', 'EDUCATION_LEVELS', 'EDUCATION_LEVELS_NAME', 'MIN_EDULEVELS', 'MIN_EDULEVELS_NAME', 'MAX_EDULEVELS', 'MAX_EDULEVELS_NAME', 'EMPLOYMENT_TYPE', 'EMPLOYMENT_TYPE_NAME', 'MIN_YEARS_EXPERIENCE', 'MAX_YEARS_EXPERIENCE', 'IS_INTERNSHIP', 'SALARY', 'REMOTE_TYPE', 'REMOTE_TYPE_NAME', 'ORIGINAL_PAY_PERIOD', 'SALARY_TO', 'SALARY_FROM', 'LOCATION', 'CITY', 'CITY_NAME', 'COUNTY', 'COUNTY_NAME', 'MSA', 'MSA_NAME', 'STATE', 'STATE_NAME', 'COUNTY_OUTGOING', 'COUNTY_NAME_OUTGOING', 'COUNTY_INCOMING', 'COUNTY_NAME_INCOMING', 'MSA_OUTGOING', 'MSA_NAME_OUTGOING', 'MSA_INCOMING', 'MSA_NAME_INCOMING', 'NAICS2', 'NAICS2_NAME', 'NAICS3', 'NAICS3_NAME', 'NAICS4', 'NAICS4_NAME', 'NAICS5', 'NAICS5_NAME', 'NAICS6', 'NAICS6_NAME', 'TITLE', 'TITLE_NAME', 'TITLE_CLEAN', 'SKILLS', 'SKILLS_NAME', 'SPECIALIZED_SKILLS', 'SPECIALIZED_SKILLS_NAME', 'CERTIFICATIONS', 'CERTIFICATIONS_NAME', 'COMMON_SKILLS', 'COMMON_SKILLS_NAME', 'SOFTWARE_SKILLS', 'SOFTWARE_SKILLS_NAME', 'ONET', 'ONET_NAME', 'ONET_2019', 'ONET_2019_NAME', 'CIP6', 'CIP6_NAME', 'CIP4', 'CIP4_NAME', 'CIP2', 'CIP2_NAME', 'SOC_2021_2', 'SOC_2021_2_NAME', 'SOC_2021_3', 'SOC_2021_3_NAME', 'SOC_2021_4', 'SOC_2021_4_NAME', 'SOC_2021_5', 'SOC_2021_5_NAME', 'LOT_CAREER_AREA', 'LOT_CAREER_AREA_NAME', 'LOT_OCCUPATION', 'LOT_OCCUPATION_NAME', 'LOT_SPECIALIZED_OCCUPATION', 'LOT_SPECIALIZED_OCCUPATION_NAME', 'LOT_OCCUPATION_GROUP', 'LOT_OCCUPATION_GROUP_NAME', 'LOT_V6_SPECIALIZED_OCCUPATION', 'LOT_V6_SPECIALIZED_OCCUPATION_NAME', 'LOT_V6_OCCUPATION', 'LOT_V6_OCCUPATION_NAME', 'LOT_V6_OCCUPATION_GROUP', 'LOT_V6_OCCUPATION_GROUP_NAME', 'LOT_V6_CAREER_AREA', 'LOT_V6_CAREER_AREA_NAME', 'SOC_2', 'SOC_2_NAME', 'SOC_3', 'SOC_3_NAME', 'SOC_4', 'SOC_4_NAME', 'SOC_5', 'SOC_5_NAME', 'LIGHTCAST_SECTORS', 'LIGHTCAST_SECTORS_NAME', 'NAICS_2022_2', 'NAICS_2022_2_NAME', 'NAICS_2022_3', 'NAICS_2022_3_NAME', 'NAICS_2022_4', 'NAICS_2022_4_NAME', 'NAICS_2022_5', 'NAICS_2022_5_NAME', 'NAICS_2022_6', 'NAICS_2022_6_NAME']\n\n\n25/10/16 22:58:41 WARN SparkStringUtils: Truncated the string representation of a plan since it was too large. This behavior can be adjusted by setting 'spark.sql.debug.maxToStringFields'.\n[Stage 1:&gt;                                                          (0 + 1) / 1]\n\n\n[Row(ID='1f57d95acf4dc67ed2819eb12f049f6a5c11782c', LAST_UPDATED_DATE='9/6/2024', LAST_UPDATED_TIMESTAMP=datetime.datetime(2024, 9, 6, 20, 32, 57, 352000), DUPLICATES=0, POSTED='6/2/2024', EXPIRED='6/8/2024', DURATION=6, SOURCE_TYPES='[\\n  \"Company\"\\n]', SOURCES='[\\n  \"brassring.com\"\\n]', URL='[\\n  \"https://sjobs.brassring.com/TGnewUI/Search/home/HomeWithPreLoad?partnerid=25450&siteid=5588&PageType=JobDetails&jobid=3542033\"\\n]', ACTIVE_URLS='[]', ACTIVE_SOURCES_INFO=None, TITLE_RAW='Enterprise Analyst (II-III)', BODY='31-May-2024\\n\\nEnterprise Analyst (II-III)\\n\\nMerchandising\\n\\nEl Dorado\\n\\nArkansas\\n\\nJob Posting\\n\\nGENERAL DESCRIPTION OF POSITION\\nPerforms business analysis using various techniques, e.g. statistical analysis, explanatory and predictive modeling, data mining. Identifies trends and patterns in data and can explain business drivers or the why behind the data. Skills typically attained in a four-year degree plus the understanding and application of analytical tools and techniques that come with 2-5 years of experience including advanced MS office skills, advanced SQL, PowerBI, and exporting/building data models.\\n\\nESSENTIAL DUTIES AND RESPONSIBILITIES\\n1. Gathers insight and performs routine and ad hoc reporting using various techniques (statistical analysis, data mining).\\n2. Frames unstructured problems\\n3. Performs data extraction/gathering, reconciling ambiguous data, and executes the hypothesis-driven approach.\\n4. Develops fact-based and actionable recommendations/presentations.\\n5. Analyze data for trends and patterns, and interpret data with a clear objective in mind\\n6. Proficiently design and develop algorithms and models to use against large datasets to create business insights\\n7. Make appropriate selection, utilization and interpretation of advanced analytical methodologies\\n8. Effectively communicate insights and recommendations to both technical and non-technical leaders and business customers/partners including preparing reports, updates and/or presentations related to progress made on a project or solution\\n9. Work with project teams and business partners to determine project goals and deliver productionized models and tools\\n10. Effectively develop trust and collaboration with internal customers and cross-functional teams\\n\\n\\nQUALIFICATIONS\\nTo perform this job successfully, an individual must be able to perform each essential duty mentioned satisfactorily. The requirements listed below are representative of the knowledge, skill, and/or ability required.\\n\\nEDUCATION AND EXPERIENCE\\nBroad knowledge of such fields as economics, statistics, business administration, finance, math, science etc. Equivalent to a four-year college degree, plus 2-5 years related experience and/or training, or equivalent combination of education and experience.\\n\\nAuto req ID\\n\\n181767BR\\n\\nStore Number/Dept Number\\n\\n299900055000 - Strat Plan Perform Mgmt\\n\\nStore Address\\n\\n200 E Peach St\\n\\nStore Zip\\n\\n71730', MODELED_EXPIRED='6/8/2024', MODELED_DURATION=6, COMPANY=894731, COMPANY_NAME='Murphy USA', COMPANY_RAW='Murphy USA', COMPANY_IS_STAFFING=False, EDUCATION_LEVELS='[\\n  2\\n]', EDUCATION_LEVELS_NAME='[\\n  \"Bachelor\\'s degree\"\\n]', MIN_EDULEVELS='Bachelor', MIN_EDULEVELS_NAME=\"Bachelor's degree\", MAX_EDULEVELS=None, MAX_EDULEVELS_NAME=None, EMPLOYMENT_TYPE=1, EMPLOYMENT_TYPE_NAME='Full-time (&gt; 32 hours)', MIN_YEARS_EXPERIENCE=2.0, MAX_YEARS_EXPERIENCE=2.0, IS_INTERNSHIP=False, SALARY=None, REMOTE_TYPE='Onsite', REMOTE_TYPE_NAME='[None]', ORIGINAL_PAY_PERIOD=None, SALARY_TO=None, SALARY_FROM=None, LOCATION='{\\n  \"lat\": 33.20763,\\n  \"lon\": -92.6662674\\n}', CITY='RWwgRG9yYWRvLCBBUg==', CITY_NAME='El Dorado, AR', COUNTY=5139, COUNTY_NAME='Union, AR', MSA=20980, MSA_NAME='El Dorado, AR', STATE=5, STATE_NAME='Arkansas', COUNTY_OUTGOING=5139, COUNTY_NAME_OUTGOING='Union, AR', COUNTY_INCOMING=5139, COUNTY_NAME_INCOMING='Union, AR', MSA_OUTGOING=20980, MSA_NAME_OUTGOING='El Dorado, AR', MSA_INCOMING=20980, MSA_NAME_INCOMING='El Dorado, AR', NAICS2=44, NAICS2_NAME='Retail Trade', NAICS3=441, NAICS3_NAME='Motor Vehicle and Parts Dealers', NAICS4=4413, NAICS4_NAME='Automotive Parts, Accessories, and Tire Retailers', NAICS5=44133, NAICS5_NAME='Automotive Parts and Accessories Retailers', NAICS6=441330, NAICS6_NAME='Automotive Parts and Accessories Retailers', TITLE='ET29C073C03D1F86B4', TITLE_NAME='Enterprise Analysts', TITLE_CLEAN='enterprise analyst ii iii', SKILLS='[\\n  \"KS126DB6T061MHD7RTGQ\",\\n  \"KS126706DPFD3354M7YK\",\\n  \"KS1280B68GD79P4WMVYW\",\\n  \"KS128006L3V0HM2B26N5\",\\n  \"KS122PM76DCYL9WC89Y7\",\\n  \"ESB17C5AF46AFE08157D\",\\n  \"KS122P063X6NGMHLP002\",\\n  \"BGSB4E1D5CA81759D758\",\\n  \"KS122PL70D99VRWMFM2T\",\\n  \"KS1218C6C8TX2Y1KRN37\",\\n  \"KS123MC78KV644P5DDZ0\",\\n  \"KS120D96FHL88PZDKZKH\",\\n  \"KS440Y975RD841M02V3S\",\\n  \"KS440W865GC4VRBW6LJP\",\\n  \"BGS1ADAA36DB65721AA3\",\\n  \"BGS4CDA2E23CE451E247\",\\n  \"KS13USA80NE38XJHA2TL\",\\n  \"KS128HP65N6N70YV5ZM7\",\\n  \"KS1239W6QZKL1H0TF1TJ\",\\n  \"KS1218B62M9QRBY8WRSK\"\\n]', SKILLS_NAME='[\\n  \"Merchandising\",\\n  \"Mathematics\",\\n  \"Presentations\",\\n  \"Predictive Modeling\",\\n  \"Data Modeling\",\\n  \"Advanced Analytics\",\\n  \"Data Extraction\",\\n  \"Statistical Analysis\",\\n  \"Data Mining\",\\n  \"Business Analysis\",\\n  \"Finance\",\\n  \"Algorithms\",\\n  \"Statistics\",\\n  \"SQL (Programming Language)\",\\n  \"Report Writing\",\\n  \"Ad Hoc Reporting\",\\n  \"Power BI\",\\n  \"Relationship Building\",\\n  \"Economics\",\\n  \"Business Administration\"\\n]', SPECIALIZED_SKILLS='[\\n  \"KS126DB6T061MHD7RTGQ\",\\n  \"KS128006L3V0HM2B26N5\",\\n  \"KS122PM76DCYL9WC89Y7\",\\n  \"ESB17C5AF46AFE08157D\",\\n  \"KS122P063X6NGMHLP002\",\\n  \"BGSB4E1D5CA81759D758\",\\n  \"KS122PL70D99VRWMFM2T\",\\n  \"KS1218C6C8TX2Y1KRN37\",\\n  \"KS123MC78KV644P5DDZ0\",\\n  \"KS120D96FHL88PZDKZKH\",\\n  \"KS440Y975RD841M02V3S\",\\n  \"KS440W865GC4VRBW6LJP\",\\n  \"BGS4CDA2E23CE451E247\",\\n  \"KS13USA80NE38XJHA2TL\",\\n  \"KS1239W6QZKL1H0TF1TJ\"\\n]', SPECIALIZED_SKILLS_NAME='[\\n  \"Merchandising\",\\n  \"Predictive Modeling\",\\n  \"Data Modeling\",\\n  \"Advanced Analytics\",\\n  \"Data Extraction\",\\n  \"Statistical Analysis\",\\n  \"Data Mining\",\\n  \"Business Analysis\",\\n  \"Finance\",\\n  \"Algorithms\",\\n  \"Statistics\",\\n  \"SQL (Programming Language)\",\\n  \"Ad Hoc Reporting\",\\n  \"Power BI\",\\n  \"Economics\"\\n]', CERTIFICATIONS='[]', CERTIFICATIONS_NAME='[]', COMMON_SKILLS='[\\n  \"KS126706DPFD3354M7YK\",\\n  \"KS1280B68GD79P4WMVYW\",\\n  \"BGS1ADAA36DB65721AA3\",\\n  \"KS128HP65N6N70YV5ZM7\",\\n  \"KS1218B62M9QRBY8WRSK\"\\n]', COMMON_SKILLS_NAME='[\\n  \"Mathematics\",\\n  \"Presentations\",\\n  \"Report Writing\",\\n  \"Relationship Building\",\\n  \"Business Administration\"\\n]', SOFTWARE_SKILLS='[\\n  \"KS440W865GC4VRBW6LJP\",\\n  \"KS13USA80NE38XJHA2TL\"\\n]', SOFTWARE_SKILLS_NAME='[\\n  \"SQL (Programming Language)\",\\n  \"Power BI\"\\n]', ONET='15-2051.01', ONET_NAME='Business Intelligence Analysts', ONET_2019='15-2051.01', ONET_2019_NAME='Business Intelligence Analysts', CIP6='[\\n  \"45.0601\",\\n  \"27.0101\"\\n]', CIP6_NAME='[\\n  \"Economics, General\",\\n  \"Mathematics, General\"\\n]', CIP4='[\\n  \"45.06\",\\n  \"27.01\"\\n]', CIP4_NAME='[\\n  \"Economics\",\\n  \"Mathematics\"\\n]', CIP2='[\\n  \"45\",\\n  \"27\"\\n]', CIP2_NAME='[\\n  \"Social Sciences\",\\n  \"Mathematics and Statistics\"\\n]', SOC_2021_2='15-0000', SOC_2021_2_NAME='Computer and Mathematical Occupations', SOC_2021_3='15-2000', SOC_2021_3_NAME='Mathematical Science Occupations', SOC_2021_4='15-2050', SOC_2021_4_NAME='Data Scientists', SOC_2021_5='15-2051', SOC_2021_5_NAME='Data Scientists', LOT_CAREER_AREA=23, LOT_CAREER_AREA_NAME='Information Technology and Computer Science', LOT_OCCUPATION=231010, LOT_OCCUPATION_NAME='Business Intelligence Analyst', LOT_SPECIALIZED_OCCUPATION=23101011, LOT_SPECIALIZED_OCCUPATION_NAME='General ERP Analyst / Consultant', LOT_OCCUPATION_GROUP=2310, LOT_OCCUPATION_GROUP_NAME='Business Intelligence', LOT_V6_SPECIALIZED_OCCUPATION=23101011, LOT_V6_SPECIALIZED_OCCUPATION_NAME='General ERP Analyst / Consultant', LOT_V6_OCCUPATION=231010, LOT_V6_OCCUPATION_NAME='Business Intelligence Analyst', LOT_V6_OCCUPATION_GROUP=2310, LOT_V6_OCCUPATION_GROUP_NAME='Business Intelligence', LOT_V6_CAREER_AREA=23, LOT_V6_CAREER_AREA_NAME='Information Technology and Computer Science', SOC_2='15-0000', SOC_2_NAME='Computer and Mathematical Occupations', SOC_3='15-2000', SOC_3_NAME='Mathematical Science Occupations', SOC_4='15-2050', SOC_4_NAME='Data Scientists', SOC_5='15-2051', SOC_5_NAME='Data Scientists', LIGHTCAST_SECTORS='[\\n  7\\n]', LIGHTCAST_SECTORS_NAME='[\\n  \"Artificial Intelligence\"\\n]', NAICS_2022_2=44, NAICS_2022_2_NAME='Retail Trade', NAICS_2022_3=441, NAICS_2022_3_NAME='Motor Vehicle and Parts Dealers', NAICS_2022_4=4413, NAICS_2022_4_NAME='Automotive Parts, Accessories, and Tire Retailers', NAICS_2022_5=44133, NAICS_2022_5_NAME='Automotive Parts and Accessories Retailers', NAICS_2022_6=441330, NAICS_2022_6_NAME='Automotive Parts and Accessories Retailers'), Row(ID='0cb072af26757b6c4ea9464472a50a443af681ac', LAST_UPDATED_DATE='8/2/2024', LAST_UPDATED_TIMESTAMP=datetime.datetime(2024, 8, 2, 17, 8, 58, 838000), DUPLICATES=0, POSTED='6/2/2024', EXPIRED='8/1/2024', DURATION=None, SOURCE_TYPES='[\\n  \"Job Board\"\\n]', SOURCES='[\\n  \"maine.gov\"\\n]', URL='[\\n  \"https://joblink.maine.gov/jobs/1085740\"\\n]', ACTIVE_URLS='[]', ACTIVE_SOURCES_INFO=None, TITLE_RAW='Oracle Consultant - Reports (3592)', BODY=\"Oracle Consultant - Reports (3592)\\n\\nat SMX in Augusta, Maine, United States\\n\\nJob Description\\n\\nOracle Consultant - Reports (3592)at SMX (https://www.smxtech.com/careers/)\\n\\nUnited States\\n\\nCreoal has recently become a proud subsidiary of SMX, marking an exciting collaboration that enhances our collective capabilities to deliver cutting-edge digital transformation solutions.SMX has a growing Oracle Cloud Practice, focusing on Commercial and Public Sector customers.\\n\\nSMX/Creoal drives digital transformation through innovative solutions that leverage Oracle, Salesforce, and leading-edge technologies for Federal, public sector, and commercial organizations across the globe. We employ a holistic approach of People, Process, and Technology.\\n\\nThe value of our organization is rooted in our team, whose experience across a wide range of technologies delivers tangible results to our clients. SMX/Creoal's skilled professional resources represent the industry's most respected digital transformation experts.\\n\\nWe are looking for an Oracle Consultant to support our client in this 100% remote role.\\n\\nEssential Duties and Responsibilities for the Oracle Consultant include:\\n\\n+ Providing direction and specialist knowledge in utilizing the following tools:\\n\\n+ Oracle Analytics Cloud (OAC)\\n\\n+ Oracle Transactional Business Intelligence (OTBI)\\n\\n+ Oracle Business Intelligence Publisher (BI Publisher)\\n\\n+ Developing reports and other business intelligence solutions to meet customers' needs in the following domains/fields:\\n\\n+ Financials\\n\\n+ Supply Chain\\n\\n+ Procurement\\n\\n+ Project Accounting\\n\\n+ Development of reusable reports using tools such as OTBI, Financial Reporting Studio, and OAC\\n\\nRequired Skills and Experience:\\n\\n+ Clearance Required: None\\n\\n+ US Citizenship is required for work on this contract. Applicant must be residing in the United States.\\n\\n+ 3-5 years of experience is required in the following toolsets:\\n\\n+ OAC\\n\\n+ OTBI\\n\\n+ BI Publisher\\n\\n+ PL/SQL\\n\\n+ Exposure to large-scale implementation projects, principally Oracle Fusion Cloud\\n\\nDesired Qualifications:\\n\\n+ Familiarity with Oracle Integration Cloud (OIC) is a plus\\n\\n+ Past background with Oracle's EBusiness Suite (EBS) product\\n\\n\\\\#cjpost #LI-REMOTE #LI-JJ1\\n\\nAt SMX, we are a team of technical and domain experts dedicated to enabling your mission. From priority national security initiatives for the DoD to highly assured and compliant solutions for healthcare, we understand that digital transformation is key to your future success.\\n\\nWe share your vision for the future and strive to accelerate your impact on the world. We bring both cutting edge technology and an expansive view of what's possible to every engagement. Our delivery model and unique approaches harness our deep technical and domain knowledge, providing forward-looking insights and practical solutions to power secure mission acceleration.\\n\\nSMX is committed to hiring and retaining a diverse workforce. All qualified candidates will receive consideration for employment without regard to disability status, protected veteran status, race, color, age, religion, national origin, citizenship, marital status, sex, sexual orientation, gender identity or expression, pregnancy or genetic information. SMX is an Equal Opportunity/Affirmative Action employer including disability and veterans.\\n\\nSelected applicant will be subject to a background investigation.\", MODELED_EXPIRED='8/1/2024', MODELED_DURATION=None, COMPANY=133098, COMPANY_NAME='Smx Corporation Limited', COMPANY_RAW='SMX', COMPANY_IS_STAFFING=True, EDUCATION_LEVELS='[\\n  99\\n]', EDUCATION_LEVELS_NAME='[\\n  \"No Education Listed\"\\n]', MIN_EDULEVELS='Associate or lower', MIN_EDULEVELS_NAME='No Education Listed', MAX_EDULEVELS=None, MAX_EDULEVELS_NAME=None, EMPLOYMENT_TYPE=1, EMPLOYMENT_TYPE_NAME='Full-time (&gt; 32 hours)', MIN_YEARS_EXPERIENCE=3.0, MAX_YEARS_EXPERIENCE=3.0, IS_INTERNSHIP=False, SALARY=None, REMOTE_TYPE='Remote', REMOTE_TYPE_NAME='Remote', ORIGINAL_PAY_PERIOD=None, SALARY_TO=None, SALARY_FROM=None, LOCATION='{\\n  \"lat\": 44.3106241,\\n  \"lon\": -69.7794897\\n}', CITY='QXVndXN0YSwgTUU=', CITY_NAME='Augusta, ME', COUNTY=23011, COUNTY_NAME='Kennebec, ME', MSA=12300, MSA_NAME='Augusta-Waterville, ME', STATE=23, STATE_NAME='Maine', COUNTY_OUTGOING=23011, COUNTY_NAME_OUTGOING='Kennebec, ME', COUNTY_INCOMING=23011, COUNTY_NAME_INCOMING='Kennebec, ME', MSA_OUTGOING=12300, MSA_NAME_OUTGOING='Augusta-Waterville, ME', MSA_INCOMING=12300, MSA_NAME_INCOMING='Augusta-Waterville, ME', NAICS2=56, NAICS2_NAME='Administrative and Support and Waste Management and Remediation Services', NAICS3=561, NAICS3_NAME='Administrative and Support Services', NAICS4=5613, NAICS4_NAME='Employment Services', NAICS5=56132, NAICS5_NAME='Temporary Help Services', NAICS6=561320, NAICS6_NAME='Temporary Help Services', TITLE='ET21DDA63780A7DC09', TITLE_NAME='Oracle Consultants', TITLE_CLEAN='oracle consultant reports', SKILLS='[\\n  \"KS122626T550SLQ7QZ1C\",\\n  \"KS123YJ6KVWC91BTMB4R\",\\n  \"BGSBF3F508F7F46312E3\",\\n  \"ESEA839CED37833AA298\",\\n  \"KS127HT6PY61NVMR3PWG\",\\n  \"ES72D57E1BC4BB22BBB0\",\\n  \"KS120ZX7019J4V8DHBTM\",\\n  \"KS440YT6CGVX2WD4DLMR\",\\n  \"KS128456FPN85WYD0SH8\"\\n]', SKILLS_NAME='[\\n  \"Procurement\",\\n  \"Financial Statements\",\\n  \"Oracle Business Intelligence (BI) / OBIA\",\\n  \"Oracle E-Business Suite\",\\n  \"PL/SQL\",\\n  \"Supply Chain\",\\n  \"Business Intelligence\",\\n  \"Oracle Fusion Middleware\",\\n  \"Project Accounting\"\\n]', SPECIALIZED_SKILLS='[\\n  \"KS122626T550SLQ7QZ1C\",\\n  \"KS123YJ6KVWC91BTMB4R\",\\n  \"BGSBF3F508F7F46312E3\",\\n  \"ESEA839CED37833AA298\",\\n  \"KS127HT6PY61NVMR3PWG\",\\n  \"ES72D57E1BC4BB22BBB0\",\\n  \"KS120ZX7019J4V8DHBTM\",\\n  \"KS440YT6CGVX2WD4DLMR\",\\n  \"KS128456FPN85WYD0SH8\"\\n]', SPECIALIZED_SKILLS_NAME='[\\n  \"Procurement\",\\n  \"Financial Statements\",\\n  \"Oracle Business Intelligence (BI) / OBIA\",\\n  \"Oracle E-Business Suite\",\\n  \"PL/SQL\",\\n  \"Supply Chain\",\\n  \"Business Intelligence\",\\n  \"Oracle Fusion Middleware\",\\n  \"Project Accounting\"\\n]', CERTIFICATIONS='[]', CERTIFICATIONS_NAME='[]', COMMON_SKILLS='[]', COMMON_SKILLS_NAME='[]', SOFTWARE_SKILLS='[\\n  \"BGSBF3F508F7F46312E3\",\\n  \"ESEA839CED37833AA298\",\\n  \"KS127HT6PY61NVMR3PWG\",\\n  \"KS440YT6CGVX2WD4DLMR\"\\n]', SOFTWARE_SKILLS_NAME='[\\n  \"Oracle Business Intelligence (BI) / OBIA\",\\n  \"Oracle E-Business Suite\",\\n  \"PL/SQL\",\\n  \"Oracle Fusion Middleware\"\\n]', ONET='15-2051.01', ONET_NAME='Business Intelligence Analysts', ONET_2019='15-2051.01', ONET_2019_NAME='Business Intelligence Analysts', CIP6='[]', CIP6_NAME='[]', CIP4='[]', CIP4_NAME='[]', CIP2='[]', CIP2_NAME='[]', SOC_2021_2='15-0000', SOC_2021_2_NAME='Computer and Mathematical Occupations', SOC_2021_3='15-2000', SOC_2021_3_NAME='Mathematical Science Occupations', SOC_2021_4='15-2050', SOC_2021_4_NAME='Data Scientists', SOC_2021_5='15-2051', SOC_2021_5_NAME='Data Scientists', LOT_CAREER_AREA=23, LOT_CAREER_AREA_NAME='Information Technology and Computer Science', LOT_OCCUPATION=231010, LOT_OCCUPATION_NAME='Business Intelligence Analyst', LOT_SPECIALIZED_OCCUPATION=23101012, LOT_SPECIALIZED_OCCUPATION_NAME='Oracle Consultant / Analyst', LOT_OCCUPATION_GROUP=2310, LOT_OCCUPATION_GROUP_NAME='Business Intelligence', LOT_V6_SPECIALIZED_OCCUPATION=23101012, LOT_V6_SPECIALIZED_OCCUPATION_NAME='Oracle Consultant / Analyst', LOT_V6_OCCUPATION=231010, LOT_V6_OCCUPATION_NAME='Business Intelligence Analyst', LOT_V6_OCCUPATION_GROUP=2310, LOT_V6_OCCUPATION_GROUP_NAME='Business Intelligence', LOT_V6_CAREER_AREA=23, LOT_V6_CAREER_AREA_NAME='Information Technology and Computer Science', SOC_2='15-0000', SOC_2_NAME='Computer and Mathematical Occupations', SOC_3='15-2000', SOC_3_NAME='Mathematical Science Occupations', SOC_4='15-2050', SOC_4_NAME='Data Scientists', SOC_5='15-2051', SOC_5_NAME='Data Scientists', LIGHTCAST_SECTORS=None, LIGHTCAST_SECTORS_NAME=None, NAICS_2022_2=56, NAICS_2022_2_NAME='Administrative and Support and Waste Management and Remediation Services', NAICS_2022_3=561, NAICS_2022_3_NAME='Administrative and Support Services', NAICS_2022_4=5613, NAICS_2022_4_NAME='Employment Services', NAICS_2022_5=56132, NAICS_2022_5_NAME='Temporary Help Services', NAICS_2022_6=561320, NAICS_2022_6_NAME='Temporary Help Services'), Row(ID='85318b12b3331fa490d32ad014379df01855c557', LAST_UPDATED_DATE='9/6/2024', LAST_UPDATED_TIMESTAMP=datetime.datetime(2024, 9, 6, 20, 32, 57, 352000), DUPLICATES=1, POSTED='6/2/2024', EXPIRED='7/7/2024', DURATION=35, SOURCE_TYPES='[\\n  \"Job Board\"\\n]', SOURCES='[\\n  \"dejobs.org\"\\n]', URL='[\\n  \"https://dejobs.org/dallas-tx/data-analyst/AB20D7C0DBB740F2BBF4F98CC806D12E/job/\",\\n  \"https://dejobs.org/dallas-tx/data-analyst/486581AFD4964ECD9DD36951AD84C0C5/job/\"\\n]', ACTIVE_URLS='[]', ACTIVE_SOURCES_INFO=None, TITLE_RAW='Data Analyst', BODY=\"Taking care of people is at the heart of everything we do, and we start by taking care of you, our valued colleague. A career at Sedgwick means experiencing our culture of caring. It means having flexibility and time for all the things that are important to you. It's an opportunity to do something meaningful, each and every day. It's having support for your mental, physical, financial and professional needs. It means sharpening your skills and growing your career. And it means working in an environment that celebrates diversity and is fair and inclusive.\\n\\nA career at Sedgwick is where passion meets purpose to make a positive impact on the world through the people and organizations we serve. If you are someone who is driven to make a difference, who enjoys a challenge and above all, if you're someone who cares, there's a place for you here. Join us and contribute to Sedgwick being a great place to work.\\n\\nGreat Place to Work\\n\\nMost Loved Workplace\\n\\nForbes Best-in-State Employer\\n\\nData Analyst\\n\\nPRIMARY PURPOSE To collect, analyze and report data; to be responsible for the data integrity; and to generate reports verifying and ensuring data integrity and accuracy.\\n\\nESSENTIAL FUNCTIONS and RESPONSIBILITIES\\n\\nCompiles data; prepares and distributes reports; and analyzes results.\\n\\nEnsures data integrity; develops and produces reports utilized in measuring data accuracy.\\n\\nMay assist in the completion of appropriate client set-up and maintenance (parameter) forms.\\n\\nSupports internal and external users including reports, installation, screen, etc.\\n\\nCreates exception reports to identify fields of incorrect data.\\n\\nGenerates custom reports for internal and external client.\\n\\nADDITIONAL FUNCTIONS and RESPONSIBILITIES\\n\\nPerforms other duties as assigned.\\n\\nSupports the organization's quality program(s).\\n\\nQUALIFICATIONS\\n\\nEducation & Licensing\\n\\nBachelor's degree from an accredited college or university preferred.\\n\\nExperience\\n\\nFive (5) years of related experience or equivalent combination of education and experience required. Two (2) years of query and report writing experience strongly preferred.\\n\\nSkills & Knowledge\\n\\nStrong knowledge of query and report writing\\n\\nExcellent oral and written communication, including presentation skills\\n\\nPC literate, including Microsoft Office products\\n\\nAnalytical and interpretive skills\\n\\nStrong organizational skills\\n\\nExcellent interpersonal skills\\n\\nExcellent negotiation skills\\n\\nAbility to meet or exceed Performance Competencies\\n\\nWORK ENVIRONMENT\\n\\nWhen applicable and appropriate, consideration will be given to reasonable accommodations.\\n\\nMental : Clear and conceptual thinking ability; excellent judgment, troubleshooting, problem solving, analysis, and discretion; ability to handle work-related stress; ability to handle multiple priorities simultaneously; and ability to meet deadlines\\n\\nPhysical : Computer keyboarding, travel as required\\n\\nAuditory/Visual : Hearing, vision and talking\\n\\nNOTE : Credit security clearance, confirmed via a background credit check, is required for this position.\\n\\nThe statements contained in this document are intended to describe the general nature and level of work being performed by a colleague assigned to this description. They are not intended to constitute a comprehensive list of functions, duties, or local variances. Management retains the discretion to add or to change the duties of the position at any time.\\n\\nSedgwick is an Equal Opportunity Employer and a Drug-Free Workplace.\\n\\nIf you're excited about this role but your experience doesn't align perfectly with every qualification in the job description, consider applying for it anyway! Sedgwick is building a diverse, equitable, and inclusive workplace and recognizes that each person possesses a unique combination of skills, knowledge, and experience. You may be just the right candidate for this or other roles.\\n\\nTaking care of people is at the heart of everything we do. Caring counts\\n\\nSedgwick is a leading global provider of technology-enabled risk, benefits and integrated business solutions. Every day, in every time zone, the most well-known and respected organizations place their trust in us to help their employees regain health and productivity, guide their consumers through the claims process, protect their brand and minimize business interruptions. Our more than 30,000 colleagues across 80 countries embrace our shared purpose and values as they demonstrate what it means to work for an organization committed to doing the right thing - one where caring counts. Watch this video to learn more about us. (https://www.youtube.com/watch?v=ywxedjBGSfA)\", MODELED_EXPIRED='6/10/2024', MODELED_DURATION=8, COMPANY=39063746, COMPANY_NAME='Sedgwick', COMPANY_RAW='Sedgwick', COMPANY_IS_STAFFING=False, EDUCATION_LEVELS='[\\n  2\\n]', EDUCATION_LEVELS_NAME='[\\n  \"Bachelor\\'s degree\"\\n]', MIN_EDULEVELS='Bachelor', MIN_EDULEVELS_NAME=\"Bachelor's degree\", MAX_EDULEVELS=None, MAX_EDULEVELS_NAME=None, EMPLOYMENT_TYPE=1, EMPLOYMENT_TYPE_NAME='Full-time (&gt; 32 hours)', MIN_YEARS_EXPERIENCE=5.0, MAX_YEARS_EXPERIENCE=None, IS_INTERNSHIP=False, SALARY=None, REMOTE_TYPE='Onsite', REMOTE_TYPE_NAME='[None]', ORIGINAL_PAY_PERIOD=None, SALARY_TO=None, SALARY_FROM=None, LOCATION='{\\n  \"lat\": 32.7766642,\\n  \"lon\": -96.7969879\\n}', CITY='RGFsbGFzLCBUWA==', CITY_NAME='Dallas, TX', COUNTY=48113, COUNTY_NAME='Dallas, TX', MSA=19100, MSA_NAME='Dallas-Fort Worth-Arlington, TX', STATE=48, STATE_NAME='Texas', COUNTY_OUTGOING=48113, COUNTY_NAME_OUTGOING='Dallas, TX', COUNTY_INCOMING=48113, COUNTY_NAME_INCOMING='Dallas, TX', MSA_OUTGOING=19100, MSA_NAME_OUTGOING='Dallas-Fort Worth-Arlington, TX', MSA_INCOMING=19100, MSA_NAME_INCOMING='Dallas-Fort Worth-Arlington, TX', NAICS2=52, NAICS2_NAME='Finance and Insurance', NAICS3=524, NAICS3_NAME='Insurance Carriers and Related Activities', NAICS4=5242, NAICS4_NAME='Agencies, Brokerages, and Other Insurance Related Activities', NAICS5=52429, NAICS5_NAME='Other Insurance Related Activities', NAICS6=524291, NAICS6_NAME='Claims Adjusting', TITLE='ET3037E0C947A02404', TITLE_NAME='Data Analysts', TITLE_CLEAN='data analyst', SKILLS='[\\n  \"KS1218W78FGVPVP2KXPX\",\\n  \"ESF3939CE1F80C10C327\",\\n  \"BGS1ADAA36DB65721AA3\",\\n  \"KS683TN76T77DQDVBZ1B\",\\n  \"KS1259D6L30YYG3XR3VL\",\\n  \"ES9BD12EB76B360E0E89\",\\n  \"KS1280B68GD79P4WMVYW\",\\n  \"KS4425C7820LCHZS7VGX\",\\n  \"KS120GV6C72JMSZKMTD7\",\\n  \"ES8B03DAD3B526316ED9\",\\n  \"KS126X663B21NB77ZHSP\",\\n  \"KS122P86NZFH1GP38G15\",\\n  \"KS126HY6YLTB9R7XJC4Z\"\\n]', SKILLS_NAME='[\\n  \"Management\",\\n  \"Exception Reporting\",\\n  \"Report Writing\",\\n  \"Security Clearance\",\\n  \"Interpersonal Communications\",\\n  \"Ability To Meet Deadlines\",\\n  \"Presentations\",\\n  \"Writing\",\\n  \"Data Analysis\",\\n  \"Organizational Skills\",\\n  \"Negotiation\",\\n  \"Data Integrity\",\\n  \"Microsoft Office\"\\n]', SPECIALIZED_SKILLS='[\\n  \"ESF3939CE1F80C10C327\",\\n  \"KS120GV6C72JMSZKMTD7\",\\n  \"KS122P86NZFH1GP38G15\"\\n]', SPECIALIZED_SKILLS_NAME='[\\n  \"Exception Reporting\",\\n  \"Data Analysis\",\\n  \"Data Integrity\"\\n]', CERTIFICATIONS='[\\n  \"KS683TN76T77DQDVBZ1B\"\\n]', CERTIFICATIONS_NAME='[\\n  \"Security Clearance\"\\n]', COMMON_SKILLS='[\\n  \"KS1218W78FGVPVP2KXPX\",\\n  \"BGS1ADAA36DB65721AA3\",\\n  \"KS1259D6L30YYG3XR3VL\",\\n  \"ES9BD12EB76B360E0E89\",\\n  \"KS1280B68GD79P4WMVYW\",\\n  \"KS4425C7820LCHZS7VGX\",\\n  \"ES8B03DAD3B526316ED9\",\\n  \"KS126X663B21NB77ZHSP\",\\n  \"KS126HY6YLTB9R7XJC4Z\"\\n]', COMMON_SKILLS_NAME='[\\n  \"Management\",\\n  \"Report Writing\",\\n  \"Interpersonal Communications\",\\n  \"Ability To Meet Deadlines\",\\n  \"Presentations\",\\n  \"Writing\",\\n  \"Organizational Skills\",\\n  \"Negotiation\",\\n  \"Microsoft Office\"\\n]', SOFTWARE_SKILLS='[\\n  \"KS126HY6YLTB9R7XJC4Z\"\\n]', SOFTWARE_SKILLS_NAME='[\\n  \"Microsoft Office\"\\n]', ONET='15-2051.01', ONET_NAME='Business Intelligence Analysts', ONET_2019='15-2051.01', ONET_2019_NAME='Business Intelligence Analysts', CIP6='[]', CIP6_NAME='[]', CIP4='[]', CIP4_NAME='[]', CIP2='[]', CIP2_NAME='[]', SOC_2021_2='15-0000', SOC_2021_2_NAME='Computer and Mathematical Occupations', SOC_2021_3='15-2000', SOC_2021_3_NAME='Mathematical Science Occupations', SOC_2021_4='15-2050', SOC_2021_4_NAME='Data Scientists', SOC_2021_5='15-2051', SOC_2021_5_NAME='Data Scientists', LOT_CAREER_AREA=23, LOT_CAREER_AREA_NAME='Information Technology and Computer Science', LOT_OCCUPATION=231113, LOT_OCCUPATION_NAME='Data / Data Mining Analyst', LOT_SPECIALIZED_OCCUPATION=23111310, LOT_SPECIALIZED_OCCUPATION_NAME='Data Analyst', LOT_OCCUPATION_GROUP=2311, LOT_OCCUPATION_GROUP_NAME='Data Analysis and Mathematics', LOT_V6_SPECIALIZED_OCCUPATION=23111310, LOT_V6_SPECIALIZED_OCCUPATION_NAME='Data Analyst', LOT_V6_OCCUPATION=231113, LOT_V6_OCCUPATION_NAME='Data / Data Mining Analyst', LOT_V6_OCCUPATION_GROUP=2311, LOT_V6_OCCUPATION_GROUP_NAME='Data Analysis and Mathematics', LOT_V6_CAREER_AREA=23, LOT_V6_CAREER_AREA_NAME='Information Technology and Computer Science', SOC_2='15-0000', SOC_2_NAME='Computer and Mathematical Occupations', SOC_3='15-2000', SOC_3_NAME='Mathematical Science Occupations', SOC_4='15-2050', SOC_4_NAME='Data Scientists', SOC_5='15-2051', SOC_5_NAME='Data Scientists', LIGHTCAST_SECTORS=None, LIGHTCAST_SECTORS_NAME=None, NAICS_2022_2=52, NAICS_2022_2_NAME='Finance and Insurance', NAICS_2022_3=524, NAICS_2022_3_NAME='Insurance Carriers and Related Activities', NAICS_2022_4=5242, NAICS_2022_4_NAME='Agencies, Brokerages, and Other Insurance Related Activities', NAICS_2022_5=52429, NAICS_2022_5_NAME='Other Insurance Related Activities', NAICS_2022_6=524291, NAICS_2022_6_NAME='Claims Adjusting'), Row(ID='1b5c3941e54a1889ef4f8ae55b401a550708a310', LAST_UPDATED_DATE='9/6/2024', LAST_UPDATED_TIMESTAMP=datetime.datetime(2024, 9, 6, 20, 32, 57, 352000), DUPLICATES=1, POSTED='6/2/2024', EXPIRED='7/20/2024', DURATION=48, SOURCE_TYPES='[\\n  \"Job Board\"\\n]', SOURCES='[\\n  \"disabledperson.com\",\\n  \"dejobs.org\"\\n]', URL='[\\n  \"https://www.disabledperson.com/jobs/59489810-sr-lead-data-mgmt-analyst-sas-product-owner\",\\n  \"https://dejobs.org/phoenix-az/sr-lead-data-mgmt-analyst-sas-product-owner/6A4BD3E7D6C749D2A255335632C587B2/job/\"\\n]', ACTIVE_URLS='[]', ACTIVE_SOURCES_INFO=None, TITLE_RAW='Sr. Lead Data Mgmt. Analyst - SAS Product Owner', BODY=\"About this role:\\n\\nWells Fargo is looking for a SAS Platform and Tools L2 Product Owner with a specialization in migrating from SAS 9 Grid to SAS Viya 4 on Google Cloud (SaaS). This key position involves leading the development and enhancement of our SAS-based analytics platform while orchestrating a seamless transition to the next-generation SAS Viya 4 environment.\\n\\nIn this role, you will:\\n\\nAct as an advisor to leadership to develop or influence objectives, plans, specifications, resources, and long-term goals for highly complex business and technical needs\\n\\nLead the strategy and resolution of highly complex and unique challenges requiring in-depth evaluation across multiple areas or the enterprise, delivering solutions that are long-term, large-scale and require vision, creativity, innovation, advanced analytical and inductive thinking\\n\\nProvide vision, direction, and expertise to senior leadership on implementing innovative and significant business solutions\\n\\nRecommend remediation of process or control gaps that align to management strategy\\n\\nStrategically engage with all levels of professionals and managers across the enterprise and serve as an expert advisor to leadership\\n\\nRepresent client in cross-functional groups to develop companywide data governance strategies\\n\\nPartner with groups companywide to coordinate and drive collaboration on solution design and remediation execution\\n\\nProduct Vision and Strategy:\\n\\nDefine and articulate a clear product vision and strategy for both SAS Platform and Tools and the migration to SAS Viya 4.\\n\\nCollaborate with stakeholders to align technical solutions with organizational goals.\\n\\nRoadmap Development:\\n\\nDevelop and maintain a comprehensive product roadmap for SAS Platform and Tools, prioritizing features and enhancements based on business value.\\n\\nPlan and execute the migration roadmap from SAS 9 Grid to SAS Viya 4, ensuring a phased and efficient transition.\\n\\nMigration Strategy: SAS 9 Grid to SAS Viya 4:\\n\\nAssess the existing SAS 9 Grid environment, identifying workloads, dependencies, and hardware configurations.\\n\\nDevelop a migration plan, including data migration, re-engineering SAS 9 Grid workloads, and establishing parallel operations for a smooth transition.\\n\\nCross-functional Collaboration:\\n\\nCollaborate with development teams, data scientists, and other stakeholders to ensure successful implementation of product features and migration processes.\\n\\nAct as a liaison between technical and non-technical teams, fostering a collaborative environment.\\n\\nRequirements Gathering:\\n\\nCollect and analyze user feedback, market trends, and competitive intelligence to inform product decisions.\\n\\nDefine detailed product requirements, user stories, and acceptance criteria for SAS Platform and the migration to SAS Viya 4.\\n\\nManage on-prem SAS products:\\n\\nEffectively manage BAU (Business As Usual) product backlog and priorities\\n\\nDrive Data Center Exit strategy for SAS products\\n\\nQuality Assurance:\\n\\nCoordinate with QA teams to define and execute test plans, ensuring the reliability and performance of both SAS Platform and SAS Viya 4.\\n\\nConduct thorough testing during the migration process to identify and rectify any issues.\\n\\nUser Training and Support:\\n\\nDevelop and deliver training programs for end-users on SAS Platform and Tools as well as SAS Viya 4.\\n\\nProvide ongoing support and troubleshooting assistance during and post-migration.\\n\\nMonitoring and Optimization:\\n\\nEstablish monitoring mechanisms for SAS Platform and Tools and SAS Viya 4, tracking performance and optimizing configurations.\\n\\nContinuously improve SAS Viya 4 configurations based on performance data.\\n\\nRequired Qualification\\n\\n7+ years of Data Management, Business Analysis, Analytics, or Project Management experience, or equivalent demonstrated through one or a combination of the following: work experience, training, military experience, education\\n\\n3+ years of experience in platform/tool operations, architecture and strategy\\n\\n1+ years of Agile experience\\n\\nDesired Qualification:\\n\\nExperience with Cloud Data Platforms\\n\\nPrior experience in migrating on-prem SAS to Cloud\\n\\nManaged SAS platform with operational responsibilities\\n\\nExperience with design of multi-tenant data architecture and its configuration spanning across both on-prem, cloud and hybrid environments\\n\\nExperience in data architecture, strategy, implementing user journeys within the data domain for large enterprise strength platforms.\\n\\nProven experience of leading development of products (data related), strong demonstration of managing SDLC and delivering outcomes.\\n\\nDemonstrate past work experience of organizing and enabling teams in a scaled Agile environment.\\n\\nGoogle Cloud certification is desired.\\n\\nExperience creating and implementing strategic plans and roadmaps at the executive level for enterprise-wide business initiatives\\n\\nJob Expectations:\\n\\nAbility to travel up to 10%\\n\\nThis position offers a hybrid work schedule\\n\\nWillingness to work on-site in one of the listed locations\\n\\nVisa sponsorship is not available for this position\\n\\nLocations: Charlotte, NC; Phoenix, AZ; Addison, TX; West Des Moines, IA\\n\\n401 S. Tryon St. Charlotte, NC\\n\\n1525 W WT Harris Blvd. Charlotte, NC\\n\\n11601 N Black Canyon Hwy. Phoenix, AZ\\n\\n5080 Spectrum Dr. Addison, TX\\n\\n800 S. Jordan Creek Pkwy. West Des Moines, IA\\n\\nNote: Job posting may come down early due to volume of applicants.\\n\\nPosting End Date:\\n\\n3 Jun 2024\\n\\n*Job posting may come down early due to volume of applicants.\\n\\nWe Value Diversity\\n\\nAt Wells Fargo, we believe in diversity, equity and inclusion in the workplace; accordingly, we welcome applications for employment from all qualified candidates, regardless of race, color, gender, national origin, religion, age, sexual orientation, gender identity, gender expression, genetic information, individuals with disabilities, pregnancy, marital status, status as a protected veteran or any other status protected by applicable law.\\n\\nEmployees support our focus on building strong customer relationships balanced with a strong risk mitigating and compliance-driven culture which firmly establishes those disciplines as critical to the success of our customers and company. They are accountable for execution of all applicable risk programs (Credit, Market, Financial Crimes, Operational, Regulatory Compliance), which includes effectively following and adhering to applicable Wells Fargo policies and procedures, appropriately fulfilling risk and compliance obligations, timely and effective escalation and remediation of issues, and making sound risk decisions. There is emphasis on proactive monitoring, governance, risk identification and escalation, as well as making sound risk decisions commensurate with the business unit's risk appetite and all risk and compliance program requirements.\\n\\nCandidates applying to job openings posted in US: All qualified applicants will receive consideration for employment without regard to race, color, religion, sex, sexual orientation, gender identity, national origin, disability, status as a protected veteran, or any other legally protected characteristic.\\n\\nCandidates applying to job openings posted in Canada: Applications for employment are encouraged from all qualified candidates, including women, persons with disabilities, aboriginal peoples and visible minorities. Accommodation for applicants with disabilities is available upon request in connection with the recruitment process.\\n\\nApplicants with Disabilities\\n\\nTo request a medical accommodation during the application or interview process, visit Disability Inclusion at Wells Fargo .\\n\\nDrug and Alcohol Policy\\n\\nWells Fargo maintains a drug free workplace. Please see our Drug and Alcohol Policy to learn more.\\n\\nCompany: WELLS FARGO BANK\\n\\nReq Number: R-372422-3\\n\\nUpdated: Sun Jun 02 04:15:06 UTC 2024\\n\\nLocation: PHOENIX,Arizona\", MODELED_EXPIRED='6/12/2024', MODELED_DURATION=10, COMPANY=37615159, COMPANY_NAME='Wells Fargo', COMPANY_RAW='Wells Fargo', COMPANY_IS_STAFFING=False, EDUCATION_LEVELS='[\\n  99\\n]', EDUCATION_LEVELS_NAME='[\\n  \"No Education Listed\"\\n]', MIN_EDULEVELS='Associate or lower', MIN_EDULEVELS_NAME='No Education Listed', MAX_EDULEVELS=None, MAX_EDULEVELS_NAME=None, EMPLOYMENT_TYPE=1, EMPLOYMENT_TYPE_NAME='Full-time (&gt; 32 hours)', MIN_YEARS_EXPERIENCE=3.0, MAX_YEARS_EXPERIENCE=None, IS_INTERNSHIP=False, SALARY=None, REMOTE_TYPE='Onsite', REMOTE_TYPE_NAME='[None]', ORIGINAL_PAY_PERIOD=None, SALARY_TO=None, SALARY_FROM=None, LOCATION='{\\n  \"lat\": 33.4483771,\\n  \"lon\": -112.0740373\\n}', CITY='UGhvZW5peCwgQVo=', CITY_NAME='Phoenix, AZ', COUNTY=4013, COUNTY_NAME='Maricopa, AZ', MSA=38060, MSA_NAME='Phoenix-Mesa-Chandler, AZ', STATE=4, STATE_NAME='Arizona', COUNTY_OUTGOING=4013, COUNTY_NAME_OUTGOING='Maricopa, AZ', COUNTY_INCOMING=4013, COUNTY_NAME_INCOMING='Maricopa, AZ', MSA_OUTGOING=38060, MSA_NAME_OUTGOING='Phoenix-Mesa-Chandler, AZ', MSA_INCOMING=38060, MSA_NAME_INCOMING='Phoenix-Mesa-Chandler, AZ', NAICS2=52, NAICS2_NAME='Finance and Insurance', NAICS3=522, NAICS3_NAME='Credit Intermediation and Related Activities', NAICS4=5221, NAICS4_NAME='Depository Credit Intermediation', NAICS5=52211, NAICS5_NAME='Commercial Banking', NAICS6=522110, NAICS6_NAME='Commercial Banking', TITLE='ET2114E0404BA30075', TITLE_NAME='Management Analysts', TITLE_CLEAN='sr lead data mgmt analyst sas product owner', SKILLS='[\\n  \"KS123QX62QYTC4JF38H8\",\\n  \"KS7G6NP6R6L1H1SKFTSY\",\\n  \"KS441PQ64HT13P34T8T5\",\\n  \"KS1218W78FGVPVP2KXPX\",\\n  \"KS1219261TYVPMGX8KVQ\",\\n  \"BGSBA798A49DA3AB544A\",\\n  \"KSRGLA2SD4T20RIP6ORS\",\\n  \"KS120B874P2P6BK1MQ0T\",\\n  \"ES4C039C261C048676A2\",\\n  \"ESB17C5AF46AFE08157D\",\\n  \"KS128DV723HFCBV6JTH1\",\\n  \"KS440726NL4QJRHCMR43\",\\n  \"ES29C56D2465C253FC1D\",\\n  \"KS4400X68616V0QJL5M8\",\\n  \"KS1218C6C8TX2Y1KRN37\",\\n  \"KS122PG64BT2BT6X15HF\",\\n  \"KS122NM6B8TWBGL2X18F\",\\n  \"ES20CECA4FF83ECE8196\",\\n  \"KS1265F71V3PY4KH0JW5\",\\n  \"KS1219D70RKFPH4CC8KN\",\\n  \"KS122HK6LN2MZHFY69GJ\",\\n  \"KS1253H61TTR1FZWSRH4\",\\n  \"KS124G66QWSYM012SWS5\",\\n  \"KS1284G6MK1552WHSZ32\",\\n  \"KS124JB619VXG6RQ810C\",\\n  \"KS441BJ6LNS1QCJHRMTW\",\\n  \"KSNX20VIRD1IZABQZI8U\",\\n  \"KS1282N6NQMZ95M1HJ7L\",\\n  \"KS1267F6MSPN366LX7ST\",\\n  \"KS127D361PF0FTXDZ7C4\",\\n  \"KS122PL6Y7WHFNZ54RQJ\",\\n  \"KS1226L6XYT1N27WRYJM\",\\n  \"ES6C7324B9377A38E0D5\",\\n  \"KS4409D76NW1S5LNCL18\",\\n  \"KS441K2756CXYXBG990G\",\\n  \"KS128866SHL94J005TTG\",\\n  \"KS1220G68PD5STH2DL2W\",\\n  \"KS122NW5YB08NCH9P98B\",\\n  \"ES7A5D0AD38AB0F9D6C6\",\\n  \"KS122P378DGNVX4NKQKN\",\\n  \"KS1226460LSTKGW59TDX\",\\n  \"KS127D36JHBK1S5F8NMB\",\\n  \"KS4403H60RHC7598V94K\",\\n  \"ESC7869CF7378283E0AA\",\\n  \"KSUMUUUWH2LGA7IKVOX7\"\\n]', SKILLS_NAME='[\\n  \"Exit Strategies\",\\n  \"Reliability\",\\n  \"User Story\",\\n  \"Management\",\\n  \"Strategic Planning\",\\n  \"Hardware Configuration Management\",\\n  \"On Prem\",\\n  \"Agile Methodology\",\\n  \"Solution Design\",\\n  \"Advanced Analytics\",\\n  \"Reengineering\",\\n  \"Safety Assurance\",\\n  \"Cross-Functional Collaboration\",\\n  \"Requirements Elicitation\",\\n  \"Business Analysis\",\\n  \"Data Management\",\\n  \"Data Architecture\",\\n  \"Influencing Skills\",\\n  \"Market Trend\",\\n  \"Business Valuation\",\\n  \"Creativity\",\\n  \"Innovation\",\\n  \"Governance\",\\n  \"Systems Development Life Cycle\",\\n  \"Leadership\",\\n  \"Test Planning\",\\n  \"Multi-Tenant Cloud Environments\",\\n  \"Scrum (Software Development)\",\\n  \"Project Management\",\\n  \"Operations\",\\n  \"Data Migration\",\\n  \"Regulatory Compliance\",\\n  \"Product Roadmaps\",\\n  \"SAS (Software)\",\\n  \"Troubleshooting (Problem Solving)\",\\n  \"Quality Assurance\",\\n  \"Software As A Service (SaaS)\",\\n  \"Data Domain\",\\n  \"Product Requirements\",\\n  \"Data Governance\",\\n  \"Competitive Intelligence\",\\n  \"Operations Architecture\",\\n  \"Risk Appetite\",\\n  \"Google Cloud Platform (GCP)\",\\n  \"User Feedback\"\\n]', SPECIALIZED_SKILLS='[\\n  \"KS123QX62QYTC4JF38H8\",\\n  \"KS441PQ64HT13P34T8T5\",\\n  \"BGSBA798A49DA3AB544A\",\\n  \"KSRGLA2SD4T20RIP6ORS\",\\n  \"KS120B874P2P6BK1MQ0T\",\\n  \"ES4C039C261C048676A2\",\\n  \"ESB17C5AF46AFE08157D\",\\n  \"KS128DV723HFCBV6JTH1\",\\n  \"ES29C56D2465C253FC1D\",\\n  \"KS4400X68616V0QJL5M8\",\\n  \"KS1218C6C8TX2Y1KRN37\",\\n  \"KS122PG64BT2BT6X15HF\",\\n  \"KS122NM6B8TWBGL2X18F\",\\n  \"KS1265F71V3PY4KH0JW5\",\\n  \"KS1219D70RKFPH4CC8KN\",\\n  \"KS1284G6MK1552WHSZ32\",\\n  \"KS441BJ6LNS1QCJHRMTW\",\\n  \"KSNX20VIRD1IZABQZI8U\",\\n  \"KS1282N6NQMZ95M1HJ7L\",\\n  \"KS1267F6MSPN366LX7ST\",\\n  \"KS122PL6Y7WHFNZ54RQJ\",\\n  \"KS1226L6XYT1N27WRYJM\",\\n  \"ES6C7324B9377A38E0D5\",\\n  \"KS4409D76NW1S5LNCL18\",\\n  \"KS1220G68PD5STH2DL2W\",\\n  \"KS122NW5YB08NCH9P98B\",\\n  \"ES7A5D0AD38AB0F9D6C6\",\\n  \"KS122P378DGNVX4NKQKN\",\\n  \"KS1226460LSTKGW59TDX\",\\n  \"KS127D36JHBK1S5F8NMB\",\\n  \"KS4403H60RHC7598V94K\",\\n  \"ESC7869CF7378283E0AA\",\\n  \"KSUMUUUWH2LGA7IKVOX7\"\\n]', SPECIALIZED_SKILLS_NAME='[\\n  \"Exit Strategies\",\\n  \"User Story\",\\n  \"Hardware Configuration Management\",\\n  \"On Prem\",\\n  \"Agile Methodology\",\\n  \"Solution Design\",\\n  \"Advanced Analytics\",\\n  \"Reengineering\",\\n  \"Cross-Functional Collaboration\",\\n  \"Requirements Elicitation\",\\n  \"Business Analysis\",\\n  \"Data Management\",\\n  \"Data Architecture\",\\n  \"Market Trend\",\\n  \"Business Valuation\",\\n  \"Systems Development Life Cycle\",\\n  \"Test Planning\",\\n  \"Multi-Tenant Cloud Environments\",\\n  \"Scrum (Software Development)\",\\n  \"Project Management\",\\n  \"Data Migration\",\\n  \"Regulatory Compliance\",\\n  \"Product Roadmaps\",\\n  \"SAS (Software)\",\\n  \"Software As A Service (SaaS)\",\\n  \"Data Domain\",\\n  \"Product Requirements\",\\n  \"Data Governance\",\\n  \"Competitive Intelligence\",\\n  \"Operations Architecture\",\\n  \"Risk Appetite\",\\n  \"Google Cloud Platform (GCP)\",\\n  \"User Feedback\"\\n]', CERTIFICATIONS='[]', CERTIFICATIONS_NAME='[]', COMMON_SKILLS='[\\n  \"KS7G6NP6R6L1H1SKFTSY\",\\n  \"KS1218W78FGVPVP2KXPX\",\\n  \"KS1219261TYVPMGX8KVQ\",\\n  \"KS440726NL4QJRHCMR43\",\\n  \"ES20CECA4FF83ECE8196\",\\n  \"KS122HK6LN2MZHFY69GJ\",\\n  \"KS1253H61TTR1FZWSRH4\",\\n  \"KS124G66QWSYM012SWS5\",\\n  \"KS124JB619VXG6RQ810C\",\\n  \"KS127D361PF0FTXDZ7C4\",\\n  \"KS441K2756CXYXBG990G\",\\n  \"KS128866SHL94J005TTG\"\\n]', COMMON_SKILLS_NAME='[\\n  \"Reliability\",\\n  \"Management\",\\n  \"Strategic Planning\",\\n  \"Safety Assurance\",\\n  \"Influencing Skills\",\\n  \"Creativity\",\\n  \"Innovation\",\\n  \"Governance\",\\n  \"Leadership\",\\n  \"Operations\",\\n  \"Troubleshooting (Problem Solving)\",\\n  \"Quality Assurance\"\\n]', SOFTWARE_SKILLS='[\\n  \"KS4409D76NW1S5LNCL18\",\\n  \"ESC7869CF7378283E0AA\"\\n]', SOFTWARE_SKILLS_NAME='[\\n  \"SAS (Software)\",\\n  \"Google Cloud Platform (GCP)\"\\n]', ONET='15-2051.01', ONET_NAME='Business Intelligence Analysts', ONET_2019='15-2051.01', ONET_2019_NAME='Business Intelligence Analysts', CIP6='[]', CIP6_NAME='[]', CIP4='[]', CIP4_NAME='[]', CIP2='[]', CIP2_NAME='[]', SOC_2021_2='15-0000', SOC_2021_2_NAME='Computer and Mathematical Occupations', SOC_2021_3='15-2000', SOC_2021_3_NAME='Mathematical Science Occupations', SOC_2021_4='15-2050', SOC_2021_4_NAME='Data Scientists', SOC_2021_5='15-2051', SOC_2021_5_NAME='Data Scientists', LOT_CAREER_AREA=23, LOT_CAREER_AREA_NAME='Information Technology and Computer Science', LOT_OCCUPATION=231113, LOT_OCCUPATION_NAME='Data / Data Mining Analyst', LOT_SPECIALIZED_OCCUPATION=23111310, LOT_SPECIALIZED_OCCUPATION_NAME='Data Analyst', LOT_OCCUPATION_GROUP=2311, LOT_OCCUPATION_GROUP_NAME='Data Analysis and Mathematics', LOT_V6_SPECIALIZED_OCCUPATION=23111310, LOT_V6_SPECIALIZED_OCCUPATION_NAME='Data Analyst', LOT_V6_OCCUPATION=231113, LOT_V6_OCCUPATION_NAME='Data / Data Mining Analyst', LOT_V6_OCCUPATION_GROUP=2311, LOT_V6_OCCUPATION_GROUP_NAME='Data Analysis and Mathematics', LOT_V6_CAREER_AREA=23, LOT_V6_CAREER_AREA_NAME='Information Technology and Computer Science', SOC_2='15-0000', SOC_2_NAME='Computer and Mathematical Occupations', SOC_3='15-2000', SOC_3_NAME='Mathematical Science Occupations', SOC_4='15-2050', SOC_4_NAME='Data Scientists', SOC_5='15-2051', SOC_5_NAME='Data Scientists', LIGHTCAST_SECTORS='[\\n  6\\n]', LIGHTCAST_SECTORS_NAME='[\\n  \"Data Privacy/Protection\"\\n]', NAICS_2022_2=52, NAICS_2022_2_NAME='Finance and Insurance', NAICS_2022_3=522, NAICS_2022_3_NAME='Credit Intermediation and Related Activities', NAICS_2022_4=5221, NAICS_2022_4_NAME='Depository Credit Intermediation', NAICS_2022_5=52211, NAICS_2022_5_NAME='Commercial Banking', NAICS_2022_6=522110, NAICS_2022_6_NAME='Commercial Banking'), Row(ID='cb5ca25f02bdf25c13edfede7931508bfd9e858f', LAST_UPDATED_DATE='6/19/2024', LAST_UPDATED_TIMESTAMP=datetime.datetime(2024, 6, 19, 7, 0), DUPLICATES=0, POSTED='6/2/2024', EXPIRED='6/17/2024', DURATION=15, SOURCE_TYPES='[\\n  \"FreeJobBoard\"\\n]', SOURCES='[\\n  \"craigslist.org\"\\n]', URL='[\\n  \"https://modesto.craigslist.org/sls/7747584269.html\"\\n]', ACTIVE_URLS='[]', ACTIVE_SOURCES_INFO=None, TITLE_RAW='Comisiones de $1000 - $3000 por semana... Comiensa Rapido!!!', BODY='Comisiones de $1000 - $3000 por semana... Comiensa Rapido!!! (MODESTO AND SURROUNDING AREAS) LH/GM compensation: COMMISSION EASY SALES employment type: job title: SALES Comisiones de $1000 - $3000 por semana... Comiensa Rapido!!! No tengas miedo de Comisiones este trabajo es facil nada mas tienes que aprenderlo con nuestro excelente entrenamiento y empiesas aser dinero Rapido. Company / Compania Lincoln Heritage Life Insurance Co. More than 60 years in business! TENEMOS MAS DE 60 ANOS EN NEGOCIO!!!!! Agency / Agencia GOLDEN MEMORIAL AGENCY #1 Final Expense Agency in the Country Que vendemos? Seguro de vida: solo un Producto Gastos Finales Planes Funerales\" What do we Sell? Small whole life policies Necesito Experiencia? No se ocupa nada de experiencia, Solo ganas de Aprender ! Do I need Experience? No. All you need is work ethic to grow with a Winning Team!!! SI No tienes seguro social No te preocupes, si noms tienes un ITIN es suficiente para sacar la licencia del estado. Cuesta el entrenamiento? No !!! Entrenamiento es Gratis . Tenemos Videos EN INGLES Y ESPANOL................. Online Training..............In person Class Training...........&.......Field Training with a Manager. Que se ocupa para tener xito y hacer dinero ? Presntate cada da con una actitud positiva y listo para trabajar al 100. 100% comisin How much money can you make in a year? Our Agents are making from $35,000 to $150,000 Annually, Managers are making from $200,000 to over 1 Million Annually. What makes our Final Expense Company a Great Company to work for? 1. We get paid in 24hrs. Sell a plan and submit a application with a 1st payment Check, you get paid within 24hrs direct deposit into your bank account. 2. We give coverage to 98% of people regardless of their Health conditions. 3. We pay out claims within 24 to 48hrs 4. We give coverage to people who Do Not have a social security number. 4. We have a Accidental, Death & Dismemberment Rider for $5.00 ($100,000 additional coverage) 5. We have a Child Rider $4 per child $10,000 coverage 6. Our Clients receive a Free Membership to Funeral Consumer Guardian Society, which helps the customer plan their final wishes and Funeral exactly as they choose. (This Free membership to FCGS can save them up to $4000 on a Traditional Funeral and $600 on a Cremation) Down below are the Qualifications to work on our Team Full Time & Part Time Must Follow our Training System. Give me a call and leave me a brief message. Gracias!!!!! Thanks!!!! IF YOU HAVE MORE QUESTIONS TEXT OR CALL ME SO I CAN EMAIL YOU MORE INFORMATION TO GET YOU STARTED. CALL OR TEXT ME TODAY 800-307-1269 Please leave a message!!! Llmame Hoy !! 800-307-1269 Porfavor deja su mensaje!!! CALL OR TEXT ME TODAY 800-307-1269 Please leave a message!!! Llmame Hoy !! 800-307-1269 Porfavor deja su mensaje!!! Oscar 800-307-1269 Porfavor deja su mensaje Principals only. Recruiters, please don\\'t contact this job poster. post id: 7747584269 updated: [ ]', MODELED_EXPIRED='6/17/2024', MODELED_DURATION=15, COMPANY=0, COMPANY_NAME='Unclassified', COMPANY_RAW='LH/GM', COMPANY_IS_STAFFING=False, EDUCATION_LEVELS='[\\n  99\\n]', EDUCATION_LEVELS_NAME='[\\n  \"No Education Listed\"\\n]', MIN_EDULEVELS='Associate or lower', MIN_EDULEVELS_NAME='No Education Listed', MAX_EDULEVELS=None, MAX_EDULEVELS_NAME=None, EMPLOYMENT_TYPE=3, EMPLOYMENT_TYPE_NAME='Part-time / full-time', MIN_YEARS_EXPERIENCE=None, MAX_YEARS_EXPERIENCE=None, IS_INTERNSHIP=False, SALARY=92500.0, REMOTE_TYPE='Onsite', REMOTE_TYPE_NAME='[None]', ORIGINAL_PAY_PERIOD='year', SALARY_TO=150000.0, SALARY_FROM=35000.0, LOCATION='{\\n  \"lat\": 37.6392595,\\n  \"lon\": -120.9970014\\n}', CITY='TW9kZXN0bywgQ0E=', CITY_NAME='Modesto, CA', COUNTY=6099, COUNTY_NAME='Stanislaus, CA', MSA=33700, MSA_NAME='Modesto, CA', STATE=6, STATE_NAME='California', COUNTY_OUTGOING=6099, COUNTY_NAME_OUTGOING='Stanislaus, CA', COUNTY_INCOMING=6099, COUNTY_NAME_INCOMING='Stanislaus, CA', MSA_OUTGOING=33700, MSA_NAME_OUTGOING='Modesto, CA', MSA_INCOMING=33700, MSA_NAME_INCOMING='Modesto, CA', NAICS2=99, NAICS2_NAME='Unclassified Industry', NAICS3=999, NAICS3_NAME='Unclassified Industry', NAICS4=9999, NAICS4_NAME='Unclassified Industry', NAICS5=99999, NAICS5_NAME='Unclassified Industry', NAICS6=999999, NAICS6_NAME='Unclassified Industry', TITLE='ET0000000000000000', TITLE_NAME='Unclassified', TITLE_CLEAN='comisiones de por semana comiensa rapido', SKILLS='[]', SKILLS_NAME='[]', SPECIALIZED_SKILLS='[]', SPECIALIZED_SKILLS_NAME='[]', CERTIFICATIONS='[]', CERTIFICATIONS_NAME='[]', COMMON_SKILLS='[]', COMMON_SKILLS_NAME='[]', SOFTWARE_SKILLS='[]', SOFTWARE_SKILLS_NAME='[]', ONET='15-2051.01', ONET_NAME='Business Intelligence Analysts', ONET_2019='15-2051.01', ONET_2019_NAME='Business Intelligence Analysts', CIP6='[]', CIP6_NAME='[]', CIP4='[]', CIP4_NAME='[]', CIP2='[]', CIP2_NAME='[]', SOC_2021_2='15-0000', SOC_2021_2_NAME='Computer and Mathematical Occupations', SOC_2021_3='15-2000', SOC_2021_3_NAME='Mathematical Science Occupations', SOC_2021_4='15-2050', SOC_2021_4_NAME='Data Scientists', SOC_2021_5='15-2051', SOC_2021_5_NAME='Data Scientists', LOT_CAREER_AREA=23, LOT_CAREER_AREA_NAME='Information Technology and Computer Science', LOT_OCCUPATION=231010, LOT_OCCUPATION_NAME='Business Intelligence Analyst', LOT_SPECIALIZED_OCCUPATION=23101012, LOT_SPECIALIZED_OCCUPATION_NAME='Oracle Consultant / Analyst', LOT_OCCUPATION_GROUP=2310, LOT_OCCUPATION_GROUP_NAME='Business Intelligence', LOT_V6_SPECIALIZED_OCCUPATION=23101012, LOT_V6_SPECIALIZED_OCCUPATION_NAME='Oracle Consultant / Analyst', LOT_V6_OCCUPATION=231010, LOT_V6_OCCUPATION_NAME='Business Intelligence Analyst', LOT_V6_OCCUPATION_GROUP=2310, LOT_V6_OCCUPATION_GROUP_NAME='Business Intelligence', LOT_V6_CAREER_AREA=23, LOT_V6_CAREER_AREA_NAME='Information Technology and Computer Science', SOC_2='15-0000', SOC_2_NAME='Computer and Mathematical Occupations', SOC_3='15-2000', SOC_3_NAME='Mathematical Science Occupations', SOC_4='15-2050', SOC_4_NAME='Data Scientists', SOC_5='15-2051', SOC_5_NAME='Data Scientists', LIGHTCAST_SECTORS=None, LIGHTCAST_SECTORS_NAME=None, NAICS_2022_2=99, NAICS_2022_2_NAME='Unclassified Industry', NAICS_2022_3=999, NAICS_2022_3_NAME='Unclassified Industry', NAICS_2022_4=9999, NAICS_2022_4_NAME='Unclassified Industry', NAICS_2022_5=99999, NAICS_2022_5_NAME='Unclassified Industry', NAICS_2022_6=999999, NAICS_2022_6_NAME='Unclassified Industry')]\n\n\n                                                                                \n\n\n\n\nCode\n# Select comprehensive columns for skill gap analysis\nskill_gap_data = df[[\n    # Job identifiers\n    'TITLE_NAME',\n    \n    # Skills columns\n    'SKILLS_NAME',\n    'SPECIALIZED_SKILLS_NAME',\n    'SOFTWARE_SKILLS_NAME',\n    'COMMON_SKILLS_NAME',\n    \n    # Education requirements\n    'EDUCATION_LEVELS_NAME',\n    'MIN_EDULEVELS',\n    'MIN_EDULEVELS_NAME',\n    \n    # Experience & Employment\n    'EMPLOYMENT_TYPE',\n    'EMPLOYMENT_TYPE_NAME',\n    'MIN_YEARS_EXPERIENCE',\n    'MAX_YEARS_EXPERIENCE',\n    'IS_INTERNSHIP',\n    \n    # Compensation\n    'SALARY',\n    'SALARY_FROM',\n    'SALARY_TO',\n    'ORIGINAL_PAY_PERIOD',\n    \n    # Remote & Location\n    'REMOTE_TYPE',\n    'REMOTE_TYPE_NAME',\n    'LOCATION',\n    'CITY',\n    'CITY_NAME',\n    'COUNTY',\n    'COUNTY_NAME',\n    'MSA',\n    'MSA_NAME',\n    'STATE',\n    'STATE_NAME',\n    \n    # Geographic mobility (outgoing/incoming)\n    'COUNTY_OUTGOING',\n    'COUNTY_NAME_OUTGOING',\n    'COUNTY_INCOMING',\n    'COUNTY_NAME_INCOMING',\n    'MSA_OUTGOING',\n    'MSA_NAME_OUTGOING',\n    'MSA_INCOMING',\n    'MSA_NAME_INCOMING',\n    \n    # Company & Industry\n    'COMPANY_NAME',\n    'NAICS2',\n    'NAICS2_NAME',\n    'NAICS3',\n    'NAICS3_NAME',\n    'NAICS4',\n    'NAICS4_NAME',\n    'NAICS5',\n    'NAICS5_NAME',\n    'NAICS6',\n    'NAICS6_NAME',\n    \n    # Occupation classification\n    'ONET',\n    'ONET_NAME',\n    'ONET_2019_NAME',\n    'SOC_2021_5_NAME'\n]]\n\n# Display dataset info\n\n\n# Preview the data\nprint(skill_gap_data.head(3))\n\n\n[Row(TITLE_NAME='Enterprise Analysts', SKILLS_NAME='[\\n  \"Merchandising\",\\n  \"Mathematics\",\\n  \"Presentations\",\\n  \"Predictive Modeling\",\\n  \"Data Modeling\",\\n  \"Advanced Analytics\",\\n  \"Data Extraction\",\\n  \"Statistical Analysis\",\\n  \"Data Mining\",\\n  \"Business Analysis\",\\n  \"Finance\",\\n  \"Algorithms\",\\n  \"Statistics\",\\n  \"SQL (Programming Language)\",\\n  \"Report Writing\",\\n  \"Ad Hoc Reporting\",\\n  \"Power BI\",\\n  \"Relationship Building\",\\n  \"Economics\",\\n  \"Business Administration\"\\n]', SPECIALIZED_SKILLS_NAME='[\\n  \"Merchandising\",\\n  \"Predictive Modeling\",\\n  \"Data Modeling\",\\n  \"Advanced Analytics\",\\n  \"Data Extraction\",\\n  \"Statistical Analysis\",\\n  \"Data Mining\",\\n  \"Business Analysis\",\\n  \"Finance\",\\n  \"Algorithms\",\\n  \"Statistics\",\\n  \"SQL (Programming Language)\",\\n  \"Ad Hoc Reporting\",\\n  \"Power BI\",\\n  \"Economics\"\\n]', SOFTWARE_SKILLS_NAME='[\\n  \"SQL (Programming Language)\",\\n  \"Power BI\"\\n]', COMMON_SKILLS_NAME='[\\n  \"Mathematics\",\\n  \"Presentations\",\\n  \"Report Writing\",\\n  \"Relationship Building\",\\n  \"Business Administration\"\\n]', EDUCATION_LEVELS_NAME='[\\n  \"Bachelor\\'s degree\"\\n]', MIN_EDULEVELS='Bachelor', MIN_EDULEVELS_NAME=\"Bachelor's degree\", EMPLOYMENT_TYPE=1, EMPLOYMENT_TYPE_NAME='Full-time (&gt; 32 hours)', MIN_YEARS_EXPERIENCE=2.0, MAX_YEARS_EXPERIENCE=2.0, IS_INTERNSHIP=False, SALARY=None, SALARY_FROM=None, SALARY_TO=None, ORIGINAL_PAY_PERIOD=None, REMOTE_TYPE='Onsite', REMOTE_TYPE_NAME='[None]', LOCATION='{\\n  \"lat\": 33.20763,\\n  \"lon\": -92.6662674\\n}', CITY='RWwgRG9yYWRvLCBBUg==', CITY_NAME='El Dorado, AR', COUNTY=5139, COUNTY_NAME='Union, AR', MSA=20980, MSA_NAME='El Dorado, AR', STATE=5, STATE_NAME='Arkansas', COUNTY_OUTGOING=5139, COUNTY_NAME_OUTGOING='Union, AR', COUNTY_INCOMING=5139, COUNTY_NAME_INCOMING='Union, AR', MSA_OUTGOING=20980, MSA_NAME_OUTGOING='El Dorado, AR', MSA_INCOMING=20980, MSA_NAME_INCOMING='El Dorado, AR', COMPANY_NAME='Murphy USA', NAICS2=44, NAICS2_NAME='Retail Trade', NAICS3=441, NAICS3_NAME='Motor Vehicle and Parts Dealers', NAICS4=4413, NAICS4_NAME='Automotive Parts, Accessories, and Tire Retailers', NAICS5=44133, NAICS5_NAME='Automotive Parts and Accessories Retailers', NAICS6=441330, NAICS6_NAME='Automotive Parts and Accessories Retailers', ONET='15-2051.01', ONET_NAME='Business Intelligence Analysts', ONET_2019_NAME='Business Intelligence Analysts', SOC_2021_5_NAME='Data Scientists'), Row(TITLE_NAME='Oracle Consultants', SKILLS_NAME='[\\n  \"Procurement\",\\n  \"Financial Statements\",\\n  \"Oracle Business Intelligence (BI) / OBIA\",\\n  \"Oracle E-Business Suite\",\\n  \"PL/SQL\",\\n  \"Supply Chain\",\\n  \"Business Intelligence\",\\n  \"Oracle Fusion Middleware\",\\n  \"Project Accounting\"\\n]', SPECIALIZED_SKILLS_NAME='[\\n  \"Procurement\",\\n  \"Financial Statements\",\\n  \"Oracle Business Intelligence (BI) / OBIA\",\\n  \"Oracle E-Business Suite\",\\n  \"PL/SQL\",\\n  \"Supply Chain\",\\n  \"Business Intelligence\",\\n  \"Oracle Fusion Middleware\",\\n  \"Project Accounting\"\\n]', SOFTWARE_SKILLS_NAME='[\\n  \"Oracle Business Intelligence (BI) / OBIA\",\\n  \"Oracle E-Business Suite\",\\n  \"PL/SQL\",\\n  \"Oracle Fusion Middleware\"\\n]', COMMON_SKILLS_NAME='[]', EDUCATION_LEVELS_NAME='[\\n  \"No Education Listed\"\\n]', MIN_EDULEVELS='Associate or lower', MIN_EDULEVELS_NAME='No Education Listed', EMPLOYMENT_TYPE=1, EMPLOYMENT_TYPE_NAME='Full-time (&gt; 32 hours)', MIN_YEARS_EXPERIENCE=3.0, MAX_YEARS_EXPERIENCE=3.0, IS_INTERNSHIP=False, SALARY=None, SALARY_FROM=None, SALARY_TO=None, ORIGINAL_PAY_PERIOD=None, REMOTE_TYPE='Remote', REMOTE_TYPE_NAME='Remote', LOCATION='{\\n  \"lat\": 44.3106241,\\n  \"lon\": -69.7794897\\n}', CITY='QXVndXN0YSwgTUU=', CITY_NAME='Augusta, ME', COUNTY=23011, COUNTY_NAME='Kennebec, ME', MSA=12300, MSA_NAME='Augusta-Waterville, ME', STATE=23, STATE_NAME='Maine', COUNTY_OUTGOING=23011, COUNTY_NAME_OUTGOING='Kennebec, ME', COUNTY_INCOMING=23011, COUNTY_NAME_INCOMING='Kennebec, ME', MSA_OUTGOING=12300, MSA_NAME_OUTGOING='Augusta-Waterville, ME', MSA_INCOMING=12300, MSA_NAME_INCOMING='Augusta-Waterville, ME', COMPANY_NAME='Smx Corporation Limited', NAICS2=56, NAICS2_NAME='Administrative and Support and Waste Management and Remediation Services', NAICS3=561, NAICS3_NAME='Administrative and Support Services', NAICS4=5613, NAICS4_NAME='Employment Services', NAICS5=56132, NAICS5_NAME='Temporary Help Services', NAICS6=561320, NAICS6_NAME='Temporary Help Services', ONET='15-2051.01', ONET_NAME='Business Intelligence Analysts', ONET_2019_NAME='Business Intelligence Analysts', SOC_2021_5_NAME='Data Scientists'), Row(TITLE_NAME='Data Analysts', SKILLS_NAME='[\\n  \"Management\",\\n  \"Exception Reporting\",\\n  \"Report Writing\",\\n  \"Security Clearance\",\\n  \"Interpersonal Communications\",\\n  \"Ability To Meet Deadlines\",\\n  \"Presentations\",\\n  \"Writing\",\\n  \"Data Analysis\",\\n  \"Organizational Skills\",\\n  \"Negotiation\",\\n  \"Data Integrity\",\\n  \"Microsoft Office\"\\n]', SPECIALIZED_SKILLS_NAME='[\\n  \"Exception Reporting\",\\n  \"Data Analysis\",\\n  \"Data Integrity\"\\n]', SOFTWARE_SKILLS_NAME='[\\n  \"Microsoft Office\"\\n]', COMMON_SKILLS_NAME='[\\n  \"Management\",\\n  \"Report Writing\",\\n  \"Interpersonal Communications\",\\n  \"Ability To Meet Deadlines\",\\n  \"Presentations\",\\n  \"Writing\",\\n  \"Organizational Skills\",\\n  \"Negotiation\",\\n  \"Microsoft Office\"\\n]', EDUCATION_LEVELS_NAME='[\\n  \"Bachelor\\'s degree\"\\n]', MIN_EDULEVELS='Bachelor', MIN_EDULEVELS_NAME=\"Bachelor's degree\", EMPLOYMENT_TYPE=1, EMPLOYMENT_TYPE_NAME='Full-time (&gt; 32 hours)', MIN_YEARS_EXPERIENCE=5.0, MAX_YEARS_EXPERIENCE=None, IS_INTERNSHIP=False, SALARY=None, SALARY_FROM=None, SALARY_TO=None, ORIGINAL_PAY_PERIOD=None, REMOTE_TYPE='Onsite', REMOTE_TYPE_NAME='[None]', LOCATION='{\\n  \"lat\": 32.7766642,\\n  \"lon\": -96.7969879\\n}', CITY='RGFsbGFzLCBUWA==', CITY_NAME='Dallas, TX', COUNTY=48113, COUNTY_NAME='Dallas, TX', MSA=19100, MSA_NAME='Dallas-Fort Worth-Arlington, TX', STATE=48, STATE_NAME='Texas', COUNTY_OUTGOING=48113, COUNTY_NAME_OUTGOING='Dallas, TX', COUNTY_INCOMING=48113, COUNTY_NAME_INCOMING='Dallas, TX', MSA_OUTGOING=19100, MSA_NAME_OUTGOING='Dallas-Fort Worth-Arlington, TX', MSA_INCOMING=19100, MSA_NAME_INCOMING='Dallas-Fort Worth-Arlington, TX', COMPANY_NAME='Sedgwick', NAICS2=52, NAICS2_NAME='Finance and Insurance', NAICS3=524, NAICS3_NAME='Insurance Carriers and Related Activities', NAICS4=5242, NAICS4_NAME='Agencies, Brokerages, and Other Insurance Related Activities', NAICS5=52429, NAICS5_NAME='Other Insurance Related Activities', NAICS6=524291, NAICS6_NAME='Claims Adjusting', ONET='15-2051.01', ONET_NAME='Business Intelligence Analysts', ONET_2019_NAME='Business Intelligence Analysts', SOC_2021_5_NAME='Data Scientists')]\n\n\n\n\nCode\nskill_gap_data = skill_gap_data.toPandas()\nprint(skill_gap_data.shape)\nskill_gap_data.head()\n\n\n[Stage 3:&gt;                                                          (0 + 2) / 2]                                                                                \n\n\n(72498, 51)\n\n\n\n\n\n\n\n\n\nTITLE_NAME\nSKILLS_NAME\nSPECIALIZED_SKILLS_NAME\nSOFTWARE_SKILLS_NAME\nCOMMON_SKILLS_NAME\nEDUCATION_LEVELS_NAME\nMIN_EDULEVELS\nMIN_EDULEVELS_NAME\nEMPLOYMENT_TYPE\nEMPLOYMENT_TYPE_NAME\n...\nNAICS4\nNAICS4_NAME\nNAICS5\nNAICS5_NAME\nNAICS6\nNAICS6_NAME\nONET\nONET_NAME\nONET_2019_NAME\nSOC_2021_5_NAME\n\n\n\n\n0\nEnterprise Analysts\n[\\n \"Merchandising\",\\n \"Mathematics\",\\n \"Pr...\n[\\n \"Merchandising\",\\n \"Predictive Modeling\"...\n[\\n \"SQL (Programming Language)\",\\n \"Power B...\n[\\n \"Mathematics\",\\n \"Presentations\",\\n \"Re...\n[\\n \"Bachelor's degree\"\\n]\nBachelor\nBachelor's degree\n1.0\nFull-time (&gt; 32 hours)\n...\n4413.0\nAutomotive Parts, Accessories, and Tire Retailers\n44133.0\nAutomotive Parts and Accessories Retailers\n441330.0\nAutomotive Parts and Accessories Retailers\n15-2051.01\nBusiness Intelligence Analysts\nBusiness Intelligence Analysts\nData Scientists\n\n\n1\nOracle Consultants\n[\\n \"Procurement\",\\n \"Financial Statements\",...\n[\\n \"Procurement\",\\n \"Financial Statements\",...\n[\\n \"Oracle Business Intelligence (BI) / OBIA...\n[]\n[\\n \"No Education Listed\"\\n]\nAssociate or lower\nNo Education Listed\n1.0\nFull-time (&gt; 32 hours)\n...\n5613.0\nEmployment Services\n56132.0\nTemporary Help Services\n561320.0\nTemporary Help Services\n15-2051.01\nBusiness Intelligence Analysts\nBusiness Intelligence Analysts\nData Scientists\n\n\n2\nData Analysts\n[\\n \"Management\",\\n \"Exception Reporting\",\\n...\n[\\n \"Exception Reporting\",\\n \"Data Analysis\"...\n[\\n \"Microsoft Office\"\\n]\n[\\n \"Management\",\\n \"Report Writing\",\\n \"In...\n[\\n \"Bachelor's degree\"\\n]\nBachelor\nBachelor's degree\n1.0\nFull-time (&gt; 32 hours)\n...\n5242.0\nAgencies, Brokerages, and Other Insurance Rela...\n52429.0\nOther Insurance Related Activities\n524291.0\nClaims Adjusting\n15-2051.01\nBusiness Intelligence Analysts\nBusiness Intelligence Analysts\nData Scientists\n\n\n3\nManagement Analysts\n[\\n \"Exit Strategies\",\\n \"Reliability\",\\n \"...\n[\\n \"Exit Strategies\",\\n \"User Story\",\\n \"H...\n[\\n \"SAS (Software)\",\\n \"Google Cloud Platfo...\n[\\n \"Reliability\",\\n \"Management\",\\n \"Strat...\n[\\n \"No Education Listed\"\\n]\nAssociate or lower\nNo Education Listed\n1.0\nFull-time (&gt; 32 hours)\n...\n5221.0\nDepository Credit Intermediation\n52211.0\nCommercial Banking\n522110.0\nCommercial Banking\n15-2051.01\nBusiness Intelligence Analysts\nBusiness Intelligence Analysts\nData Scientists\n\n\n4\nUnclassified\n[]\n[]\n[]\n[]\n[\\n \"No Education Listed\"\\n]\nAssociate or lower\nNo Education Listed\n3.0\nPart-time / full-time\n...\n9999.0\nUnclassified Industry\n99999.0\nUnclassified Industry\n999999.0\nUnclassified Industry\n15-2051.01\nBusiness Intelligence Analysts\nBusiness Intelligence Analysts\nData Scientists\n\n\n\n\n5 rows × 51 columns\n\n\n\n\n\nCode\n# Parse the skills column (convert string to list)\nskill_gap_data['SKILLS_LIST'] = skill_gap_data['SKILLS_NAME'].apply(\n    lambda x: json.loads(x) if pd.notna(x) else []\n)\n\n# Get all skills from all jobs\nall_skills = []\nfor skills in skill_gap_data['SKILLS_LIST']:\n    all_skills.extend(skills)\n\n# Count how often each skill appears\nskill_counts = Counter(all_skills)\n\n# Get top 20 skills\ntop_50_skills = pd.DataFrame(\n    skill_counts.most_common(50), \n    columns=['Skill', 'Number_of_Jobs']\n)\n\nprint(\"\\n=== TOP 50 MOST DEMANDED SKILLS ===\")\nprint(top_50_skills)\n\n\n\n=== TOP 50 MOST DEMANDED SKILLS ===\n                                       Skill  Number_of_Jobs\n0                              Communication           31661\n1                              Data Analysis           28515\n2                                 Management           24631\n3                 SQL (Programming Language)           21733\n4                            Problem Solving           18522\n5                                 Leadership           17561\n6                           Computer Science           17287\n7                                 Operations           14767\n8                         Project Management           13711\n9                           Business Process           13278\n10                     Business Requirements           13035\n11                           Microsoft Excel           12826\n12                                   Finance           12438\n13             Python (Programming Language)           12253\n14                          SAP Applications           12123\n15                           Detail Oriented           11987\n16                             Presentations           11890\n17                                 Dashboard           11856\n18  Tableau (Business Intelligence Software)           11781\n19                                  Planning           11578\n20                                   Writing           11274\n21                                  Power BI           10850\n22                     Business Intelligence           10423\n23                                  Research           10038\n24                                Consulting            9533\n25                         Agile Methodology            9131\n26                                Innovation            9000\n27         Troubleshooting (Problem Solving)            8996\n28                    Information Technology            8852\n29                           Data Management            8691\n30                          Customer Service            8603\n31                           Decision Making            8528\n32                                Statistics            8343\n33                                     Sales            8246\n34                             Data Modeling            8244\n35                        Data Visualization            8124\n36                       Workflow Management            7860\n37                         Analytical Skills            7757\n38                              Data Quality            7711\n39                          Microsoft Office            7564\n40              Interpersonal Communications            7398\n41                      Microsoft PowerPoint            7161\n42                              Data Science            6882\n43                               Mathematics            6823\n44                                Governance            6785\n45                          Data Warehousing            6634\n46                                Automation            6559\n47                        Influencing Skills            6471\n48                       Process Improvement            6123\n49                  R (Programming Language)            6104\n\n\n\n\nCode\n# Parse the skills column (convert string to list)\nskill_gap_data['SOFTWARE_SKILLS_LIST'] = skill_gap_data['SOFTWARE_SKILLS_NAME'].apply(\n    lambda x: json.loads(x) if pd.notna(x) else []\n)\n\n# Get all skills from all jobs\nall_skills = []\nfor skills in skill_gap_data['SOFTWARE_SKILLS_LIST']:\n    all_skills.extend(skills)\n\n# Count how often each skill appears\nskill_counts = Counter(all_skills)\n\n# Get top 20 skills\ntop_50_skills = pd.DataFrame(\n    skill_counts.most_common(50), \n    columns=['Skill', 'Number_of_Jobs']\n)\n\nprint(\"\\n=== TOP 50 MOST DEMANDED SOFTWARE SKILLS ===\")\nprint(top_50_skills)\n\n\n\n=== TOP 50 MOST DEMANDED SOFTWARE SKILLS ===\n                                               Skill  Number_of_Jobs\n0                         SQL (Programming Language)           21733\n1                                    Microsoft Excel           12826\n2                      Python (Programming Language)           12253\n3                                   SAP Applications           12123\n4                                          Dashboard           11856\n5           Tableau (Business Intelligence Software)           11781\n6                                           Power BI           10850\n7                                   Microsoft Office            7564\n8                               Microsoft PowerPoint            7161\n9                           R (Programming Language)            6104\n10                                   Microsoft Azure            4759\n11                               Amazon Web Services            4692\n12                                      Oracle Cloud            4053\n13                                    SAS (Software)            3539\n14           Application Programming Interface (API)            3509\n15                                  Microsoft Access            3247\n16                              Relational Databases            3155\n17                                        Salesforce            2838\n18                       Java (Programming Language)            2632\n19                                 Microsoft Outlook            2437\n20                                   Microsoft Visio            2372\n21                                              JIRA            2341\n22                                           SAP ERP            2203\n23                                       SAP S/4HANA            2100\n24                              Microsoft SharePoint            1961\n25                                   Reporting Tools            1915\n26                 JavaScript (Programming Language)            1822\n27                           Oracle E-Business Suite            1815\n28                                    Microsoft Word            1719\n29                             Microsoft SQL Servers            1711\n30                                           Alteryx            1686\n31  Advanced Business Application Programming (ABAP)            1618\n32                          Order Management Systems            1525\n33                                      Spreadsheets            1517\n34                   Enterprise Application Software            1469\n35                       Business Intelligence Tools            1464\n36             Oracle Human Capital Management (HCM)            1451\n37                  Extensible Markup Language (XML)            1442\n38     The Open Group Architecture Framework (TOGAF)            1432\n39                                        Databricks            1428\n40                        SAP Sales And Distribution            1425\n41                                            PL/SQL            1369\n42                          Oracle Fusion Middleware            1367\n43                                     Apache Hadoop            1350\n44                                        ServiceNow            1336\n45                     Visual Basic For Applications            1239\n46                       Google Cloud Platform (GCP)            1237\n47                                      Apache Spark            1225\n48                     SQL Server Reporting Services            1194\n49            SQL Server Integration Services (SSIS)            1166\n\n\n\n\nCode\n# ONLY use the skills from your df_team\nteam_skills = df_skills.columns.tolist()  # ['Python', 'SQL', 'Machine Learning', 'Cloud Computing']\n\nprint(f\"\\nYour team's skills: {team_skills}\")\n\n# Map job posting variations to your skills\nskill_variations = {\n    'Python': ['Python', 'Python (Programming Language)', 'Python Scripting'],\n    'SQL': ['SQL', 'SQL (Programming Language)', 'MySQL', 'PostgreSQL', 'SQL Server'],\n    'Machine Learning': ['Machine Learning', 'Deep Learning', 'ML', 'Predictive Modeling', \n                         'Data Mining', 'Neural Networks'],\n    'Cloud Computing': ['Cloud Computing', 'AWS', 'Azure', 'GCP', 'Google Cloud Platform (GCP)',\n                        'Amazon Web Services', 'Microsoft Azure', 'Cloud Services']\n}\n\n# Check if team has each top skill\ndef team_has_skill(job_skill):\n    \"\"\"Check if any of your 4 skills matches the job skill\"\"\"\n    for team_skill in team_skills:\n        variations = skill_variations.get(team_skill, [team_skill])\n        for variation in variations:\n            if variation.lower() in job_skill.lower() or job_skill.lower() in variation.lower():\n                return f'✓ YES ({team_skill})'\n    return '✗ NO'\n\ntop_50_skills['Team_Has_It'] = top_50_skills['Skill'].apply(team_has_skill)\n\nprint(\"\\n=== DO YOU HAVE THESE TOP 50 SOFTWARE SKILLS? ===\")\nprint(top_50_skills)\n\n\n\nYour team's skills: ['Python', 'SQL', 'Machine Learning', 'Cloud Computing']\n\n=== DO YOU HAVE THESE TOP 50 SOFTWARE SKILLS? ===\n                                               Skill  Number_of_Jobs  \\\n0                         SQL (Programming Language)           21733   \n1                                    Microsoft Excel           12826   \n2                      Python (Programming Language)           12253   \n3                                   SAP Applications           12123   \n4                                          Dashboard           11856   \n5           Tableau (Business Intelligence Software)           11781   \n6                                           Power BI           10850   \n7                                   Microsoft Office            7564   \n8                               Microsoft PowerPoint            7161   \n9                           R (Programming Language)            6104   \n10                                   Microsoft Azure            4759   \n11                               Amazon Web Services            4692   \n12                                      Oracle Cloud            4053   \n13                                    SAS (Software)            3539   \n14           Application Programming Interface (API)            3509   \n15                                  Microsoft Access            3247   \n16                              Relational Databases            3155   \n17                                        Salesforce            2838   \n18                       Java (Programming Language)            2632   \n19                                 Microsoft Outlook            2437   \n20                                   Microsoft Visio            2372   \n21                                              JIRA            2341   \n22                                           SAP ERP            2203   \n23                                       SAP S/4HANA            2100   \n24                              Microsoft SharePoint            1961   \n25                                   Reporting Tools            1915   \n26                 JavaScript (Programming Language)            1822   \n27                           Oracle E-Business Suite            1815   \n28                                    Microsoft Word            1719   \n29                             Microsoft SQL Servers            1711   \n30                                           Alteryx            1686   \n31  Advanced Business Application Programming (ABAP)            1618   \n32                          Order Management Systems            1525   \n33                                      Spreadsheets            1517   \n34                   Enterprise Application Software            1469   \n35                       Business Intelligence Tools            1464   \n36             Oracle Human Capital Management (HCM)            1451   \n37                  Extensible Markup Language (XML)            1442   \n38     The Open Group Architecture Framework (TOGAF)            1432   \n39                                        Databricks            1428   \n40                        SAP Sales And Distribution            1425   \n41                                            PL/SQL            1369   \n42                          Oracle Fusion Middleware            1367   \n43                                     Apache Hadoop            1350   \n44                                        ServiceNow            1336   \n45                     Visual Basic For Applications            1239   \n46                       Google Cloud Platform (GCP)            1237   \n47                                      Apache Spark            1225   \n48                     SQL Server Reporting Services            1194   \n49            SQL Server Integration Services (SSIS)            1166   \n\n                 Team_Has_It  \n0                ✓ YES (SQL)  \n1                       ✗ NO  \n2             ✓ YES (Python)  \n3                       ✗ NO  \n4                       ✗ NO  \n5                       ✗ NO  \n6                       ✗ NO  \n7                       ✗ NO  \n8                       ✗ NO  \n9                       ✗ NO  \n10   ✓ YES (Cloud Computing)  \n11   ✓ YES (Cloud Computing)  \n12                      ✗ NO  \n13                      ✗ NO  \n14                      ✗ NO  \n15                      ✗ NO  \n16                      ✗ NO  \n17                      ✗ NO  \n18                      ✗ NO  \n19                      ✗ NO  \n20                      ✗ NO  \n21                      ✗ NO  \n22                      ✗ NO  \n23                      ✗ NO  \n24                      ✗ NO  \n25                      ✗ NO  \n26                      ✗ NO  \n27                      ✗ NO  \n28                      ✗ NO  \n29               ✓ YES (SQL)  \n30                      ✗ NO  \n31                      ✗ NO  \n32                      ✗ NO  \n33                      ✗ NO  \n34                      ✗ NO  \n35                      ✗ NO  \n36                      ✗ NO  \n37  ✓ YES (Machine Learning)  \n38                      ✗ NO  \n39                      ✗ NO  \n40                      ✗ NO  \n41               ✓ YES (SQL)  \n42                      ✗ NO  \n43                      ✗ NO  \n44                      ✗ NO  \n45                      ✗ NO  \n46   ✓ YES (Cloud Computing)  \n47                      ✗ NO  \n48               ✓ YES (SQL)  \n49               ✓ YES (SQL)  \n\n\n\n\nCode\n# Top 15 for maximum readability\ntop_15_skills = top_50_skills.head(15)\n\ncolors = ['#4CAF50' if '✓ YES' in has_it else '#FF5252' \n          for has_it in top_15_skills['Team_Has_It']]\n\nplt.figure(figsize=(12, 7))\n\nbars = plt.barh(range(len(top_15_skills)), \n                top_15_skills['Number_of_Jobs'], \n                color=colors,\n                edgecolor='black',\n                linewidth=0.7,\n                alpha=0.8)\n\nplt.yticks(range(len(top_15_skills)), top_15_skills['Skill'], fontsize=12)\nplt.xlabel('Number of Jobs', fontsize=13, fontweight='bold')\nplt.title('Top 15 Most In-Demand Software Skills', \n          fontsize=17, fontweight='bold', pad=20)\n\n# Add value labels\nfor i, (bar, value) in enumerate(zip(bars, top_15_skills['Number_of_Jobs'])):\n    plt.text(value + 300, i, f'{value:,}', \n             va='center', fontsize=11, fontweight='bold')\n\n# Legend\nfrom matplotlib.patches import Patch\nlegend_elements = [\n    Patch(facecolor='#4CAF50', label='✅ Team Has This'),\n    Patch(facecolor='#FF5252', label='❌ Need to Learn')\n]\nplt.legend(handles=legend_elements, loc='lower right', fontsize=12)\n\nplt.grid(axis='x', alpha=0.3, linestyle='--')\nplt.gca().invert_yaxis()\nplt.tight_layout()\nplt.savefig('top_15_software_skills.png', dpi=300, bbox_inches='tight')\nplt.show()\n\nprint(\"\\n✅ Chart saved as: top_15_software_skills.png\")\n\n\n/tmp/ipykernel_4259/2287073121.py:36: UserWarning:\n\nGlyph 9989 (\\N{WHITE HEAVY CHECK MARK}) missing from font(s) DejaVu Sans.\n\n/tmp/ipykernel_4259/2287073121.py:36: UserWarning:\n\nGlyph 10060 (\\N{CROSS MARK}) missing from font(s) DejaVu Sans.\n\n/tmp/ipykernel_4259/2287073121.py:37: UserWarning:\n\nGlyph 9989 (\\N{WHITE HEAVY CHECK MARK}) missing from font(s) DejaVu Sans.\n\n/tmp/ipykernel_4259/2287073121.py:37: UserWarning:\n\nGlyph 10060 (\\N{CROSS MARK}) missing from font(s) DejaVu Sans.\n\n/home/ubuntu/assignment-02-t-primero/.venv/lib/python3.12/site-packages/IPython/core/pylabtools.py:170: UserWarning:\n\nGlyph 9989 (\\N{WHITE HEAVY CHECK MARK}) missing from font(s) DejaVu Sans.\n\n/home/ubuntu/assignment-02-t-primero/.venv/lib/python3.12/site-packages/IPython/core/pylabtools.py:170: UserWarning:\n\nGlyph 10060 (\\N{CROSS MARK}) missing from font(s) DejaVu Sans.\n\n\n\n\n\n\n\n\n\n\n\n✅ Chart saved as: top_15_software_skills.png\n\n\n\n\nCode\n# Get the top 50 software skills results (from your previous output)\n# Assuming top_50_skills is your dataframe from the previous analysis\nteam_avg = df_skills.mean()\n\n# Add team's average proficiency level\ndef get_team_proficiency(skill_match):\n    \"\"\"Extract proficiency level if team has the skill\"\"\"\n    if '✓ YES' in skill_match:\n        # Extract skill name from \"✓ YES (Skill Name)\"\n        team_skill = skill_match.split('(')[1].split(')')[0]\n        if team_skill in team_avg.index:\n            return team_avg[team_skill]\n    return 0  # No proficiency if team doesn't have it\n\ntop_50_skills['Team_Proficiency'] = top_50_skills['Team_Has_It'].apply(get_team_proficiency)\n\n# Add proficiency labels\ndef proficiency_label(score):\n    if score == 0:\n        return \"No Knowledge\"\n    elif score &lt; 2:\n        return \"Beginner\"\n    elif score &lt; 3:\n        return \"Basic\"\n    elif score &lt; 4:\n        return \"Intermediate\"\n    elif score &lt; 5:\n        return \"Advanced\"\n    else:\n        return \"Expert\"\n\ntop_50_skills['Proficiency_Level'] = top_50_skills['Team_Proficiency'].apply(proficiency_label)\n\nprint(\"\\n=== TOP 50 SKILLS WITH YOUR PROFICIENCY RATINGS ===\")\nprint(top_50_skills[['Skill', 'Number_of_Jobs', 'Team_Proficiency', 'Proficiency_Level']])\n\n\n\n=== TOP 50 SKILLS WITH YOUR PROFICIENCY RATINGS ===\n                                               Skill  Number_of_Jobs  \\\n0                         SQL (Programming Language)           21733   \n1                                    Microsoft Excel           12826   \n2                      Python (Programming Language)           12253   \n3                                   SAP Applications           12123   \n4                                          Dashboard           11856   \n5           Tableau (Business Intelligence Software)           11781   \n6                                           Power BI           10850   \n7                                   Microsoft Office            7564   \n8                               Microsoft PowerPoint            7161   \n9                           R (Programming Language)            6104   \n10                                   Microsoft Azure            4759   \n11                               Amazon Web Services            4692   \n12                                      Oracle Cloud            4053   \n13                                    SAS (Software)            3539   \n14           Application Programming Interface (API)            3509   \n15                                  Microsoft Access            3247   \n16                              Relational Databases            3155   \n17                                        Salesforce            2838   \n18                       Java (Programming Language)            2632   \n19                                 Microsoft Outlook            2437   \n20                                   Microsoft Visio            2372   \n21                                              JIRA            2341   \n22                                           SAP ERP            2203   \n23                                       SAP S/4HANA            2100   \n24                              Microsoft SharePoint            1961   \n25                                   Reporting Tools            1915   \n26                 JavaScript (Programming Language)            1822   \n27                           Oracle E-Business Suite            1815   \n28                                    Microsoft Word            1719   \n29                             Microsoft SQL Servers            1711   \n30                                           Alteryx            1686   \n31  Advanced Business Application Programming (ABAP)            1618   \n32                          Order Management Systems            1525   \n33                                      Spreadsheets            1517   \n34                   Enterprise Application Software            1469   \n35                       Business Intelligence Tools            1464   \n36             Oracle Human Capital Management (HCM)            1451   \n37                  Extensible Markup Language (XML)            1442   \n38     The Open Group Architecture Framework (TOGAF)            1432   \n39                                        Databricks            1428   \n40                        SAP Sales And Distribution            1425   \n41                                            PL/SQL            1369   \n42                          Oracle Fusion Middleware            1367   \n43                                     Apache Hadoop            1350   \n44                                        ServiceNow            1336   \n45                     Visual Basic For Applications            1239   \n46                       Google Cloud Platform (GCP)            1237   \n47                                      Apache Spark            1225   \n48                     SQL Server Reporting Services            1194   \n49            SQL Server Integration Services (SSIS)            1166   \n\n    Team_Proficiency Proficiency_Level  \n0               3.00      Intermediate  \n1               0.00      No Knowledge  \n2               3.00      Intermediate  \n3               0.00      No Knowledge  \n4               0.00      No Knowledge  \n5               0.00      No Knowledge  \n6               0.00      No Knowledge  \n7               0.00      No Knowledge  \n8               0.00      No Knowledge  \n9               0.00      No Knowledge  \n10              2.75             Basic  \n11              2.75             Basic  \n12              0.00      No Knowledge  \n13              0.00      No Knowledge  \n14              0.00      No Knowledge  \n15              0.00      No Knowledge  \n16              0.00      No Knowledge  \n17              0.00      No Knowledge  \n18              0.00      No Knowledge  \n19              0.00      No Knowledge  \n20              0.00      No Knowledge  \n21              0.00      No Knowledge  \n22              0.00      No Knowledge  \n23              0.00      No Knowledge  \n24              0.00      No Knowledge  \n25              0.00      No Knowledge  \n26              0.00      No Knowledge  \n27              0.00      No Knowledge  \n28              0.00      No Knowledge  \n29              3.00      Intermediate  \n30              0.00      No Knowledge  \n31              0.00      No Knowledge  \n32              0.00      No Knowledge  \n33              0.00      No Knowledge  \n34              0.00      No Knowledge  \n35              0.00      No Knowledge  \n36              0.00      No Knowledge  \n37              2.75             Basic  \n38              0.00      No Knowledge  \n39              0.00      No Knowledge  \n40              0.00      No Knowledge  \n41              3.00      Intermediate  \n42              0.00      No Knowledge  \n43              0.00      No Knowledge  \n44              0.00      No Knowledge  \n45              0.00      No Knowledge  \n46              2.75             Basic  \n47              0.00      No Knowledge  \n48              3.00      Intermediate  \n49              3.00      Intermediate  \n\n\n\n\nCode\n# Calculate how \"ready\" you are based on both having the skill AND proficiency\ntop_50_skills['Readiness_Score'] = top_50_skills['Team_Proficiency'] / 5 * 100\n\n# Market demand importance (normalize to 100)\nmax_demand = top_50_skills['Number_of_Jobs'].max()\ntop_50_skills['Market_Importance'] = (top_50_skills['Number_of_Jobs'] / max_demand) * 100\n\n# Gap Score: negative = you're behind, positive = you're ahead\ntop_50_skills['Gap_Score'] = top_50_skills['Readiness_Score'] - top_50_skills['Market_Importance']\n\nprint(\"\\n=== SKILL GAP ANALYSIS (Top 20) ===\")\nanalysis_df = top_50_skills[['Skill', 'Market_Importance', 'Readiness_Score', 'Gap_Score']].head(20)\nprint(analysis_df)\n\n\n\n=== SKILL GAP ANALYSIS (Top 20) ===\n                                       Skill  Market_Importance  \\\n0                 SQL (Programming Language)         100.000000   \n1                            Microsoft Excel          59.016243   \n2              Python (Programming Language)          56.379699   \n3                           SAP Applications          55.781530   \n4                                  Dashboard          54.552984   \n5   Tableau (Business Intelligence Software)          54.207887   \n6                                   Power BI          49.924079   \n7                           Microsoft Office          34.804215   \n8                       Microsoft PowerPoint          32.949892   \n9                   R (Programming Language)          28.086320   \n10                           Microsoft Azure          21.897575   \n11                       Amazon Web Services          21.589288   \n12                              Oracle Cloud          18.649059   \n13                            SAS (Software)          16.283992   \n14   Application Programming Interface (API)          16.145953   \n15                          Microsoft Access          14.940413   \n16                      Relational Databases          14.517094   \n17                                Salesforce          13.058482   \n18               Java (Programming Language)          12.110615   \n19                         Microsoft Outlook          11.213362   \n\n    Readiness_Score  Gap_Score  \n0              60.0 -40.000000  \n1               0.0 -59.016243  \n2              60.0   3.620301  \n3               0.0 -55.781530  \n4               0.0 -54.552984  \n5               0.0 -54.207887  \n6               0.0 -49.924079  \n7               0.0 -34.804215  \n8               0.0 -32.949892  \n9               0.0 -28.086320  \n10             55.0  33.102425  \n11             55.0  33.410712  \n12              0.0 -18.649059  \n13              0.0 -16.283992  \n14              0.0 -16.145953  \n15              0.0 -14.940413  \n16              0.0 -14.517094  \n17              0.0 -13.058482  \n18              0.0 -12.110615  \n19              0.0 -11.213362  \n\n\n\n\nCode\n# Create a comparison visualization\nfig, axes = plt.subplots(2, 2, figsize=(16, 12))\n\n# 1. Skills you have - compare proficiency to demand\nskills_you_have = top_50_skills[top_50_skills['Team_Proficiency'] &gt; 0].head(10)\n\nax1 = axes[0, 0]\nx = np.arange(len(skills_you_have))\nwidth = 0.35\n\nbars1 = ax1.barh(x - width/2, skills_you_have['Market_Importance'], width, \n                 label='Market Importance', color='coral', alpha=0.8)\nbars2 = ax1.barh(x + width/2, skills_you_have['Readiness_Score'], width, \n                 label='Your Readiness', color='skyblue', alpha=0.8)\n\nax1.set_yticks(x)\nax1.set_yticklabels(skills_you_have['Skill'], fontsize=9)\nax1.set_xlabel('Score (0-100)')\nax1.set_title('Skills You Have: Market Demand vs Your Proficiency', fontweight='bold')\nax1.legend()\nax1.invert_yaxis()\n\n# 2. Team proficiency heatmap\nax2 = axes[0, 1]\nsns.heatmap(df_skills.T, annot=True, fmt='.0f', cmap='RdYlGn', vmin=1, vmax=5, \n            ax=ax2, cbar_kws={'label': 'Proficiency (1-5)'})\nax2.set_title('Team Member Proficiency Levels', fontweight='bold')\nax2.set_xlabel('Team Member')\nax2.set_ylabel('Skill')\n\n# 3. Top missing skills by market demand\nmissing_skills = top_50_skills[top_50_skills['Team_Proficiency'] == 0].head(15)\n\nax3 = axes[1, 0]\nsns.barplot(data=missing_skills, y='Skill', x='Number_of_Jobs', \n            palette='Reds_r', ax=ax3)\nax3.set_title('Top 15 Skills You Need to Learn', fontweight='bold')\nax3.set_xlabel('Number of Jobs Requiring This Skill')\n\n# 4. Gap analysis scatter plot\nax4 = axes[1, 1]\ncolors = ['red' if gap &lt; -20 else 'orange' if gap &lt; 0 else 'green' \n          for gap in top_50_skills['Gap_Score'].head(20)]\n\nax4.scatter(top_50_skills['Market_Importance'].head(20), \n           top_50_skills['Readiness_Score'].head(20),\n           s=top_50_skills['Number_of_Jobs'].head(20)/50,\n           c=colors, alpha=0.6)\n\n# Add diagonal line (perfect match)\nmax_val = max(top_50_skills['Market_Importance'].max(), \n              top_50_skills['Readiness_Score'].max())\nax4.plot([0, max_val], [0, max_val], 'k--', alpha=0.3, label='Perfect Match')\n\nax4.set_xlabel('Market Importance')\nax4.set_ylabel('Your Readiness Score')\nax4.set_title('Gap Analysis: Are You Ready for Market Demand?', fontweight='bold')\nax4.legend(['Perfect Match', 'Below line = Need to improve'])\nax4.grid(True, alpha=0.3)\n\nplt.tight_layout()\nplt.show()\n\n\n/tmp/ipykernel_4259/904824765.py:35: FutureWarning:\n\n\n\nPassing `palette` without assigning `hue` is deprecated and will be removed in v0.14.0. Assign the `y` variable to `hue` and set `legend=False` for the same effect.\n\n\n\n\n\n\n\n\n\n\n\n\n\nCode\n# Function to create individual analysis (FOCUSED VERSION)\ndef analyze_individual(person_name, person_skills, top_50_skills):\n    \"\"\"Analyze only the 4 specific skills being tracked\"\"\"\n    \n    print(\"\\n\" + \"=\"*80)\n    print(f\"📊 INDIVIDUAL ANALYSIS: {person_name.upper()}\")\n    print(\"=\"*80)\n    \n    # Get person's proficiency for each skill\n    def get_person_proficiency(skill_match):\n        \"\"\"Get this person's proficiency if they have the skill\"\"\"\n        if '✓ YES' in skill_match:\n            team_skill = skill_match.split('(')[1].split(')')[0]\n            if team_skill in person_skills.index:\n                return person_skills[team_skill]\n        return 0\n    \n    # Create individual dataframe\n    individual_df = top_50_skills.copy()\n    individual_df[f'{person_name}_Proficiency'] = individual_df['Team_Has_It'].apply(get_person_proficiency)\n    \n    # Calculate scores\n    individual_df[f'{person_name}_Readiness'] = (individual_df[f'{person_name}_Proficiency'] / 5) * 100\n    max_demand = individual_df['Number_of_Jobs'].max()\n    individual_df['Market_Importance'] = (individual_df['Number_of_Jobs'] / max_demand) * 100\n    individual_df[f'{person_name}_Gap'] = individual_df[f'{person_name}_Readiness'] - individual_df['Market_Importance']\n    \n    # 1. Current Skills Summary\n    print(f\"\\n🎯 {person_name}'s Current Skill Levels:\")\n    for skill, level in person_skills.items():\n        proficiency = ['Beginner', 'Basic', 'Intermediate', 'Advanced', 'Expert']\n        status = '✅ Job-Ready' if level &gt;= 4 else '⚠️ Needs Work'\n        print(f\"  • {skill}: {level}/5 ({proficiency[int(level)-1]}) {status}\")\n    \n    # 2. Average proficiency across the 4 tracked skills\n    avg_proficiency = person_skills.mean()\n    job_ready_count = (person_skills &gt;= 4).sum()\n    \n    print(f\"\\n📊 Summary of Your 4 Focus Skills:\")\n    print(f\"  • Job-Ready Skills (4+): {job_ready_count}/4\")\n    print(f\"  • Average proficiency: {avg_proficiency:.1f}/5\")\n    \n    # 3. Strengths (Skills at 4+)\n    print(f\"\\n💪 {person_name}'s STRENGTHS (Skills at 4+ level):\")\n    strengths = person_skills[person_skills &gt;= 4]\n    if len(strengths) &gt; 0:\n        for skill, level in strengths.items():\n            # Find market demand for this skill\n            skill_rows = individual_df[individual_df['Team_Has_It'].str.contains(skill, na=False, case=False)]\n            jobs = skill_rows['Number_of_Jobs'].iloc[0] if len(skill_rows) &gt; 0 else 0\n            print(f\"  ✅ {skill}: {level}/5 → Opens access to {jobs:,} jobs\")\n    else:\n        print(f\"  None yet (no skills at 4+)\")\n        print(f\"  💡 Focus on getting at least one skill to 4+ for job-readiness\")\n    \n    # 4. Skills needing improvement\n    print(f\"\\n📚 {person_name} SHOULD IMPROVE (Skills below 4):\")\n    to_improve = person_skills[person_skills &lt; 4]\n    if len(to_improve) &gt; 0:\n        for skill, level in to_improve.items():\n            target = 4\n            improvement_needed = target - level\n            \n            # Find market demand\n            skill_rows = individual_df[individual_df['Team_Has_It'].str.contains(skill, na=False, case=False)]\n            jobs = skill_rows['Number_of_Jobs'].iloc[0] if len(skill_rows) &gt; 0 else 0\n            \n            print(f\"  ⚠️ {skill}: {level}/5 → Target: {target}/5 (improve by {improvement_needed})\")\n            print(f\"     └─ Potential: {jobs:,} jobs once you reach 4+\")\n    else:\n        print(f\"  🌟 All skills are job-ready! Consider deepening expertise to 5/5\")\n    \n    # 5. Priority recommendation\n    print(f\"\\n🎯 PRIORITY RECOMMENDATION FOR {person_name}:\")\n    if len(to_improve) &gt; 0:\n        # Find the skill with highest market demand that needs improvement\n        priority_skill = None\n        max_jobs = 0\n        for skill, level in to_improve.items():\n            skill_rows = individual_df[individual_df['Team_Has_It'].str.contains(skill, na=False, case=False)]\n            jobs = skill_rows['Number_of_Jobs'].iloc[0] if len(skill_rows) &gt; 0 else 0\n            if jobs &gt; max_jobs:\n                max_jobs = jobs\n                priority_skill = skill\n        \n        if priority_skill:\n            current = person_skills[priority_skill]\n            gap = 4 - current\n            print(f\"  Focus on: {priority_skill}\")\n            print(f\"  Current: {current}/5 → Target: 4/5 (Gap: {gap} levels)\")\n            print(f\"  Why: Highest market demand ({max_jobs:,} jobs) among skills you need to improve\")\n    else:\n        print(f\"  All 4 focus skills are job-ready!\")\n        print(f\"  Next step: Build portfolio projects or learn complementary skills\")\n    \n    return individual_df, avg_proficiency\n\n\n# Run analysis for each team member\nresults = {}\nfor member in df_skills.index:\n    person_skills = df_skills.loc[member]\n    individual_analysis, avg_prof = analyze_individual(member, person_skills, top_50_skills)\n    results[member] = {\n        'analysis': individual_analysis,\n        'avg_proficiency': avg_prof,\n        'skills': person_skills\n    }\n\n\n\n================================================================================\n📊 INDIVIDUAL ANALYSIS: THOMAS\n================================================================================\n\n🎯 Thomas's Current Skill Levels:\n  • Python: 1/5 (Beginner) ⚠️ Needs Work\n  • SQL: 2/5 (Basic) ⚠️ Needs Work\n  • Machine Learning: 1/5 (Beginner) ⚠️ Needs Work\n  • Cloud Computing: 1/5 (Beginner) ⚠️ Needs Work\n\n📊 Summary of Your 4 Focus Skills:\n  • Job-Ready Skills (4+): 0/4\n  • Average proficiency: 1.2/5\n\n💪 Thomas's STRENGTHS (Skills at 4+ level):\n  None yet (no skills at 4+)\n  💡 Focus on getting at least one skill to 4+ for job-readiness\n\n📚 Thomas SHOULD IMPROVE (Skills below 4):\n  ⚠️ Python: 1/5 → Target: 4/5 (improve by 3)\n     └─ Potential: 12,253 jobs once you reach 4+\n  ⚠️ SQL: 2/5 → Target: 4/5 (improve by 2)\n     └─ Potential: 21,733 jobs once you reach 4+\n  ⚠️ Machine Learning: 1/5 → Target: 4/5 (improve by 3)\n     └─ Potential: 1,442 jobs once you reach 4+\n  ⚠️ Cloud Computing: 1/5 → Target: 4/5 (improve by 3)\n     └─ Potential: 4,759 jobs once you reach 4+\n\n🎯 PRIORITY RECOMMENDATION FOR Thomas:\n  Focus on: SQL\n  Current: 2/5 → Target: 4/5 (Gap: 2 levels)\n  Why: Highest market demand (21,733 jobs) among skills you need to improve\n\n================================================================================\n📊 INDIVIDUAL ANALYSIS: FAYOBOMI\n================================================================================\n\n🎯 Fayobomi's Current Skill Levels:\n  • Python: 2/5 (Basic) ⚠️ Needs Work\n  • SQL: 3/5 (Intermediate) ⚠️ Needs Work\n  • Machine Learning: 2/5 (Basic) ⚠️ Needs Work\n  • Cloud Computing: 2/5 (Basic) ⚠️ Needs Work\n\n📊 Summary of Your 4 Focus Skills:\n  • Job-Ready Skills (4+): 0/4\n  • Average proficiency: 2.2/5\n\n💪 Fayobomi's STRENGTHS (Skills at 4+ level):\n  None yet (no skills at 4+)\n  💡 Focus on getting at least one skill to 4+ for job-readiness\n\n📚 Fayobomi SHOULD IMPROVE (Skills below 4):\n  ⚠️ Python: 2/5 → Target: 4/5 (improve by 2)\n     └─ Potential: 12,253 jobs once you reach 4+\n  ⚠️ SQL: 3/5 → Target: 4/5 (improve by 1)\n     └─ Potential: 21,733 jobs once you reach 4+\n  ⚠️ Machine Learning: 2/5 → Target: 4/5 (improve by 2)\n     └─ Potential: 1,442 jobs once you reach 4+\n  ⚠️ Cloud Computing: 2/5 → Target: 4/5 (improve by 2)\n     └─ Potential: 4,759 jobs once you reach 4+\n\n🎯 PRIORITY RECOMMENDATION FOR Fayobomi:\n  Focus on: SQL\n  Current: 3/5 → Target: 4/5 (Gap: 1 levels)\n  Why: Highest market demand (21,733 jobs) among skills you need to improve\n\n================================================================================\n📊 INDIVIDUAL ANALYSIS: DOMINIQUE\n================================================================================\n\n🎯 Dominique's Current Skill Levels:\n  • Python: 4/5 (Advanced) ✅ Job-Ready\n  • SQL: 3/5 (Intermediate) ⚠️ Needs Work\n  • Machine Learning: 4/5 (Advanced) ✅ Job-Ready\n  • Cloud Computing: 3/5 (Intermediate) ⚠️ Needs Work\n\n📊 Summary of Your 4 Focus Skills:\n  • Job-Ready Skills (4+): 2/4\n  • Average proficiency: 3.5/5\n\n💪 Dominique's STRENGTHS (Skills at 4+ level):\n  ✅ Python: 4/5 → Opens access to 12,253 jobs\n  ✅ Machine Learning: 4/5 → Opens access to 1,442 jobs\n\n📚 Dominique SHOULD IMPROVE (Skills below 4):\n  ⚠️ SQL: 3/5 → Target: 4/5 (improve by 1)\n     └─ Potential: 21,733 jobs once you reach 4+\n  ⚠️ Cloud Computing: 3/5 → Target: 4/5 (improve by 1)\n     └─ Potential: 4,759 jobs once you reach 4+\n\n🎯 PRIORITY RECOMMENDATION FOR Dominique:\n  Focus on: SQL\n  Current: 3/5 → Target: 4/5 (Gap: 1 levels)\n  Why: Highest market demand (21,733 jobs) among skills you need to improve\n\n================================================================================\n📊 INDIVIDUAL ANALYSIS: ARYAN\n================================================================================\n\n🎯 Aryan's Current Skill Levels:\n  • Python: 5/5 (Expert) ✅ Job-Ready\n  • SQL: 4/5 (Advanced) ✅ Job-Ready\n  • Machine Learning: 4/5 (Advanced) ✅ Job-Ready\n  • Cloud Computing: 5/5 (Expert) ✅ Job-Ready\n\n📊 Summary of Your 4 Focus Skills:\n  • Job-Ready Skills (4+): 4/4\n  • Average proficiency: 4.5/5\n\n💪 Aryan's STRENGTHS (Skills at 4+ level):\n  ✅ Python: 5/5 → Opens access to 12,253 jobs\n  ✅ SQL: 4/5 → Opens access to 21,733 jobs\n  ✅ Machine Learning: 4/5 → Opens access to 1,442 jobs\n  ✅ Cloud Computing: 5/5 → Opens access to 4,759 jobs\n\n📚 Aryan SHOULD IMPROVE (Skills below 4):\n  🌟 All skills are job-ready! Consider deepening expertise to 5/5\n\n🎯 PRIORITY RECOMMENDATION FOR Aryan:\n  All 4 focus skills are job-ready!\n  Next step: Build portfolio projects or learn complementary skills"
  },
  {
    "objectID": "introduction.html",
    "href": "introduction.html",
    "title": "Research Introduction: AI vs. Non-AI Careers",
    "section": "",
    "text": "The American labor market is undergoing a fundamental geographic restructuring. Factors such as the COVID-19 global pandemic have shifted the way businesses operate, the rise of Artificial Intelligence (AI) continuously impacts the labor force as it improves, and emerging tech hubs have presented competition for established tech hubs. These modern complexities raise critical questions:\n\nWhich cities or states have the highest job growth for AI vs. non-AI careers?\nAre remote jobs increasing or decreasing across industries?\nDo tech hubs still dominate hiring, or are other locations emerging?\nHow do urban vs. rural job markets differ for AI and non-AI careers?\n\nThis research examines job growth patterns, remote work trends, and the shifting geography of AI and non-AI careers to understand how location shapes opportunity in the evolving American economy."
  },
  {
    "objectID": "introduction.html#introduction",
    "href": "introduction.html#introduction",
    "title": "Research Introduction: AI vs. Non-AI Careers",
    "section": "",
    "text": "The American labor market is undergoing a fundamental geographic restructuring. Factors such as the COVID-19 global pandemic have shifted the way businesses operate, the rise of Artificial Intelligence (AI) continuously impacts the labor force as it improves, and emerging tech hubs have presented competition for established tech hubs. These modern complexities raise critical questions:\n\nWhich cities or states have the highest job growth for AI vs. non-AI careers?\nAre remote jobs increasing or decreasing across industries?\nDo tech hubs still dominate hiring, or are other locations emerging?\nHow do urban vs. rural job markets differ for AI and non-AI careers?\n\nThis research examines job growth patterns, remote work trends, and the shifting geography of AI and non-AI careers to understand how location shapes opportunity in the evolving American economy."
  },
  {
    "objectID": "introduction.html#research-rationale",
    "href": "introduction.html#research-rationale",
    "title": "Research Introduction: AI vs. Non-AI Careers",
    "section": "Research Rationale",
    "text": "Research Rationale\n\nAI’s Impact on Employment Geography\nBessen ((2018)) argues that AI’s employment impact depends critically on market demand rather than automation alone. Analyzing over a century of manufacturing data, he finds that technology-driven productivity gains initially increased jobs when demand was elastic but eventually reduced employment once markets became saturated. This suggests that geographic regions where AI targets unmet needs may experience job growth, while areas where AI serves already-saturated markets face potential displacement—a distinction crucial for understanding the uneven geographic distribution of AI career opportunities.\n\n\nRemote Work and Post-Pandemic Restructuring\nWith COVID-19 disrupting various business models, American corporations had to quickly restructure operations. Five years later, COVID-19 is no longer considered a national emergency, with various public and private sector organizations implementing return-to-office (RTO) mandates (Paulino et al. (2025)). Although the trend is currently favorable for RTO policies, “smaller companies, which often cannot compete on salary alone, are increasingly embracing remote work flexibility to attract and retain top talent” (Paulino et al. (2025)). Smaller companies can use remote work policies to their advantage, whether to lower their overhead costs or retain top talent without offering as much salary compared to in-office based roles.\n\n\nEmerging Tech Hubs and Geographic Concentration\nTech hubs seem to be emerging in droves across various parts of America. According to Chen, Levanon, and Sigelman ((2024)), although there are many smaller hubs forming, the Silicon Valley on the West Coast of the United States is still dominant. They explore the idea that there is a relationship between emerging tech hubs and established tech hubs: “the greatest determinant of migration is geographic proximity” (Chen, Levanon, and Sigelman (2024)). Another reason for the expansion of tech hubs in the United States is “likely motivated by quality of life and cost of living” (Chen, Levanon, and Sigelman (2024)). Although other tech hubs are spreading towards other regions in the United States, Silicon Valley residents shouldn’t see this as a threat, since growing tech talent causes a synergy that, as a result, both grows and redistributes tech employment.\n\n\nUrban-Rural Disparities in Remote Work Access\nGeographic location significantly shapes access to remote work opportunities, with important implications for employment equity. Paul ((2022)) analyzes pre-pandemic travel survey data and finds that rural workers prefer but rarely access work-from-home arrangements compared to urban counterparts, primarily due to inadequate broadband infrastructure and the geographic concentration of remote-compatible jobs in metropolitan areas. The study reveals that urban workers were nearly twice as likely to have remote work options, while rural workers—particularly Hispanic rural workers—faced compounded disadvantages in accessing virtual employment. These patterns suggest that AI careers requiring advanced digital infrastructure and remote work capabilities may concentrate in urban areas unless targeted policies address rural technology access gaps."
  },
  {
    "objectID": "introduction.html#methodology",
    "href": "introduction.html#methodology",
    "title": "Research Introduction: AI vs. Non-AI Careers",
    "section": "Methodology",
    "text": "Methodology\nWe undertook an investigation of job posting data from January to September 2024. Our tool, Lightcast, enabled us to standardize the many titles, locations, and employer information that populated the job postings. Through that process, we also conducted a feature analysis to understand the kinds of construction that are going on for jobs requiring artificial intelligence “in both a technical and a generative sense.” Overall, we read just over 22,000 job postings requiring AI-related skills.\nThen on the basic level, we conducted some summary and inferential statistics to understand the kinds of pay differences that might exist among postings for AI and non-AI jobs. On another level, we ran the postings through a random-forest regressor—a kind of model that uses certain given variables to try to explain or understand what is going on with the posting salaries. The model itself has 10 different versions, and each one assigns weights to the different given variables (such as the industry in which the job is located) to come up with a predicted salary. Results should shed light on the nature of pay for AI skills in the job market and how geographic and industrial factors influence compensation patterns."
  },
  {
    "objectID": "introduction.html#research-questions",
    "href": "introduction.html#research-questions",
    "title": "Research Introduction: AI vs. Non-AI Careers",
    "section": "Research Questions",
    "text": "Research Questions\nThis analysis addresses the following key questions:\n\nGeographic Distribution: Where are AI jobs concentrated, and how does this compare to non-AI career opportunities?\nRemote Work Trends: How have remote, hybrid, and on-site work arrangements evolved post-pandemic for AI versus non-AI positions?\nUrban-Rural Divide: What disparities exist between urban and rural areas in terms of AI job growth and compensation?\nCompensation Patterns: How do salaries for AI-related positions compare across different geographic regions and work arrangements?"
  },
  {
    "objectID": "introduction.html#references",
    "href": "introduction.html#references",
    "title": "Research Introduction: AI vs. Non-AI Careers",
    "section": "References",
    "text": "References\n\n\nBessen, J. (2018): AI and Jobs: The Role of Demand, Working Paper, National Bureau of Economic Research.\n\n\nChen, Z., G. Levanon, and M. Sigelman. (2024): America’s Tech Hubs Are Multiplying: How Tech Powerhouses’ Diaspora Are Fueling the Rise of New Cities on the Talent Frontier,The Burning Glass Institute.\n\n\nPaul, J. A. (2022): “Work from home behaviors among u.s. Urban and rural residents,” Transportation Research Part A: Policy and Practice, 165, 254–69.\n\n\nPaulino, M., S. J. London, L. M. Giurge, R. W. Buell, and A. S. Gabriel. (2025): “Return-to-office mandates and workplace inequality: Implications for industrial-organizational psychology,” Industrial and Organizational Psychology,."
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Geographic & Remote Work Analysis",
    "section": "",
    "text": "This project analyzes job market trends in 2024, focusing on geographic and remote work analysis."
  },
  {
    "objectID": "index.html#overview",
    "href": "index.html#overview",
    "title": "Geographic & Remote Work Analysis",
    "section": "",
    "text": "This project analyzes job market trends in 2024, focusing on geographic and remote work analysis."
  },
  {
    "objectID": "index.html#key-findings",
    "href": "index.html#key-findings",
    "title": "Geographic & Remote Work Analysis",
    "section": "Key Findings",
    "text": "Key Findings\n\nEmerging tech hubs are now leading in job growth, outpacing legacy hubs\nRemote work availability is highest in the Real Estate, Arts, and Finance sectors. Additionally, most of the remote job postings are from Alaska\nTop in-demand skills include…"
  },
  {
    "objectID": "index.html#explore-the-analysis",
    "href": "index.html#explore-the-analysis",
    "title": "Geographic & Remote Work Analysis",
    "section": "Explore the Analysis",
    "text": "Explore the Analysis\nResearch Introduction: Background and research questions Geographic Trends: EDA and Visualizations: Exploratory data analysis Tech Hub Analysis: Legacy vs emerging tech hubs Skill Gap Analysis: In-demand skills analysis Random Forest: Predictive modeling"
  },
  {
    "objectID": "index.html#about-this-project",
    "href": "index.html#about-this-project",
    "title": "Geographic & Remote Work Analysis",
    "section": "About This Project",
    "text": "About This Project\nDataset: Lightcast Job Postings (Jan-Sep 2024) Team: Group 09 Course: AD688 - Cloud Analytics"
  },
  {
    "objectID": "RandomForest.html",
    "href": "RandomForest.html",
    "title": "Random Forest",
    "section": "",
    "text": "Random Forest Analysis\nThe purpose of this analysis is to determine how much does salary depends on geography versus other variables such as years of experience, job field, remote/onsite work, and level of education.\nVariables Used\nThe following variables will be used in the Random Forest model:"
  },
  {
    "objectID": "RandomForest.html#random-forest-model-deployment-interpretation",
    "href": "RandomForest.html#random-forest-model-deployment-interpretation",
    "title": "Random Forest",
    "section": "Random Forest Model Deployment & Interpretation",
    "text": "Random Forest Model Deployment & Interpretation\nBefore using the model for predictive analysis, we will measure how strong the model is.\nThe table below shows the following metrics:\n\nRMSE (Root Mean Squared Error): Average error between predicted and actual salaries.\nMAE (Mean Absolute Error): Average error without considering direction (absolute value of the errors).\nR-Squared: Coefficient of determination that shows how well the predicted salaries approximates actual salaries.\n\n\n\nCode\nrf = RandomForestRegressor(\n    featuresCol=\"features\",\n    labelCol=\"SALARY\",\n    numTrees=300,\n    maxDepth=12,\n    seed=42\n)\n\npipeline = Pipeline(stages=indexers + encoders + [assembler, rf])\n\n#Train / Test Split - Using 80% of data for training and 20% for testing\ntrain_df, test_df = rf_df.randomSplit([0.8, 0.2], seed=42)\n\n# Fit and Predict\nmodel = pipeline.fit(train_df)\npred = model.transform(test_df)\n\n# RMSE, MAE, R squared\nev = RegressionEvaluator(labelCol=\"SALARY\", predictionCol=\"prediction\")\n\nrmse = ev.setMetricName(\"rmse\").evaluate(pred)\nmae  = ev.setMetricName(\"mae\").evaluate(pred)\nr2   = ev.setMetricName(\"r2\").evaluate(pred)\n\nrf_metrics = pd.DataFrame({\n    \"RMSE\": [rmse],\n    \"MAE\": [mae],\n    \"R²\": [r2]\n}).round({\"RMSE\": 0, \"MAE\": 0, \"R²\": 3})\n\nrf_metrics\n\n\n\n\n\n\n\n\n\nRMSE\nMAE\nR²\n\n\n\n\n0\n38837.0\n30067.0\n0.193\n\n\n\n\n\n\n\nInterpretation: These variables collectively explains the salary by about 20%. Whereas in the testing data, the tested salaries were off by ~39K compared to the actual.\nFeature Importance\nFeature importance determines which variables used in the model had the most influence/impact on determining the salary. The graph below shows the top 20 variables used.\n\n\nCode\nrf_stage = model.stages[-1]\nimportances = np.array(rf_stage.featureImportances.toArray())\n\nmeta = pred.schema[\"features\"].metadata[\"ml_attr\"][\"attrs\"]\nattrs = sorted([*meta.get(\"binary\", []), *meta.get(\"numeric\", [])], key=lambda a: a[\"idx\"])\nfeature_names = [a[\"name\"] for a in attrs]\n\ntopn = 20\nfeat_imp = (pd.DataFrame({\"Feature\": feature_names, \"Importance\": importances})\n              .sort_values(\"Importance\", ascending=False)\n              .head(topn))\n\ndef clean_label(s: str) -&gt; str:\n    s = re.sub(r'(_ohe|_idx)$', '', s)\n    s = s.replace(\"MIN_EDULEVELS\",\"Education\") \\\n         .replace(\"NAICS2_NAME\",\"Industry\") \\\n         .replace(\"STATE_NAME\",\"State\") \\\n         .replace(\"STATE_NAME_ohe\",\"State\") \\\n         .replace(\"MIN_EDULEVELS_ohe\",\"Education\") \\\n         .replace(\"NAICS2_NAME_ohe\",\"Industry\") \\\n         .replace(\"REMOTE_TYPE\",\"Remote\")\n    return textwrap.shorten(s, width=28, placeholder=\"…\")  # wrap/shorten\nfeat_imp[\"Label\"] = feat_imp[\"Feature\"].map(clean_label)\n\nplt.figure(figsize=(8,6))\nsns.barplot(data=feat_imp, x=\"Importance\", y=\"Label\")\nplt.title(f\"Top {topn} Random Forest Feature Importances\")\nplt.xlabel(\"Importance\"); plt.ylabel(\"Feature\")\nplt.tight_layout()\nplt.show()\n\n\n\n\n\n\n\n\n\nInterpretation: Despite a relatively lower R squared value below 20% - this chart clearly shows that state (and ultimately location) has less influence on the amount of salary an employee receives compared to their education, position, and field."
  },
  {
    "objectID": "RandomForest.html#predictive-analysis",
    "href": "RandomForest.html#predictive-analysis",
    "title": "Random Forest",
    "section": "Predictive Analysis",
    "text": "Predictive Analysis\nThis analysis uses synthetic data to estimate what the Random Forest model would predict the salaries would be. There are 10 different variations of job type, state, education, etc. to predict each salary.\n\n\nCode\nfrom pyspark.sql import functions as F\n\ncat_cols = [\"REMOTE_TYPE\", \"STATE_NAME\", \"MIN_EDULEVELS\", \"NAICS2_NAME\"]\nnum_cols = [\"MIN_YEARS_EXPERIENCE\"]\n\n# Generic data to test predictive analysis\ntest_data = [\n    {\"REMOTE_TYPE\": \"Onsite\", \"STATE_NAME\": \"California\", \"MIN_EDULEVELS\": \"Master's\",\n     \"NAICS2_NAME\": \"Information\", \"MIN_YEARS_EXPERIENCE\": 7.0},\n\n    {\"REMOTE_TYPE\": \"Remote\", \"STATE_NAME\": \"Texas\", \"MIN_EDULEVELS\": \"Associate or lower\",\n     \"NAICS2_NAME\": \"Administrative and Support and Waste Management and Remediation Services\", \"MIN_YEARS_EXPERIENCE\": 2.0},\n\n    {\"REMOTE_TYPE\": \"Onsite\", \"STATE_NAME\": \"Washington\", \"MIN_EDULEVELS\": \"Bachelor\",\n     \"NAICS2_NAME\": \"Professional, Scientific, and Technical Services\", \"MIN_YEARS_EXPERIENCE\": 12.0},\n\n    {\"REMOTE_TYPE\": \"Hybrid\", \"STATE_NAME\": \"Illinois\", \"MIN_EDULEVELS\": \"Bachelor\",\n     \"NAICS2_NAME\": \"Finance and Insurance\", \"MIN_YEARS_EXPERIENCE\": 6.0},\n\n    {\"REMOTE_TYPE\": \"Onsite\", \"STATE_NAME\": \"New York\", \"MIN_EDULEVELS\": \"Master's\",\n     \"NAICS2_NAME\": \"Educational Services\", \"MIN_YEARS_EXPERIENCE\": 10.0},\n\n    {\"REMOTE_TYPE\": \"Hybrid\", \"STATE_NAME\": \"Florida\", \"MIN_EDULEVELS\": \"Bachelor\",\n     \"NAICS2_NAME\": \"Manufacturing\", \"MIN_YEARS_EXPERIENCE\": 8.0},\n\n    {\"REMOTE_TYPE\": \"Onsite\", \"STATE_NAME\": \"Ohio\", \"MIN_EDULEVELS\": \"Associate or lower\",\n     \"NAICS2_NAME\": \"Health Care and Social Assistance\", \"MIN_YEARS_EXPERIENCE\": 3.0},\n\n    {\"REMOTE_TYPE\": \"Onsite\", \"STATE_NAME\": \"Virginia\", \"MIN_EDULEVELS\": \"PhD\",\n     \"NAICS2_NAME\": \"Professional, Scientific, and Technical Services\", \"MIN_YEARS_EXPERIENCE\": 9.0},\n\n    {\"REMOTE_TYPE\": \"Remote\", \"STATE_NAME\": \"Colorado\", \"MIN_EDULEVELS\": \"Bachelor\",\n     \"NAICS2_NAME\": \"Real Estate and Rental and Leasing\", \"MIN_YEARS_EXPERIENCE\": 7.0},\n\n    {\"REMOTE_TYPE\": \"Onsite\", \"STATE_NAME\": \"Michigan\", \"MIN_EDULEVELS\": \"Bachelor\",\n     \"NAICS2_NAME\": \"Wholesale Trade\", \"MIN_YEARS_EXPERIENCE\": 5.0},\n]\n\nnew_df = spark.createDataFrame(test_data)\n\n# Preventative for nulls in categoricals your pipeline indexes\nnew_df = new_df.fillna({c: \"Unknown\" for c in cat_cols})\n\n# Predicting the salaries using trained pipeline model\npred = model.transform(new_df)\n\npred_pdf = (\n    pred.select(\n        F.col(\"REMOTE_TYPE\").alias(\"Remote/Onsite\"),\n        F.col(\"STATE_NAME\").alias(\"State\"),\n        F.col(\"MIN_EDULEVELS\").alias(\"Education\"),\n        F.col(\"NAICS2_NAME\").alias(\"Industry\"),\n        F.col(\"MIN_YEARS_EXPERIENCE\").alias(\"Min Yrs Exp\"),\n        F.col(\"prediction\").alias(\"Predicted Salary\"),\n    )\n    .orderBy(F.col(\"Predicted Salary\").desc())\n    .toPandas()\n)\n\n# Round and format currency\npred_pdf[\"Predicted Salary\"] = pred_pdf[\"Predicted Salary\"].round(0)\n\n# Add a rank column\npred_pdf.insert(0, \"#\", range(1, len(pred_pdf) + 1))\n\n# Render a clean, index-free, currency-formatted table\npred_pdf.style.format({\n    \"Predicted Salary\": \"${:,.0f}\",\n    \"Min Yrs Exp\": \"{:.0f}\"\n}).hide(axis=\"index\")\n\n\n\n\n\n\n\n#\nRemote/Onsite\nState\nEducation\nIndustry\nMin Yrs Exp\nPredicted Salary\n\n\n\n\n1\nOnsite\nVirginia\nPhD\nProfessional, Scientific, and Technical Services\n9\n$230,041\n\n\n2\nOnsite\nCalifornia\nMaster's\nInformation\n7\n$170,895\n\n\n3\nOnsite\nWashington\nBachelor\nProfessional, Scientific, and Technical Services\n12\n$140,037\n\n\n4\nHybrid\nFlorida\nBachelor\nManufacturing\n8\n$123,385\n\n\n5\nHybrid\nIllinois\nBachelor\nFinance and Insurance\n6\n$121,486\n\n\n6\nRemote\nTexas\nAssociate or lower\nAdministrative and Support and Waste Management and Remediation Services\n2\n$114,545\n\n\n7\nOnsite\nMichigan\nBachelor\nWholesale Trade\n5\n$113,658\n\n\n8\nRemote\nColorado\nBachelor\nReal Estate and Rental and Leasing\n7\n$111,829\n\n\n9\nOnsite\nOhio\nAssociate or lower\nHealth Care and Social Assistance\n3\n$102,082\n\n\n10\nOnsite\nNew York\nMaster's\nEducational Services\n10\n$75,675\n\n\n\n\n\nInterpretation: The results are varied - in some instances the results align with our previous analysis - higher eduction, onsite, and tech should see higher salaries. For example, the first line and eigth line do have the highest salaries being in information and tech alongside 5+ years of experience, onsite, and higher education completed. However, the fith line has the lowest salary, but does not necessarily align in an intuitive sense - 10 years of experience, Masters, onsite, etc. should be ranked higher."
  },
  {
    "objectID": "RandomForest.html#kmeans-clustering-analysis",
    "href": "RandomForest.html#kmeans-clustering-analysis",
    "title": "Random Forest",
    "section": "KMeans Clustering Analysis",
    "text": "KMeans Clustering Analysis\nThis analysis explores salary and years of experience by the NAICS Name. As shown below, three groups have been for various NAICS’s, with years of experience horizontally, and salary on the vertical axis.\n\n\nCode\n# Visualizing the results\nplot_pdf = pred.select(\"MIN_YEARS_EXPERIENCE\", \"SALARY\", \"cluster\") \\\n               .sample(False, 0.25, 42).toPandas()\nimport matplotlib.pyplot as plt\nplt.figure(figsize=(8,6))\ns = plt.scatter(plot_pdf[\"MIN_YEARS_EXPERIENCE\"], plot_pdf[\"SALARY\"], c=plot_pdf[\"cluster\"], alpha=.6)\nplt.xlabel(\"MIN_YEARS_EXPERIENCE\"); plt.ylabel(\"SALARY\")\nplt.title(\"Clustering by NAICS2\")\nhandles,_ = s.legend_elements()\nplt.legend(handles, [f\"Cluster {i}\" for i in sorted(plot_pdf['cluster'].unique())], title=\"Clusters\")\nplt.grid(True, alpha=.3); plt.tight_layout(); plt.show()\n\n\n\n\n\n\n\n\n\nInterpretation: The KMeans cluster mostly uses salaries to separate each cluster group - while some clusters pay lower or higher pay at the same years of experience, this suggests that the industry does influence salaries at different levels of experience. Overall, salaries generally rise with experience, though industry effects can override that pattern."
  }
]