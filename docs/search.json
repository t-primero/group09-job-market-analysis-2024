[
  {
    "objectID": "eda.html",
    "href": "eda.html",
    "title": "EDA",
    "section": "",
    "text": "Code\nfrom pyspark.sql import SparkSession\nspark = SparkSession.builder.appName(\"JobPostingsEDA\").getOrCreate()\ndf = spark.read.option(\"header\",\"true\").option(\"inferSchema\",\"true\") \\\n    .option(\"multiLine\",\"true\").option(\"escape\",\"\\\"\") \\\n    .csv(\"data/lightcast_job_postings.csv\")\ndf.cache()\ndf.count()\n\n\n72498\n\n\n\n\nCode\nfrom pyspark.sql.functions import when, col, trim\nfrom pyspark.sql.types import IntegerType, FloatType\n\ncols_blank = [\"CITY_NAME\",\"STATE_NAME\",\"REMOTE_TYPE\",\"MIN_EDULEVELS\",\n              \"SALARY\",\"SALARY_FROM\",\"SALARY_TO\",\n              \"MIN_YEARS_EXPERIENCE\",\"MAX_YEARS_EXPERIENCE\"]\nfor c in cols_blank:\n    if c in df.columns:\n        df = df.withColumn(c, when(trim(col(c)) == \"\", None).otherwise(col(c)))\n\ndf = df.withColumn(\"REMOTE_TYPE\", col(\"REMOTE_TYPE\").cast(IntegerType())) \\\n       .withColumn(\"MIN_EDULEVELS\", col(\"MIN_EDULEVELS\").cast(IntegerType())) \\\n       .withColumn(\"SALARY\", col(\"SALARY\").cast(FloatType())) \\\n       .withColumn(\"SALARY_FROM\", col(\"SALARY_FROM\").cast(FloatType())) \\\n       .withColumn(\"SALARY_TO\", col(\"SALARY_TO\").cast(FloatType())) \\\n       .withColumn(\"MIN_YEARS_EXPERIENCE\", col(\"MIN_YEARS_EXPERIENCE\").cast(FloatType())) \\\n       .withColumn(\"MAX_YEARS_EXPERIENCE\", col(\"MAX_YEARS_EXPERIENCE\").cast(FloatType()))\n\ndf = df.withColumn(\n    \"REMOTE_TYPE\",\n    when(col(\"REMOTE_TYPE\") == 1, \"Remote\")\n    .when(col(\"REMOTE_TYPE\") == 2, \"Onsite\")\n    .when(col(\"REMOTE_TYPE\") == 3, \"Hybrid\")\n    .otherwise(\"Onsite\")\n)\n\ndf = df.withColumn(\n    \"MIN_EDULEVELS\",\n    when(col(\"MIN_EDULEVELS\").isin(0,1,99), \"Associate or lower\")\n    .when(col(\"MIN_EDULEVELS\") == 2, \"Bachelor\")\n    .when(col(\"MIN_EDULEVELS\") == 3, \"Master's\")\n    .when(col(\"MIN_EDULEVELS\") == 4, \"PhD\")\n    .otherwise(\"Associate or lower\")\n)\n\ndf = df.withColumn(\"CITY_NAME\", when(col(\"CITY_NAME\").isNull(), \"No City\").otherwise(col(\"CITY_NAME\")))\ndf = df.withColumn(\"STATE_NAME\", when(col(\"STATE_NAME\").isNull(), \"No State\").otherwise(col(\"STATE_NAME\")))\n\ndf = df.withColumn(\n    \"SALARY\",\n    when(col(\"SALARY\").isNull() & col(\"SALARY_FROM\").isNotNull() & col(\"SALARY_TO\").isNotNull(),\n         (col(\"SALARY_FROM\") + col(\"SALARY_TO\"))/2.0\n    ).otherwise(col(\"SALARY\"))\n)\ndf.count()\n\n\n72498\n\n\n\n\nCode\ndf.write.mode(\"overwrite\").parquet(\"data/clean_job_postings.parquet\")\n\n\n\n\nCode\n# Remote share by state\nstate_remote = df.groupBy(\"STATE_NAME\",\"REMOTE_TYPE\").count().orderBy(\"count\", ascending=False)\nstate_remote.show(20, truncate=False)\n\n# Top cities by postings\ndf.groupBy(\"CITY_NAME\",\"STATE_NAME\").count().orderBy(\"count\", ascending=False).show(20, truncate=False)\n\n# Salary by state\ndf.groupBy(\"STATE_NAME\").avg(\"SALARY\").orderBy(\"avg(SALARY)\", ascending=False).show(20, truncate=False)\n\n\n+--------------+-----------+-----+\n|STATE_NAME    |REMOTE_TYPE|count|\n+--------------+-----------+-----+\n|Texas         |Onsite     |6763 |\n|California    |Onsite     |5766 |\n|Florida       |Onsite     |3060 |\n|Virginia      |Onsite     |2942 |\n|Illinois      |Onsite     |2896 |\n|New York      |Onsite     |2787 |\n|North Carolina|Onsite     |2240 |\n|Ohio          |Onsite     |2198 |\n|Georgia       |Onsite     |2169 |\n|New Jersey    |Onsite     |2148 |\n|Pennsylvania  |Onsite     |1828 |\n|Massachusetts |Onsite     |1651 |\n|Michigan      |Onsite     |1522 |\n|Arizona       |Onsite     |1349 |\n|Washington    |Onsite     |1260 |\n|Colorado      |Onsite     |1141 |\n|Texas         |Remote     |1091 |\n|Minnesota     |Onsite     |1075 |\n|California    |Remote     |1056 |\n|Maryland      |Onsite     |1018 |\n+--------------+-----------+-----+\nonly showing top 20 rows\n\n\n+-----------------+---------------------------------------+-----+\n|CITY_NAME        |STATE_NAME                             |count|\n+-----------------+---------------------------------------+-----+\n|New York, NY     |New York                               |2175 |\n|Chicago, IL      |Illinois                               |1803 |\n|Atlanta, GA      |Georgia                                |1706 |\n|Austin, TX       |Texas                                  |1463 |\n|Houston, TX      |Texas                                  |1423 |\n|Dallas, TX       |Texas                                  |1326 |\n|Charlotte, NC    |North Carolina                         |1226 |\n|Washington, DC   |Washington, D.C. (District of Columbia)|1210 |\n|Boston, MA       |Massachusetts                          |1012 |\n|Richmond, VA     |Virginia                               |884  |\n|San Francisco, CA|California                             |876  |\n|Phoenix, AZ      |Arizona                                |759  |\n|Los Angeles, CA  |California                             |737  |\n|Seattle, WA      |Washington                             |650  |\n|Columbus, OH     |Ohio                                   |647  |\n|Denver, CO       |Colorado                               |630  |\n|Tampa, FL        |Florida                                |617  |\n|Minneapolis, MN  |Minnesota                              |606  |\n|Philadelphia, PA |Pennsylvania                           |595  |\n|Raleigh, NC      |North Carolina                         |568  |\n+-----------------+---------------------------------------+-----+\nonly showing top 20 rows\n\n\n+---------------------------------------+------------------+\n|STATE_NAME                             |avg(SALARY)       |\n+---------------------------------------+------------------+\n|Connecticut                            |124966.07226107226|\n|New Jersey                             |123011.95022371365|\n|Arkansas                               |122204.1050955414 |\n|Virginia                               |121915.68095572734|\n|Vermont                                |121862.91588785047|\n|California                             |121078.16375806837|\n|Montana                                |120711.40350877192|\n|Illinois                               |120562.1273692191 |\n|Washington                             |119963.5337972167 |\n|Washington, D.C. (District of Columbia)|118926.40808080808|\n|Massachusetts                          |117145.98220858896|\n|Michigan                               |116451.63358778626|\n|North Carolina                         |116420.56212424849|\n|Maryland                               |116161.16097560976|\n|Iowa                                   |115321.96656534955|\n|Oklahoma                               |114818.31034482758|\n|Minnesota                              |114782.0500736377 |\n|Texas                                  |114607.66336818521|\n|New York                               |114173.67230695901|\n|Georgia                                |114030.27155655096|\n+---------------------------------------+------------------+\nonly showing top 20 rows\n\n\n\n\nCode\nfrom pyspark.sql.functions import col, count, sum as _sum, when, to_date, year, month, desc\n\n# Parse posting date if available\ndate_col = \"POSTED_DATE\"\nif date_col in df.columns:\n    df = df.withColumn(date_col, to_date(col(date_col)))\n    df = df.withColumn(\"YEAR\", year(col(date_col))).withColumn(\"MONTH\", month(col(date_col)))\n\n# Flag AI vs non AI using title and description keywords\nai_patterns = [\"ai\",\"artificial intelligence\",\"machine learning\",\"ml\",\"deep learning\",\"nlp\",\"computer vision\",\"llm\",\"genai\",\"gen ai\",\"data scientist\",\"ml engineer\"]\ndef mk_like(c):\n    expr = None\n    for p in ai_patterns:\n        cond = col(c).rlike(f\"(?i)\\\\b{p}\\\\b\")\n        expr = cond if expr is None else (expr | cond)\n    return expr\n\nai_flag = None\nif \"TITLE\" in df.columns:\n    ai_flag = mk_like(\"TITLE\")\nif \"JOB_DESCRIPTION\" in df.columns:\n    ai_desc = mk_like(\"JOB_DESCRIPTION\")\n    ai_flag = ai_desc if ai_flag is None else (ai_flag | ai_desc)\n\nif ai_flag is not None:\n    df = df.withColumn(\"IS_AI_ROLE\", when(ai_flag, 1).otherwise(0))\nelse:\n    df = df.withColumn(\"IS_AI_ROLE\", when(col(\"TITLE\").isNotNull(), 0).otherwise(0))\n\n\n\n\nCode\nfrom pyspark.sql.functions import desc\n\n\n\nRemote share by state\nstate_remote = df.groupBy(“STATE_NAME”,“REMOTE_TYPE”).count().orderBy(“count”, ascending=False) state_remote.show(30, truncate=False)\n\n\nTop states by postings\nstate_totals = df.groupBy(“STATE_NAME”).count().orderBy(“count”, ascending=False) state_totals.show(30, truncate=False)\n\n\nAI vs non AI counts by state\nfrom pyspark.sql.functions import count, sum as _sum, avg ai_state = df.groupBy(“STATE_NAME”).agg( _sum(“IS_AI_ROLE”).alias(“ai_posts”), (count(“*“) - _sum(“IS_AI_ROLE”)).alias(“non_ai_posts”) ).orderBy(“ai_posts”, ascending=False) ai_state.show(30, truncate=False)\n\n\nMonthly trend of remote vs onsite overall\nif “YEAR” in df.columns and “MONTH” in df.columns: monthly_remote = df.groupBy(“YEAR”,“MONTH”,“REMOTE_TYPE”).count().orderBy(“YEAR”,“MONTH”,“REMOTE_TYPE”) monthly_remote.show(60, truncate=False)\n\n\nSalary by state for AI vs non AI\nif “SALARY” in df.columns: sal_by_state_ai = df.groupBy(“STATE_NAME”,“IS_AI_ROLE”).agg(avg(“SALARY”).alias(“avg_salary”)).orderBy(“avg_salary”, ascending=False) sal_by_state_ai.show(30, truncate=False) ```"
  }
]