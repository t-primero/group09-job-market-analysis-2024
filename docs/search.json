[
  {
    "objectID": "tech_hub_analysis.html",
    "href": "tech_hub_analysis.html",
    "title": "Tech Hub Analysis",
    "section": "",
    "text": "This section evaluates whether legacy tech hubs (Bay Area, Seattle, Boston, NYC, Austin) still dominate AI hiring or whether a set of emerging hubs is gaining share. We compare posting volume, AI share, remote/hybrid availability, and median salary (when available).\n\n\n\n\n\n\nNote\n\n\n\nData source: data/raw/lightcast_job_postings.csv (Lightcast, 2024; Jan–Sep if that’s what you downloaded).\nInstructions: Make sure the CSV is at data/raw/lightcast_job_postings.csv."
  },
  {
    "objectID": "tech_hub_analysis.html#purpose",
    "href": "tech_hub_analysis.html#purpose",
    "title": "Tech Hub Analysis",
    "section": "",
    "text": "This section evaluates whether legacy tech hubs (Bay Area, Seattle, Boston, NYC, Austin) still dominate AI hiring or whether a set of emerging hubs is gaining share. We compare posting volume, AI share, remote/hybrid availability, and median salary (when available).\n\n\n\n\n\n\nNote\n\n\n\nData source: data/raw/lightcast_job_postings.csv (Lightcast, 2024; Jan–Sep if that’s what you downloaded).\nInstructions: Make sure the CSV is at data/raw/lightcast_job_postings.csv."
  },
  {
    "objectID": "tech_hub_analysis.html#setup",
    "href": "tech_hub_analysis.html#setup",
    "title": "Tech Hub Analysis",
    "section": "0.2 Setup",
    "text": "0.2 Setup\nlibrary(tidyverse) library(lubridate) theme_set(theme_minimal(base_size = 14))\npath &lt;- “data/raw/lightcast_job_postings.csv” raw &lt;- read_csv(path, show_col_types = FALSE) df &lt;- raw %&gt;% rename_with(toupper) %&gt;% mutate( CITY_NAME = coalesce(CITY_NAME, CITY, NA), STATE_NAME = coalesce(STATE_NAME, STATE, NA), TITLE = coalesce(JOB_TITLE, TITLE, NA), SKILLS_TXT = coalesce(SKILLS, SKILL_TEXT, NA), POSTED = coalesce(POSTED_DATE, DATE_POSTED, as.character(NA)), POSTED = suppressWarnings(ymd(POSTED)), REMOTE_TYPE = case_when( REMOTE_TYPE %in% c(“Remote”,“REMOTE”,“remote”,“1”) ~ “Remote”, REMOTE_TYPE %in% c(“Hybrid”,“HYBRID”,“hybrid”,“3”) ~ “Hybrid”, TRUE ~ “On-site” ), SALARY = suppressWarnings(readr::parse_number(coalesce(SALARY, SALARY_TO, SALARY_FROM))) )"
  },
  {
    "objectID": "eda.html",
    "href": "eda.html",
    "title": "EDA",
    "section": "",
    "text": "Code\nfrom pyspark.sql import SparkSession\nspark = SparkSession.builder.appName(\"JobPostingsEDA\").getOrCreate()\ndf = spark.read.option(\"header\",\"true\").option(\"inferSchema\",\"true\") \\\n    .option(\"multiLine\",\"true\").option(\"escape\",\"\\\"\") \\\n    .csv(\"data/raw/lightcast_job_postings.csv\")\ndf.cache()\ndf.count()\n\n\n72498\n\n\n\n\nCode\nfrom pyspark.sql.functions import when, col, trim\nfrom pyspark.sql.types import IntegerType, FloatType\n\ncols_blank = [\"CITY_NAME\",\"STATE_NAME\",\"REMOTE_TYPE\",\"MIN_EDULEVELS\",\n              \"SALARY\",\"SALARY_FROM\",\"SALARY_TO\",\n              \"MIN_YEARS_EXPERIENCE\",\"MAX_YEARS_EXPERIENCE\"]\nfor c in cols_blank:\n    if c in df.columns:\n        df = df.withColumn(c, when(trim(col(c)) == \"\", None).otherwise(col(c)))\n\ndf = df.withColumn(\"REMOTE_TYPE\", col(\"REMOTE_TYPE\").cast(IntegerType())) \\\n       .withColumn(\"MIN_EDULEVELS\", col(\"MIN_EDULEVELS\").cast(IntegerType())) \\\n       .withColumn(\"SALARY\", col(\"SALARY\").cast(FloatType())) \\\n       .withColumn(\"SALARY_FROM\", col(\"SALARY_FROM\").cast(FloatType())) \\\n       .withColumn(\"SALARY_TO\", col(\"SALARY_TO\").cast(FloatType())) \\\n       .withColumn(\"MIN_YEARS_EXPERIENCE\", col(\"MIN_YEARS_EXPERIENCE\").cast(FloatType())) \\\n       .withColumn(\"MAX_YEARS_EXPERIENCE\", col(\"MAX_YEARS_EXPERIENCE\").cast(FloatType()))\n\ndf = df.withColumn(\n    \"REMOTE_TYPE\",\n    when(col(\"REMOTE_TYPE\") == 1, \"Remote\")\n    .when(col(\"REMOTE_TYPE\") == 2, \"Onsite\")\n    .when(col(\"REMOTE_TYPE\") == 3, \"Hybrid\")\n    .otherwise(\"Onsite\")\n)\n\ndf = df.withColumn(\n    \"MIN_EDULEVELS\",\n    when(col(\"MIN_EDULEVELS\").isin(0,1,99), \"Associate or lower\")\n    .when(col(\"MIN_EDULEVELS\") == 2, \"Bachelor\")\n    .when(col(\"MIN_EDULEVELS\") == 3, \"Master's\")\n    .when(col(\"MIN_EDULEVELS\") == 4, \"PhD\")\n    .otherwise(\"Associate or lower\")\n)\n\ndf = df.withColumn(\"CITY_NAME\", when(col(\"CITY_NAME\").isNull(), \"No City\").otherwise(col(\"CITY_NAME\")))\ndf = df.withColumn(\"STATE_NAME\", when(col(\"STATE_NAME\").isNull(), \"No State\").otherwise(col(\"STATE_NAME\")))\n\ndf = df.withColumn(\n    \"SALARY\",\n    when(col(\"SALARY\").isNull() & col(\"SALARY_FROM\").isNotNull() & col(\"SALARY_TO\").isNotNull(),\n         (col(\"SALARY_FROM\") + col(\"SALARY_TO\"))/2.0\n    ).otherwise(col(\"SALARY\"))\n)\ndf.count()\n\n\n72498\n\n\n\n\nCode\ndf.write.mode(\"overwrite\").parquet(\"data/clean_job_postings.parquet\")\n\n\n\n\nCode\n# Remote share by state\nstate_remote = df.groupBy(\"STATE_NAME\",\"REMOTE_TYPE\").count().orderBy(\"count\", ascending=False)\nstate_remote.show(20, truncate=False)\n\n# Top cities by postings\ndf.groupBy(\"CITY_NAME\",\"STATE_NAME\").count().orderBy(\"count\", ascending=False).show(20, truncate=False)\n\n# Salary by state\ndf.groupBy(\"STATE_NAME\").avg(\"SALARY\").orderBy(\"avg(SALARY)\", ascending=False).show(20, truncate=False)\n\n\n+--------------+-----------+-----+\n|STATE_NAME    |REMOTE_TYPE|count|\n+--------------+-----------+-----+\n|Texas         |Onsite     |6763 |\n|California    |Onsite     |5766 |\n|Florida       |Onsite     |3060 |\n|Virginia      |Onsite     |2942 |\n|Illinois      |Onsite     |2896 |\n|New York      |Onsite     |2787 |\n|North Carolina|Onsite     |2240 |\n|Ohio          |Onsite     |2198 |\n|Georgia       |Onsite     |2169 |\n|New Jersey    |Onsite     |2148 |\n|Pennsylvania  |Onsite     |1828 |\n|Massachusetts |Onsite     |1651 |\n|Michigan      |Onsite     |1522 |\n|Arizona       |Onsite     |1349 |\n|Washington    |Onsite     |1260 |\n|Colorado      |Onsite     |1141 |\n|Texas         |Remote     |1091 |\n|Minnesota     |Onsite     |1075 |\n|California    |Remote     |1056 |\n|Maryland      |Onsite     |1018 |\n+--------------+-----------+-----+\nonly showing top 20 rows\n\n\n+-----------------+---------------------------------------+-----+\n|CITY_NAME        |STATE_NAME                             |count|\n+-----------------+---------------------------------------+-----+\n|New York, NY     |New York                               |2175 |\n|Chicago, IL      |Illinois                               |1803 |\n|Atlanta, GA      |Georgia                                |1706 |\n|Austin, TX       |Texas                                  |1463 |\n|Houston, TX      |Texas                                  |1423 |\n|Dallas, TX       |Texas                                  |1326 |\n|Charlotte, NC    |North Carolina                         |1226 |\n|Washington, DC   |Washington, D.C. (District of Columbia)|1210 |\n|Boston, MA       |Massachusetts                          |1012 |\n|Richmond, VA     |Virginia                               |884  |\n|San Francisco, CA|California                             |876  |\n|Phoenix, AZ      |Arizona                                |759  |\n|Los Angeles, CA  |California                             |737  |\n|Seattle, WA      |Washington                             |650  |\n|Columbus, OH     |Ohio                                   |647  |\n|Denver, CO       |Colorado                               |630  |\n|Tampa, FL        |Florida                                |617  |\n|Minneapolis, MN  |Minnesota                              |606  |\n|Philadelphia, PA |Pennsylvania                           |595  |\n|Raleigh, NC      |North Carolina                         |568  |\n+-----------------+---------------------------------------+-----+\nonly showing top 20 rows\n\n\n+---------------------------------------+------------------+\n|STATE_NAME                             |avg(SALARY)       |\n+---------------------------------------+------------------+\n|Connecticut                            |124966.07226107226|\n|New Jersey                             |123011.95022371365|\n|Arkansas                               |122204.1050955414 |\n|Virginia                               |121915.68095572734|\n|Vermont                                |121862.91588785047|\n|California                             |121078.16375806837|\n|Montana                                |120711.40350877192|\n|Illinois                               |120562.1273692191 |\n|Washington                             |119963.5337972167 |\n|Washington, D.C. (District of Columbia)|118926.40808080808|\n|Massachusetts                          |117145.98220858896|\n|Michigan                               |116451.63358778626|\n|North Carolina                         |116420.56212424849|\n|Maryland                               |116161.16097560976|\n|Iowa                                   |115321.96656534955|\n|Oklahoma                               |114818.31034482758|\n|Minnesota                              |114782.0500736377 |\n|Texas                                  |114607.66336818521|\n|New York                               |114173.67230695901|\n|Georgia                                |114030.27155655096|\n+---------------------------------------+------------------+\nonly showing top 20 rows\n\n\n\n\nCode\nfrom pyspark.sql.functions import col, count, sum as _sum, when, to_date, year, month, desc\n\n# Parse posting date if available\ndate_col = \"POSTED_DATE\"\nif date_col in df.columns:\n    df = df.withColumn(date_col, to_date(col(date_col)))\n    df = df.withColumn(\"YEAR\", year(col(date_col))).withColumn(\"MONTH\", month(col(date_col)))\n\n# Flag AI vs non AI using title and description keywords\nai_patterns = [\"ai\",\"artificial intelligence\",\"machine learning\",\"ml\",\"deep learning\",\"nlp\",\"computer vision\",\"llm\",\"genai\",\"gen ai\",\"data scientist\",\"ml engineer\"]\ndef mk_like(c):\n    expr = None\n    for p in ai_patterns:\n        cond = col(c).rlike(f\"(?i)\\\\b{p}\\\\b\")\n        expr = cond if expr is None else (expr | cond)\n    return expr\n\nai_flag = None\nif \"TITLE\" in df.columns:\n    ai_flag = mk_like(\"TITLE\")\nif \"JOB_DESCRIPTION\" in df.columns:\n    ai_desc = mk_like(\"JOB_DESCRIPTION\")\n    ai_flag = ai_desc if ai_flag is None else (ai_flag | ai_desc)\n\nif ai_flag is not None:\n    df = df.withColumn(\"IS_AI_ROLE\", when(ai_flag, 1).otherwise(0))\nelse:\n    df = df.withColumn(\"IS_AI_ROLE\", when(col(\"TITLE\").isNotNull(), 0).otherwise(0))\n\n\n\n\nCode\nfrom pyspark.sql.functions import desc\n\n\n\nRemote share by state\nstate_remote = df.groupBy(“STATE_NAME”,“REMOTE_TYPE”).count().orderBy(“count”, ascending=False) state_remote.show(30, truncate=False)\n\n\nTop states by postings\nstate_totals = df.groupBy(“STATE_NAME”).count().orderBy(“count”, ascending=False) state_totals.show(30, truncate=False)\n\n\nAI vs non AI counts by state\nfrom pyspark.sql.functions import count, sum as _sum, avg ai_state = df.groupBy(“STATE_NAME”).agg( _sum(“IS_AI_ROLE”).alias(“ai_posts”), (count(“*“) - _sum(“IS_AI_ROLE”)).alias(“non_ai_posts”) ).orderBy(“ai_posts”, ascending=False) ai_state.show(30, truncate=False)\n\n\nMonthly trend of remote vs onsite overall\nif “YEAR” in df.columns and “MONTH” in df.columns: monthly_remote = df.groupBy(“YEAR”,“MONTH”,“REMOTE_TYPE”).count().orderBy(“YEAR”,“MONTH”,“REMOTE_TYPE”) monthly_remote.show(60, truncate=False)\n\n\nSalary by state for AI vs non AI\nif “SALARY” in df.columns: sal_by_state_ai = df.groupBy(“STATE_NAME”,“IS_AI_ROLE”).agg(avg(“SALARY”).alias(“avg_salary”)).orderBy(“avg_salary”, ascending=False) sal_by_state_ai.show(30, truncate=False) ```"
  },
  {
    "objectID": "geographic_trends.html",
    "href": "geographic_trends.html",
    "title": "Geographic Trends",
    "section": "",
    "text": "Code\nfrom pyspark.sql import SparkSession, functions as F\nimport seaborn as sns, matplotlib.pyplot as plt\nsns.set(style=\"whitegrid\")\n\nspark = SparkSession.builder.appName(\"EDA\").getOrCreate()\ndf = spark.read.parquet(\"data/clean_job_postings.parquet\")\n\n\nOverview Geographic EDA using Lightcast cleaned Spark DataFrame df. Focus on states, remote share, salaries, and hubs.\nTop 10 States by Job postings\n\n\nCode\nstate_counts = (df.groupBy(\"STATE_NAME\")\n                  .agg(F.count(\"*\").alias(\"postings\"))\n                  .orderBy(F.col(\"postings\").desc())\n                  .limit(10))\npdf = state_counts.toPandas()\n\nplt.figure(figsize=(8,4))\nsns.barplot(data=pdf, x=\"postings\", y=\"STATE_NAME\", color=\"#4C78A8\")\nplt.title(\"Top 10 States by Job Postings\")\nplt.xlabel(\"Postings\")\nplt.ylabel(\"State\")\nplt.tight_layout()\nplt.show()\n\n\n\n\n\n\n\n\n\nRemote vs Onsite Share by Industry\n\n\nCode\nremote_ind = (df.groupBy(\"NAICS2_NAME\",\"REMOTE_TYPE\")\n                .agg(F.count(\"*\").alias(\"postings\")))\npivot = (remote_ind.groupBy(\"NAICS2_NAME\")\n           .pivot(\"REMOTE_TYPE\", [\"Remote\",\"Hybrid\",\"Onsite\"])\n           .sum(\"postings\")\n           .fillna(0))\npivot = pivot.withColumn(\"total\", F.col(\"Remote\")+F.col(\"Hybrid\")+F.col(\"Onsite\")) \\\n             .withColumn(\"Remote_share\", F.col(\"Remote\")/F.col(\"total\")) \\\n             .orderBy(F.col(\"Remote_share\").desc()) \\\n             .limit(12)\npdf = pivot.select(\"NAICS2_NAME\",\"Remote_share\").toPandas()\n\nplt.figure(figsize=(8,5))\nsns.barplot(data=pdf, x=\"Remote_share\", y=\"NAICS2_NAME\", color=\"#E45756\")\nfrom matplotlib.ticker import FuncFormatter\nplt.gca().xaxis.set_major_formatter(FuncFormatter(lambda x,_: f\"{x:.0%}\"))\nplt.title(\"Industries with Highest Remote Share\")\nplt.xlabel(\"Remote share\")\nplt.ylabel(\"Industry\")\nplt.tight_layout()\nplt.show()\n\n\n\n\n\n\n\n\n\nAverage Salary by State\n\n\nCode\nstate_salary = (df.select(\"STATE_NAME\",\"SALARY\")\n                  .where(F.col(\"SALARY\").isNotNull())\n                  .groupBy(\"STATE_NAME\")\n                  .agg(F.count(\"*\").alias(\"n_postings\"),\n                       F.avg(\"SALARY\").alias(\"avg_salary\"),\n                       F.expr(\"percentile_approx(SALARY,0.5)\").alias(\"median_salary\"))\n                  .orderBy(F.col(\"avg_salary\").desc())\n                  .limit(20))\npdf = state_salary.toPandas()\n\nplt.figure(figsize=(9,5))\nsns.barplot(data=pdf, x=\"avg_salary\", y=\"STATE_NAME\", color=\"#72B7B2\")\nplt.title(\"Average Salary by State\")\nplt.xlabel(\"Average salary\")\nplt.ylabel(\"State\")\nplt.tight_layout()\nplt.show()\n\n\n\n\n\n\n\n\n\nTech Hubs vs Emerging Locations\n\n\nCode\nhub = (df.withColumn(\"hub_label\",\n          F.when(F.col(\"STATE_NAME\").isin(\"California\",\"Texas\",\"Massachusetts\",\"Washington\",\"New York\"),\n                 F.lit(\"Tech Hub\")).otherwise(F.lit(\"Emerging\")))\n         .groupBy(\"hub_label\").agg(F.count(\"*\").alias(\"postings\"))\n         .orderBy(F.col(\"postings\").desc()))\npdf = hub.toPandas()\n\nplt.figure(figsize=(5,4))\nsns.barplot(data=pdf, x=\"hub_label\", y=\"postings\", palette=\"Set2\")\nplt.title(\"Tech Hubs vs Emerging Locations\")\nplt.xlabel(\"\")\nplt.ylabel(\"Postings\")\nplt.tight_layout()\nplt.show()\n\n\n\n\n\n\n\n\n\nTop states by postings\n\n\nCode\ntop_states = df.groupBy(\"STATE_NAME\").count().orderBy(\"count\", ascending=False).limit(15).toPandas()\ntop_states.plot(kind=\"barh\", x=\"STATE_NAME\", y=\"count\", figsize=(8,6), legend=False, title=\"Top states by postings\")\nimport matplotlib.pyplot as plt\nplt.gca().invert_yaxis()\nplt.tight_layout()\nplt.show()\n\n\n\n\n\n\n\n\n\nTop states by remote share\n\n\nCode\nstate_remote_pdf = df.groupBy(\"STATE_NAME\",\"REMOTE_TYPE\").count().toPandas()\npivot = state_remote_pdf.pivot_table(index=\"STATE_NAME\", columns=\"REMOTE_TYPE\", values=\"count\", aggfunc=\"sum\", fill_value=0)\npivot[\"total\"] = pivot.sum(axis=1)\nfor c in [\"Remote\",\"Hybrid\",\"Onsite\"]:\n    if c not in pivot.columns:\n        pivot[c] = 0\npivot[\"remote_share\"] = pivot[\"Remote\"] / pivot[\"total\"]\ntop_remote = pivot.sort_values(\"remote_share\", ascending=False).head(15)\n\ntop_remote[\"remote_share\"].plot(kind=\"barh\", figsize=(8,6), xlim=(0,1), title=\"Top states by remote share\")\nplt.gca().invert_yaxis()\nplt.tight_layout()"
  },
  {
    "objectID": "skill_gap_analysis.html",
    "href": "skill_gap_analysis.html",
    "title": "Skill Gap Analysis",
    "section": "",
    "text": "Objective: Compare the skills required in IT job postings against the actual skills of your group members to identify knowledge gaps and areas for improvement."
  },
  {
    "objectID": "skill_gap_analysis.html#create-a-team-based-skill-dataframe",
    "href": "skill_gap_analysis.html#create-a-team-based-skill-dataframe",
    "title": "Skill Gap Analysis",
    "section": "1 Create a team-based skill dataframe",
    "text": "1 Create a team-based skill dataframe\nEach team member should list their current skills relevant to their selected IT career path. Use a numerical scale (1-5) to indicate proficiency levels:\nNote: Each team member has been given a fictional score to better demonstrate the variations in proficiency level.\n\n1 = Beginner\n2 = Basic knowledge\n3 = Intermediate\n4 = Advanced\n5 = Expert\n\n\n\nCode\nimport pandas as pd\n\nskills_data = {\n    \"Name\": [\"Thomas\", \"Fayobomi\", \"Dominique\", \"Aryan\"],\n    \"Python\": [1, 2, 4, 5],\n    \"SQL\": [2, 3, 3, 4],\n    \"Machine Learning\": [1, 2, 4, 4],\n    \"Cloud Computing\": [1, 2, 3, 5]\n}\n\ndf_skills = pd.DataFrame(skills_data)\ndf_skills.set_index(\"Name\", inplace=True)\ndf_skills\n\n\n\n\n\n\n\n\n\nPython\nSQL\nMachine Learning\nCloud Computing\n\n\nName\n\n\n\n\n\n\n\n\nThomas\n1\n2\n1\n1\n\n\nFayobomi\n2\n3\n2\n2\n\n\nDominique\n4\n3\n4\n3\n\n\nAryan\n5\n4\n4\n5\n\n\n\n\n\n\n\nYou can use heatmaps or any other visualizations to visualize team strengths and gaps.\n\n1.1 \nVisualizing Skill Gaps with Seaborn\n\n\nCode\nimport seaborn as sns\nimport matplotlib.pyplot as plt\n\nplt.figure(figsize=(8, 6))\nsns.heatmap(df_skills, annot=True, cmap=\"coolwarm\", linewidths=0.5)\nplt.title(\"Team Skill Levels Heatmap\")\nplt.show()\n\n\n\n\n\n\n\n\n\n\n\n1.2 Compare team skills to industry requirements\nExtract most in-demand skills from IT job postings. Identify gaps between team skill levels and job expectations."
  },
  {
    "objectID": "skill_gap_analysis.html#extracting-top-skills-from-job-descriptions",
    "href": "skill_gap_analysis.html#extracting-top-skills-from-job-descriptions",
    "title": "Skill Gap Analysis",
    "section": "2 Extracting Top Skills from Job Descriptions",
    "text": "2 Extracting Top Skills from Job Descriptions\n\n\nCode\nfrom collections import Counter\n\n#Assuming job_descriptions is a list of text from job postings\ntop_skills = [\"Python\", \"SQL\", \"Machine Learning\", \"Cloud Computing\", \"Docker\", \"AWS\"]\njob_skill_counts = Counter(top_skills)\n\n# Compare with team skill levels\nfor skill in top_skills:\n    if skill not in df_skills.columns:\n        df_skills[skill] = 0  # Assume no knowledge in missing skills\n\ndf_skills\n\n\n\n\n\n\n\n\n\nPython\nSQL\nMachine Learning\nCloud Computing\nDocker\nAWS\n\n\nName\n\n\n\n\n\n\n\n\n\n\nThomas\n1\n2\n1\n1\n0\n0\n\n\nFayobomi\n2\n3\n2\n2\n0\n0\n\n\nDominique\n4\n3\n4\n3\n0\n0\n\n\nAryan\n5\n4\n4\n5\n0\n0"
  },
  {
    "objectID": "skill_gap_analysis.html#improvement-plan",
    "href": "skill_gap_analysis.html#improvement-plan",
    "title": "Skill Gap Analysis",
    "section": "3 Improvement Plan",
    "text": "3 Improvement Plan\nWhich skills should each member prioritize learning? What courses or resources can help? How can the team collaborate to bridge skill gaps?"
  },
  {
    "objectID": "RandomForest.html",
    "href": "RandomForest.html",
    "title": "Random Forest",
    "section": "",
    "text": "Random Forest Analysis\nThe purpose of this analysis is to determine how much does salary depends on geography versus other variables such as years of experience, job field, remote/onsite work, and level of education.\nVariables Used\nThe following variables will be used in the Random Forest model:\n\n\nRemote Type (On-Site/Remote)\n\n\nState Name\n\n\nMinimum Education levels\n\n\nNAICS Name\n\n\nRandom Forest Model Deployment & Interpretation\n\n\nCode\nrf = RandomForestRegressor(\n    featuresCol=\"features\",\n    labelCol=\"SALARY\",\n    numTrees=300,\n    maxDepth=12,\n    seed=42\n)\n\npipeline = Pipeline(stages=indexers + encoders + [assembler, rf])\n\n#Train / Test Split - Using 80% of data for training and 20% for testing\ntrain_df, test_df = rf_df.randomSplit([0.8, 0.2], seed=42)\n\n# Fit and Predict\nmodel = pipeline.fit(train_df)\npred = model.transform(test_df)\n\n# RMSE, MAE, R squared\nev = RegressionEvaluator(labelCol=\"SALARY\", predictionCol=\"prediction\")\n\nrmse = ev.setMetricName(\"rmse\").evaluate(pred)\nmae  = ev.setMetricName(\"mae\").evaluate(pred)\nr2   = ev.setMetricName(\"r2\").evaluate(pred)\n\nrf_metrics = pd.DataFrame({\n    \"RMSE\": [rmse],\n    \"MAE\": [mae],\n    \"R²\": [r2]\n}).round({\"RMSE\": 0, \"MAE\": 0, \"R²\": 3})\n\nrf_metrics\n\n\n\n\n\n\n\n\n\nRMSE\nMAE\nR²\n\n\n\n\n0\n38828.0\n30056.0\n0.194\n\n\n\n\n\n\n\nInterpretation: These variables collectively explains the salary by about 20%. Whereas in the testing data, the tested salaries were off by ~39K compared to the actual.\nFeature Importance\nFeature importance determines which variables used in the model had the most influence/impact on determining the salary. The graph below shows the top 20 variables used.\n\n\nCode\nrf_stage = model.stages[-1]\nimportances = np.array(rf_stage.featureImportances.toArray())\n\nmeta = pred.schema[\"features\"].metadata[\"ml_attr\"][\"attrs\"]\nattrs = sorted([*meta.get(\"binary\", []), *meta.get(\"numeric\", [])], key=lambda a: a[\"idx\"])\nfeature_names = [a[\"name\"] for a in attrs]\n\ntopn = 20\nfeat_imp = (pd.DataFrame({\"Feature\": feature_names, \"Importance\": importances})\n              .sort_values(\"Importance\", ascending=False)\n              .head(topn))\n\ndef clean_label(s: str) -&gt; str:\n    s = re.sub(r'(_ohe|_idx)$', '', s)\n    s = s.replace(\"MIN_EDULEVELS\",\"Education\") \\\n         .replace(\"NAICS2_NAME\",\"Industry\") \\\n         .replace(\"STATE_NAME\",\"State\") \\\n         .replace(\"REMOTE_TYPE\",\"Remote\")\n    return textwrap.shorten(s, width=28, placeholder=\"…\")  # wrap/shorten\nfeat_imp[\"Label\"] = feat_imp[\"Feature\"].map(clean_label)\n\nplt.figure(figsize=(7,6))\nsns.barplot(data=feat_imp, x=\"Importance\", y=\"Label\")\nplt.title(f\"Top {topn} Random Forest Feature Importances\")\nplt.xlabel(\"Importance\"); plt.ylabel(\"Feature\")\nplt.tight_layout()\nplt.show()\n\n\n\n\n\n\n\n\n\nInterpretation: Despite a relatively lower R squared value below 20% - this chart clearly shows that state (and ultimately location) has less influence on the amount of salary an employee receives compared to their education, position, and field.\nPredictive Analysis\nThis analysis uses synthetic data to estimate what the Random Forest model would predict the salaries would be. There are 10 different variations of job type, state, education, etc. to predict each salary.\n\n\nCode\nfrom pyspark.sql import functions as F\n\ncat_cols = [\"REMOTE_TYPE\", \"STATE_NAME\", \"MIN_EDULEVELS\", \"NAICS2_NAME\"]\nnum_cols = [\"MIN_YEARS_EXPERIENCE\"]\n\n# Generic data to test predictive analysis\ntest_data = [\n    {\"REMOTE_TYPE\": \"Onsite\", \"STATE_NAME\": \"California\", \"MIN_EDULEVELS\": \"Master's\",\n     \"NAICS2_NAME\": \"Information\", \"MIN_YEARS_EXPERIENCE\": 7.0},\n\n    {\"REMOTE_TYPE\": \"Remote\", \"STATE_NAME\": \"Texas\", \"MIN_EDULEVELS\": \"Associate or lower\",\n     \"NAICS2_NAME\": \"Administrative and Support and Waste Management and Remediation Services\", \"MIN_YEARS_EXPERIENCE\": 2.0},\n\n    {\"REMOTE_TYPE\": \"Onsite\", \"STATE_NAME\": \"Washington\", \"MIN_EDULEVELS\": \"Bachelor\",\n     \"NAICS2_NAME\": \"Professional, Scientific, and Technical Services\", \"MIN_YEARS_EXPERIENCE\": 12.0},\n\n    {\"REMOTE_TYPE\": \"Hybrid\", \"STATE_NAME\": \"Illinois\", \"MIN_EDULEVELS\": \"Bachelor\",\n     \"NAICS2_NAME\": \"Finance and Insurance\", \"MIN_YEARS_EXPERIENCE\": 6.0},\n\n    {\"REMOTE_TYPE\": \"Onsite\", \"STATE_NAME\": \"New York\", \"MIN_EDULEVELS\": \"Master's\",\n     \"NAICS2_NAME\": \"Educational Services\", \"MIN_YEARS_EXPERIENCE\": 10.0},\n\n    {\"REMOTE_TYPE\": \"Hybrid\", \"STATE_NAME\": \"Florida\", \"MIN_EDULEVELS\": \"Bachelor\",\n     \"NAICS2_NAME\": \"Manufacturing\", \"MIN_YEARS_EXPERIENCE\": 8.0},\n\n    {\"REMOTE_TYPE\": \"Onsite\", \"STATE_NAME\": \"Ohio\", \"MIN_EDULEVELS\": \"Associate or lower\",\n     \"NAICS2_NAME\": \"Health Care and Social Assistance\", \"MIN_YEARS_EXPERIENCE\": 3.0},\n\n    {\"REMOTE_TYPE\": \"Onsite\", \"STATE_NAME\": \"Virginia\", \"MIN_EDULEVELS\": \"PhD\",\n     \"NAICS2_NAME\": \"Professional, Scientific, and Technical Services\", \"MIN_YEARS_EXPERIENCE\": 9.0},\n\n    {\"REMOTE_TYPE\": \"Remote\", \"STATE_NAME\": \"Colorado\", \"MIN_EDULEVELS\": \"Bachelor\",\n     \"NAICS2_NAME\": \"Real Estate and Rental and Leasing\", \"MIN_YEARS_EXPERIENCE\": 7.0},\n\n    {\"REMOTE_TYPE\": \"Onsite\", \"STATE_NAME\": \"Michigan\", \"MIN_EDULEVELS\": \"Bachelor\",\n     \"NAICS2_NAME\": \"Wholesale Trade\", \"MIN_YEARS_EXPERIENCE\": 5.0},\n]\n\nnew_df = spark.createDataFrame(test_data)\n\n# Preventative for nulls in categoricals your pipeline indexes\nnew_df = new_df.fillna({c: \"Unknown\" for c in cat_cols})\n\n# Predicting the salaries using trained pipeline model\npred = model.transform(new_df)\n\npred_pdf = (\n    pred.select(\n        F.col(\"REMOTE_TYPE\").alias(\"Remote/Onsite\"),\n        F.col(\"STATE_NAME\").alias(\"State\"),\n        F.col(\"MIN_EDULEVELS\").alias(\"Education\"),\n        F.col(\"NAICS2_NAME\").alias(\"Industry\"),\n        F.col(\"MIN_YEARS_EXPERIENCE\").alias(\"Min Yrs Exp\"),\n        F.col(\"prediction\").alias(\"Predicted Salary\"),\n    )\n    .orderBy(F.col(\"Predicted Salary\").desc())\n    .toPandas()\n)\n\n# Round and format currency\npred_pdf[\"Predicted Salary\"] = pred_pdf[\"Predicted Salary\"].round(0)\n\n# Add a rank column\npred_pdf.insert(0, \"#\", range(1, len(pred_pdf) + 1))\n\n# Render a clean, index-free, currency-formatted table\npred_pdf.style.format({\n    \"Predicted Salary\": \"${:,.0f}\",\n    \"Min Yrs Exp\": \"{:.0f}\"\n}).hide(axis=\"index\")\n\n\n\n\n\n\n\n#\nRemote/Onsite\nState\nEducation\nIndustry\nMin Yrs Exp\nPredicted Salary\n\n\n\n\n1\nOnsite\nVirginia\nPhD\nProfessional, Scientific, and Technical Services\n9\n$231,918\n\n\n2\nOnsite\nCalifornia\nMaster's\nInformation\n7\n$171,380\n\n\n3\nOnsite\nWashington\nBachelor\nProfessional, Scientific, and Technical Services\n12\n$139,904\n\n\n4\nHybrid\nFlorida\nBachelor\nManufacturing\n8\n$122,962\n\n\n5\nHybrid\nIllinois\nBachelor\nFinance and Insurance\n6\n$121,860\n\n\n6\nRemote\nTexas\nAssociate or lower\nAdministrative and Support and Waste Management and Remediation Services\n2\n$115,777\n\n\n7\nOnsite\nMichigan\nBachelor\nWholesale Trade\n5\n$113,347\n\n\n8\nRemote\nColorado\nBachelor\nReal Estate and Rental and Leasing\n7\n$111,173\n\n\n9\nOnsite\nOhio\nAssociate or lower\nHealth Care and Social Assistance\n3\n$102,261\n\n\n10\nOnsite\nNew York\nMaster's\nEducational Services\n10\n$75,983\n\n\n\n\n\nInterpretation: The results are varied - in some instances the results align with our previous analysis - higher eduction, onsite, and tech should see higher salaries. For example, the first line and eigth line do have the highest salaries being in information and tech alongside 5+ years of experience, onsite, and higher education completed. However, the fith line has the lowest salary, but does not necessarily align in an intuitive sense - 10 years of experience, Masters, onsite, etc. should be ranked higher.\nKMeans Clustering Analysis\nThis analysis explores salary and years of experience by the NAICS Name. As shown below, three groups have been for various NAICS’s, with years of experience horizontally, and salary on the vertical axis.\n\n\nCode\n# Visualizing the results\nplot_pdf = pred.select(\"MIN_YEARS_EXPERIENCE\", \"SALARY\", \"cluster\") \\\n               .sample(False, 0.25, 42).toPandas()\nimport matplotlib.pyplot as plt\nplt.figure(figsize=(8,6))\ns = plt.scatter(plot_pdf[\"MIN_YEARS_EXPERIENCE\"], plot_pdf[\"SALARY\"], c=plot_pdf[\"cluster\"], alpha=.6)\nplt.xlabel(\"MIN_YEARS_EXPERIENCE\"); plt.ylabel(\"SALARY\")\nplt.title(\"Clustering by NAICS2\")\nhandles,_ = s.legend_elements()\nplt.legend(handles, [f\"Cluster {i}\" for i in sorted(plot_pdf['cluster'].unique())], title=\"Clusters\")\nplt.grid(True, alpha=.3); plt.tight_layout(); plt.show()\n\n\n\n\n\n\n\n\n\nInterpretation: The KMeans cluster mostly uses salaries to separate each cluster group - while some clusters pay lower or higher pay at the same years of experience, this suggests that the industry does influence salaries at different levels of experience. Overall, salaries generally rise with experience, though industry effects can override that pattern."
  },
  {
    "objectID": "introduction.html",
    "href": "introduction.html",
    "title": "Research Introduction: AI vs. Non-AI Careers",
    "section": "",
    "text": "The American labor market is undergoing a fundamental geographic restructuring. Factors such as the COVID-19 global pandemic have shifted the way businesses operate, the rise of Artificial Intelligence (AI) continuously impacts the labor force as it improves, and emerging tech hubs have presented competition for established tech hubs. These modern complexities raise critical questions:\n\nWhich cities or states have the highest job growth for AI vs. non-AI careers?\nAre remote jobs increasing or decreasing across industries?\nDo tech hubs still dominate hiring, or are other locations emerging?\nHow do urban vs. rural job markets differ for AI and non-AI careers?\n\nThis research examines job growth patterns, remote work trends, and the shifting geography of AI and non-AI careers to understand how location shapes opportunity in the evolving American economy."
  },
  {
    "objectID": "introduction.html#introduction",
    "href": "introduction.html#introduction",
    "title": "Research Introduction: AI vs. Non-AI Careers",
    "section": "",
    "text": "The American labor market is undergoing a fundamental geographic restructuring. Factors such as the COVID-19 global pandemic have shifted the way businesses operate, the rise of Artificial Intelligence (AI) continuously impacts the labor force as it improves, and emerging tech hubs have presented competition for established tech hubs. These modern complexities raise critical questions:\n\nWhich cities or states have the highest job growth for AI vs. non-AI careers?\nAre remote jobs increasing or decreasing across industries?\nDo tech hubs still dominate hiring, or are other locations emerging?\nHow do urban vs. rural job markets differ for AI and non-AI careers?\n\nThis research examines job growth patterns, remote work trends, and the shifting geography of AI and non-AI careers to understand how location shapes opportunity in the evolving American economy."
  },
  {
    "objectID": "introduction.html#research-rationale",
    "href": "introduction.html#research-rationale",
    "title": "Research Introduction: AI vs. Non-AI Careers",
    "section": "Research Rationale",
    "text": "Research Rationale\n\nAI’s Impact on Employment Geography\nBessen ((2018)) argues that AI’s employment impact depends critically on market demand rather than automation alone. Analyzing over a century of manufacturing data, he finds that technology-driven productivity gains initially increased jobs when demand was elastic but eventually reduced employment once markets became saturated. This suggests that geographic regions where AI targets unmet needs may experience job growth, while areas where AI serves already-saturated markets face potential displacement—a distinction crucial for understanding the uneven geographic distribution of AI career opportunities.\n\n\nRemote Work and Post-Pandemic Restructuring\nWith COVID-19 disrupting various business models, American corporations had to quickly restructure operations. Five years later, COVID-19 is no longer considered a national emergency, with various public and private sector organizations implementing return-to-office (RTO) mandates (Paulino et al. (2025)). Although the trend is currently favorable for RTO policies, “smaller companies, which often cannot compete on salary alone, are increasingly embracing remote work flexibility to attract and retain top talent” (Paulino et al. (2025)). Smaller companies can use remote work policies to their advantage, whether to lower their overhead costs or retain top talent without offering as much salary compared to in-office based roles.\n\n\nEmerging Tech Hubs and Geographic Concentration\nTech hubs seem to be emerging in droves across various parts of America. According to Chen, Levanon, and Sigelman ((2024)), although there are many smaller hubs forming, the Silicon Valley on the West Coast of the United States is still dominant. They explore the idea that there is a relationship between emerging tech hubs and established tech hubs: “the greatest determinant of migration is geographic proximity” (Chen, Levanon, and Sigelman (2024)). Another reason for the expansion of tech hubs in the United States is “likely motivated by quality of life and cost of living” (Chen, Levanon, and Sigelman (2024)). Although other tech hubs are spreading towards other regions in the United States, Silicon Valley residents shouldn’t see this as a threat, since growing tech talent causes a synergy that, as a result, both grows and redistributes tech employment.\n\n\nUrban-Rural Disparities in Remote Work Access\nGeographic location significantly shapes access to remote work opportunities, with important implications for employment equity. Paul ((2022)) analyzes pre-pandemic travel survey data and finds that rural workers prefer but rarely access work-from-home arrangements compared to urban counterparts, primarily due to inadequate broadband infrastructure and the geographic concentration of remote-compatible jobs in metropolitan areas. The study reveals that urban workers were nearly twice as likely to have remote work options, while rural workers—particularly Hispanic rural workers—faced compounded disadvantages in accessing virtual employment. These patterns suggest that AI careers requiring advanced digital infrastructure and remote work capabilities may concentrate in urban areas unless targeted policies address rural technology access gaps."
  },
  {
    "objectID": "introduction.html#methodology",
    "href": "introduction.html#methodology",
    "title": "Research Introduction: AI vs. Non-AI Careers",
    "section": "Methodology",
    "text": "Methodology\nWe undertook an investigation of job posting data from January to September 2024. Our tool, Lightcast, enabled us to standardize the many titles, locations, and employer information that populated the job postings. Through that process, we also conducted a feature analysis to understand the kinds of construction that are going on for jobs requiring artificial intelligence “in both a technical and a generative sense.” Overall, we read just over 22,000 job postings requiring AI-related skills.\nThen on the basic level, we conducted some summary and inferential statistics to understand the kinds of pay differences that might exist among postings for AI and non-AI jobs. On another level, we ran the postings through a random-forest regressor—a kind of model that uses certain given variables to try to explain or understand what is going on with the posting salaries. The model itself has 10 different versions, and each one assigns weights to the different given variables (such as the industry in which the job is located) to come up with a predicted salary. Results should shed light on the nature of pay for AI skills in the job market and how geographic and industrial factors influence compensation patterns."
  },
  {
    "objectID": "introduction.html#research-questions",
    "href": "introduction.html#research-questions",
    "title": "Research Introduction: AI vs. Non-AI Careers",
    "section": "Research Questions",
    "text": "Research Questions\nThis analysis addresses the following key questions:\n\nGeographic Distribution: Where are AI jobs concentrated, and how does this compare to non-AI career opportunities?\nRemote Work Trends: How have remote, hybrid, and on-site work arrangements evolved post-pandemic for AI versus non-AI positions?\nUrban-Rural Divide: What disparities exist between urban and rural areas in terms of AI job growth and compensation?\nCompensation Patterns: How do salaries for AI-related positions compare across different geographic regions and work arrangements?"
  },
  {
    "objectID": "introduction.html#structure-of-this-report",
    "href": "introduction.html#structure-of-this-report",
    "title": "Research Introduction: AI vs. Non-AI Careers",
    "section": "Structure of This Report",
    "text": "Structure of This Report\nThe remainder of this report is organized as follows: Section 2 presents our findings on remote work trends; Section 3 examines the urban-rural divide in AI employment; Section 4 discusses implications for job seekers, employers, and policymakers; and Section 5 concludes with recommendations for fostering inclusive growth in the AI economy."
  },
  {
    "objectID": "introduction.html#references",
    "href": "introduction.html#references",
    "title": "Research Introduction: AI vs. Non-AI Careers",
    "section": "References",
    "text": "References\n\n\nBessen, J. (2018): AI and Jobs: The Role of Demand, Working Paper, National Bureau of Economic Research.\n\n\nChen, Z., G. Levanon, and M. Sigelman. (2024): America’s Tech Hubs Are Multiplying: How Tech Powerhouses’ Diaspora Are Fueling the Rise of New Cities on the Talent Frontier,The Burning Glass Institute.\n\n\nPaul, J. A. (2022): “Work from home behaviors among u.s. Urban and rural residents,” Transportation Research Part A: Policy and Practice, 165, 254–69.\n\n\nPaulino, M., S. J. London, L. M. Giurge, R. W. Buell, and A. S. Gabriel. (2025): “Return-to-office mandates and workplace inequality: Implications for industrial-organizational psychology,” Industrial and Organizational Psychology,."
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Geographic & Remote Work Analysis",
    "section": "",
    "text": "This project analyzes job market trends in 2024, focusing on geographic and remote work analysis."
  },
  {
    "objectID": "index.html#overview",
    "href": "index.html#overview",
    "title": "Geographic & Remote Work Analysis",
    "section": "",
    "text": "This project analyzes job market trends in 2024, focusing on geographic and remote work analysis."
  },
  {
    "objectID": "index.html#key-findings",
    "href": "index.html#key-findings",
    "title": "Geographic & Remote Work Analysis",
    "section": "Key Findings",
    "text": "Key Findings\n\nEmerging tech hubs are now leading in job growth, outpacing legacy hubs\nRemote work availability is highest in the Real Estate, Arts, and Finance sectors. Additionally, most of the remote job postings are from Alaska\nTop in-demand skills include…"
  },
  {
    "objectID": "index.html#explore-the-analysis",
    "href": "index.html#explore-the-analysis",
    "title": "Geographic & Remote Work Analysis",
    "section": "Explore the Analysis",
    "text": "Explore the Analysis\nResearch Introduction: Background and research questions Geographic Trends: EDA and Visualizations: Exploratory data analysis Tech Hub Analysis: Legacy vs emerging tech hubs Skill Gap Analysis: In-demand skills analysis Random Forest: Predictive modeling"
  },
  {
    "objectID": "index.html#about-this-project",
    "href": "index.html#about-this-project",
    "title": "Geographic & Remote Work Analysis",
    "section": "About This Project",
    "text": "About This Project\nDataset: Lightcast Job Postings (Jan-Sep 2024) Team: Group 09 Course: AD688 - Cloud Analytics"
  }
]