---
title: "Tech Hub Analysis"
format:
  html:
    toc: true
    code-fold: true
    number-sections: true
---

## Purpose

This section evaluates whether legacy tech hubs (Bay Area, Seattle, Boston, NYC, Austin) still dominate AI hiring or whether a set of emerging hubs is gaining share. We compare posting **volume**, **AI share**, **remote/hybrid availability**, and **median salary** (when available).

::: callout-note
**Data source:** `data/raw/lightcast_job_postings.csv` (Lightcast, 2024; Jan–Sep if that’s what you downloaded).  
**Instructions:** Make sure the CSV is at **`data/raw/lightcast_job_postings.csv`**.
:::

## Setup

```{r}
library(tidyverse)
library(lubridate)
theme_set(theme_minimal(base_size = 14))

path <- "data/raw/lightcast_job_postings.csv"
raw <- read_csv(path, show_col_types = FALSE)
df <- raw %>%
  rename_with(toupper) %>%
  mutate(
    CITY_NAME  = coalesce(CITY_NAME, CITY, NA),
    STATE_NAME = coalesce(STATE_NAME, STATE, NA),
    TITLE      = coalesce(JOB_TITLE, TITLE, NA),
    SKILLS_TXT = coalesce(SKILLS, SKILL_TEXT, NA),
    POSTED     = coalesce(POSTED_DATE, DATE_POSTED, as.character(NA)),
    POSTED     = suppressWarnings(ymd(POSTED)),
    REMOTE_TYPE = case_when(
      REMOTE_TYPE %in% c("Remote","REMOTE","remote","1") ~ "Remote",
      REMOTE_TYPE %in% c("Hybrid","HYBRID","hybrid","3") ~ "Hybrid",
      TRUE                                               ~ "On-site"
    ),
    SALARY = suppressWarnings(readr::parse_number(coalesce(SALARY, SALARY_TO, SALARY_FROM)))
  )

# Prefer an existing Lightcast AI flag if present; otherwise derive via keywords
has_ai <- any(names(df) %in% c("AI_RELATED","AI_FLAG"))
if (!has_ai) {
  ai_regex <- "(?i)\\bAI\\b|artificial intelligence|machine learning|\\bML\\b|deep learning|NLP|computer vision|MLOps|LLM|generative"
  df <- df %>%
    mutate(
      AI_RELATED = if_else(
        str_detect(coalesce(TITLE, ""), ai_regex) |
          str_detect(coalesce(SKILLS_TXT, ""), ai_regex),
        TRUE, FALSE, missing = FALSE
      )
    )
} else {
  df <- df %>%
    mutate(AI_RELATED = coalesce(AI_RELATED, AI_FLAG, FALSE))
}

# Simple metro label (prefer true MSA/METRO if present)
df <- df %>%
  mutate(
    METRO = coalesce(METRO, MSA, paste0(CITY_NAME, ", ", STATE_NAME)) %>% str_trim()
  )
legacy_hubs <- c(
  "San Francisco, CA", "San Jose, CA", "Oakland, CA",   # Bay Area proxy (simple)
  "Seattle, WA",
  "Boston, MA",
  "New York, NY",
  "Austin, TX"
)

emerging_hubs <- c(
  "Raleigh, NC", "Durham, NC",
  "Denver, CO", "Boulder, CO",
  "Atlanta, GA",
  "Salt Lake City, UT",
  "Pittsburgh, PA",
  "Nashville, TN",
  "Miami, FL",
  "Phoenix, AZ"
)

df <- df %>%
  mutate(
    HUB_CLASS = case_when(
      METRO %in% legacy_hubs   ~ "Legacy Hub",
      METRO %in% emerging_hubs ~ "Emerging Hub",
      TRUE                     ~ "Other"
    )
  )
kpi <- df %>%
  filter(!is.na(METRO), !is.na(STATE_NAME)) %>%
  mutate(REMOTE_BIN = if_else(REMOTE_TYPE %in% c("Remote","Hybrid"), "Remote/Hybrid", "On-site")) %>%
  group_by(HUB_CLASS) %>%
  summarise(
    postings     = dplyr::n(),
    ai_share     = mean(AI_RELATED, na.rm = TRUE),
    remote_share = mean(REMOTE_BIN == "Remote/Hybrid", na.rm = TRUE),
    med_salary   = if (all(is.na(SALARY))) NA_real_ else median(SALARY, na.rm = TRUE),
    .groups = "drop"
  ) %>%
  arrange(desc(postings))

kpi
kpi %>%
  mutate(HUB_CLASS = forcats::fct_relevel(HUB_CLASS, "Legacy Hub","Emerging Hub","Other")) %>%
  ggplot(aes(HUB_CLASS, ai_share)) +
  geom_col() +
  scale_y_continuous(labels = scales::percent_format(accuracy = 1)) +
  labs(x = NULL, y = "AI Share of Postings", title = "AI Share by Hub Class (2024)")
kpi %>%
  mutate(HUB_CLASS = forcats::fct_relevel(HUB_CLASS, "Legacy Hub","Emerging Hub","Other")) %>%
  ggplot(aes(HUB_CLASS, remote_share)) +
  geom_col() +
  scale_y_continuous(labels = scales::percent_format(accuracy = 1)) +
  labs(x = NULL, y = "Remote/Hybrid Share", title = "Remote Availability by Hub Class (2024)")
metro_tbl <- df %>%
  filter(HUB_CLASS != "Other") %>%
  group_by(METRO, HUB_CLASS) %>%
  summarise(
    postings   = dplyr::n(),
    ai_share   = mean(AI_RELATED, na.rm = TRUE),
    remote_sh  = mean(REMOTE_TYPE %in% c("Remote","Hybrid"), na.rm = TRUE),
    med_salary = if (all(is.na(SALARY))) NA_real_ else median(SALARY, na.rm = TRUE),
    .groups = "drop"
  ) %>%
  arrange(desc(ai_share), desc(postings)) %>%
  slice_head(n = 12)

metro_tbl
metro_tbl %>%
  ggplot(aes(reorder(METRO, ai_share), ai_share, fill = HUB_CLASS)) +
  geom_col() +
  coord_flip() +
  scale_y_continuous(labels = scales::percent) +
  labs(x = NULL, y = "AI Share of Postings",
       title = "Top Metros by AI Intensity (AI Share Among Postings)") +
  theme(legend.position = "top")
